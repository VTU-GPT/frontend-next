[[["ec8c4203-e463-42e8-a36f-8f6c772fef74",{"pageContent":" \n  DAYANANDA SAGAR ACADEMY  \nOF \nTECHNOLOGY AND MANAGEMENT \n \n \n \nLecture Notes on \nRESEARCH METHODOLOGY & INTELLECTUAL \nPROPERTY RIGHTS – 21RMI56 \n \nPrepared by \nDr. Dilip R B.E, M.E, Ph.D., IEEE MISTE \nMr. Syed Ateequr Rehman B. E, M.Tech \nDr. Saranya SN B.E, M.E, Ph.D. \n \n \n \n \nDEPARTMENT OF ELECTRONICS AND \nCOMMUNICATION ENGINEERING ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":1}}}],["b609af76-5653-44ba-90cd-4b1cbe20ecdc",{"pageContent":" \n \nSubject: RESEARCH METHODOLOGY & INTELLECTUAL PROPERTY RIGHTS \nSubject Code: 21RMI56 \n \nCOURSE OVERVIEW \nThe architecture of course contents introduces an individual into the field of research inferring \nits fundamentals, objectives, motivation and ethics towards engineering research. The course \ncontents  emphasizes  on  literature  review  pattern  and  technical  reading  focused  towards \npublishing the research work with proper attributions and citations to the support system. The \ncourse contents introduce an individual as a researcher towards intellectual property rights and \nfurther grading into the capacities of patenting with necessary validation protocols. Further the \nconcepts of  copyrights and trademarks ensure proper understanding about its adaptation and \nprecautions while applying the principles of any other previous references in ongoing research. \nSeveral case studies also validate the same. Industrial design rights, acts and laws ensure the \nlearner  to  advance  his/her  findings  towards  the  registration  of  their  design.  Geographical \nindications highlight the aspects of nativity of the product and its global impact upholding the \ncredibility of its surroundings \nCOURSE OBJECTIVES \n• To understand the knowledge on basics of research and its types. \n• To learn the concept of Literature Review, Technical Reading, Attributions and \nCitations. \n• To discuss the concepts of Intellectual Property Rights in engineering \n• To interpret the concepts of copyrights, trademarks, GI and Industrial design \nCOURSE OUTCOMES \n \n \nCO’S Course outcomes: students will be able to  \nC01 \nUnderstand  the fundamentals  of research  problem  formulation and  illustrate the \nimportance of IPR in growth of individuals and nation. \nC02 \nApply  different principles  of  ethics  and  corporate  social  responsibility in  research \npublication and IPR \nC03 \nAnalyse   the   operational procedure   of   Literature   Review,   Technical Reading, and \nDrafting Processes of IPR and Publications  \nC04 \nInvestigate the strategic plan for the efficient and effective distribution on research and \nIPR concepts that respond to evolving markets. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":2}}}],["9299c1b6-371e-4cd1-8e48-314c4c2b80e2",{"pageContent":" \n \nCOURSE DETAILS \n \nRESEARCH METHODOLOGY & INTELLECTUAL PROPERTY RIGHTS \nCourse Code - 21RMI56 CIE Marks – 50 \nTeaching Hours / Week (L:T:P:S) - 1:2:0:0 SEE Marks – 50 \nTotal Hours of Pedagogy – 25 Total Marks – 100 \nCredits - 02 Exam Hours - 03 \nCOURSE SYLLABUS \n \nModule 1: Introduction \nMeaning  of  Research,  Objectives  of  Engineering  Research,  and  Motivation  in  Engineering \nResearch, Types of Engineering Research, Finding and Solving a Worthwhile Problem. Ethics in \nEngineering Research, Ethics in Engineering Research Practice, Types of Research \nMisconduct, Ethical Issues Related to Authorship. \nModule 2: Literature Review and Technical Reading, Attributions and Citations \nLiterature Review and Technical Reading, New and Existing Knowledge, Analysis and Synthesis \nof  Prior  Art,  Bibliographic  Databases:  Web  of  Science,  Google  and  Google  Scholar,  Effective \nSearch:  The  Way  Forward,  Introduction  to  Technical  Reading,  Conceptualizing  Research, \nCritical  and  Creative  Reading,  Taking  Notes  While  Reading,  Reading  Mathematics  and \nAlgorithms, Reading a Datasheet. \nAttributions  and  Citations:  Giving  Credit  Wherever  Due,  Citations:  Functions  and  Attributes, \nImpact of Title and Keywords on Citations, Knowledge Flow through Citation, Citing Datasets, \nStyles for Citations, Acknowledgments and Attributions, What Should Be Acknowledged, \nAcknowledgments in, Books Dissertations, Dedication or Acknowledgments. \nModule 3: Intellectual Property Rights, Patents and Process of Patenting \nIntroduction to Intellectual Property: Role of IP in the Economic and Cultural Development of \nthe Society, IP Governance, IP as a Global Indicator of Innovation, Origin of IP, History of IP in \nIndia, Major Amendments in IP Laws and Acts in India. \nPatents: Conditions for Obtaining a Patent Protection, To Patent or Not to Patent an Invention, \nRights  Associated  with  Patents,  Enforcement  of  Patent  Rights,  Inventions,  and  Eligible  for \nPatenting,  Non-Patentable  Matters,  Patent  Infringements,  Avoid  Public Disclosure  of  an \nInvention before Patenting. \nProcess of Patenting: Prior Art Search, Choice of Application to be Filed, Patent Application \nForms,  Jurisdiction  of  Filing  Patent  Application,  Publication,  Pre-grant  Opposition, ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":3}}}],["684161fe-0741-478a-8ef2-926775ad8660",{"pageContent":" \n \nExamination,   Grant   of   a   Patent,   Validity   of   Patent   Protection,   Post-grant   Opposition, \nCommercialization of a  Patent, Need for  a Patent Attorney/Agent, Can a Worldwide Patent be \nObtained, Do I Need First to File a Patent in India, Patent Related Forms, Fee Structure, Types \nof Patent Applications, Commonly Used Terms in Patenting, National Bodies Dealing with \nPatent Affairs, Utility Models \nModule 4: Copyrights and Related Rights and Trademarks \nCopyrights  and  Related  Rights:  Classes  of  Copyrights,  Criteria  for  Copyright,  Ownership  of \nCopyright,  Copyrights  of  the  Author,  Copyright  Infringements,  Copyright  Infringement  is  a \nCriminal  Offence,  Copyright  Infringement  is   a Cognizable   Offence,  Fair  Use  Doctrine, \nCopyrights  and  Internet,  Non-Copyright  Work,  Copyright  Registration,  Judicial  Powers  of  the \nRegistrar  of  Copyrights,  Fee  Structure,  Copyright  Symbol,  Validity  of  Copyright,  Copyright \nProfile  of  India,  Copyright  and  the  word  ‘Publish,  Transfer  of  Copyrights  to  a  Publisher, \nCopyrights  and  the  Word  ‘Adaptation’,  Copyrights  and  the  Word  ‘Indian  Work’,  Joint \nAuthorship,  Copyright  Society,  Copyright  Board,  Copyright  Enforcement  Advisory  Council \n(CEAC), International Copyright Agreements, Conventions and Treaties, Interesting Copyrights \nCases. \nTrademarks: Eligibility Criteria, Who Can Apply for a Trademark, Acts and Laws, Designation \nof  Trademark  Symbols,  Classification  of  Trademarks,  Registration  of  a  Trademark  is  Not \nCompulsory,  Validity  of  Trademark,  and  Types  of  Trademark  Registered  in  India,  Trademark \nRegistry, and Process for Trademarks Registration, Prior Art Search, and Famous Case Law: \nCoca-Cola Company vs. Bisleri International Pvt. Ltd. \nModule 5: Industrial Design, Geographical Indications and Case studies on Patents \nIndustrial Designs: Eligibility Criteria, Acts and Laws to Govern Industrial Designs, Design \nRights, Enforcement of Design Rights, Non-Protectable Industrial Designs India, Protection \nTerm, Procedure for Registration of Industrial Designs, Prior Art Search, Application for \nRegistration, Duration of the Registration of a Design, Importance of Design Registration, \nCancellation of the Registered Design, Application Forms, Classification of Industrial Designs, \nDesigns Registration Trend in India, International Treaties, Famous Case Law: Apple Inc. vs. \nSamsung Electronics Co. \nGeographical  Indications:  Acts,  Laws  and  Rules  Pertaining  to  GI,  Ownership  of  GI,  Rights \nGranted  to  the  Holders,  Registered  GI  in  India,  Identification  of  Registered  GI,  Classes  of  GI, \nNon-Registerable  GI,  Protection  of  GI,  Collective  or  Certification  Marks,  Enforcement  of  GI \nRights, Procedure for GI Registration Documents Required for GI Registration, GI Ecosystem in \nIndia. \nCase Studies on Patents: Case study of Curcuma (Turmeric) Patent, Case study of Neem Patent, \nCase study of Basmati patent, IP Organizations in India, Schemes and Programs ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":4}}}],["778578c5-b01d-4b15-9319-80334c3a4ce4",{"pageContent":" \n \nTextbooks \n1. Dipankar Deb • Rajeeb Dey, Valentina E. Balas “Engineering Research Methodology”, \nISSN 1868-4394 ISSN 1868-4408 (electronic), Intelligent Systems Reference Library, \nISBN 978-981-13- 2946-3 ISBN 978-981-13-2947-0 (eBook), \nhttps://doi.org/10.1007/978-981-13-2947-0 \n2. Intellectual Property A Primer for Academia by Prof. Rupinder Tewari and Ms. \nMamta Bhardwaj \nReference books \n1. David V. Thiel “Research Methods for Engineers” Cambridge University Press, 978- \n1-107-03488- 4 \n2. Intellectual Property Rights by N.K.Acharya Asia Law House 6th Edition. ISBN: \n978-93-81849-30-9 \nCOURSE ASSESSMENT DETAILS \nAssessment Details (both CIE and SEE) \n• The Weightage of Continuous Internal Evaluation (CIE) is 50% and for Semester End \nExam (SEE) is 50%. \n• The minimum passing mark for the CIE is 40% of the maximum marks (20 marks out \nof 50). \n• A student shall be deemed to have satisfied the academic requirements and earned the \ncredits  allotted  to  each  subject/  course  if  the  student  secures  not  less  than  35%  (18 \nMarks out of 50) in the semester-end examination (SEE), and a minimum of 40% (40 \nmarks out of 100) in the sum total of the CIE (Continuous Internal Evaluation) and SEE \n(Semester End Examination) taken together. \n• Continuous Internal Evaluation: \no Three Unit Tests each of 20 Marks (duration 01 hour) \no First test at the end of 5th week of the semester \no Second test at the end of the 10th week of the semester \no Third test at the end of the 15th week of the semester \no Two assignments each of 10 Marks \no First assignment at the end of 4th week of the semester \no Second assignment at the end of 9th week of the semester \no Group discussion/Seminar/quiz any one of three suitably planned to attain the \nCOs and POs for 20 Marks (duration 01 hours) \n• At the end of the 13th week of the semester The sum of three tests, two assignments, \nand quiz/seminar/group discussion will be out of 100 marks and will be scaled down to \n50 marks (to have less stressed CIE, the portion of the syllabus should not be ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":5}}}],["e43e6d0c-acbd-4007-929a-f4e69225ce5c",{"pageContent":" \ncommon /repeated for any of the methods of the CIE. Each method of CIE should have \na different syllabus portion of the course). \n• CIE  methods  /question  paper  is  designed  to  attain  the  different  levels  of  Bloom’s \ntaxonomy as per the Outcome defined for the course. \n• Semester  End  Examination:  Theory  SEE  will  be  conducted  by  University  as  per  the \nscheduled timetable, with common question papers for the subject (duration 03 hours) \no The  question  paper   will  be  set  for  100  marks.  Marks  scored  shall  be \nproportionally reduced to 50 marks \no The question paper will have ten questions. Each question is set for 20 marks. \no There will be 2 questions from each module. Each of the two questions is under \na module (with a maximum of 2 sub-questions). \no The students have to answer 5 full questions, selecting one full question from \neach module. Marks scored by the students will be proportionally scaled down \nto 50 marks ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":6}}}],["7de4bfff-8d53-4bbd-a51e-4f5513c14431",{"pageContent":" \n \n \nINDEX \nSubject: RESEARCH METHODOLOGY & INTELLECTUAL PROPERTY RIGHTS \nSubject Code: 21RMI56 \n \nSl. No Title Page No \n1 Introduction 1 - 16 \n2 Literature Review and Technical Reading, Attributions and Citations 17 - 40 \n3 Intellectual Property Rights, Patents and Process of Patenting 41 - 77 \n4 Copyrights and Related Rights and Trademarks 78 - 101 \n5 Industrial Design, Geographical Indications and Case studies on Patents 102 - 118 ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":7}}}],["c0062663-940c-4850-866e-9cb14363a352",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 1 \n \n \n \nMODULE 1: INTRODUCTION \n \nSyllabus \n \nMeaning  of  Research, Objectives  of  Engineering  Research,  and  Motivation  in  Engineering \nResearch, Types of Engineering Research, Finding and Solving a Worthwhile Problem. Ethics in \nEngineering Research, Ethics in Engineering Research Practice, Types of Research Misconduct, \nEthical Issues Related to Authorship. \n \n  \n \nMEANING OF RESEARCH \n \n• Research refers to a careful, well-defined (or redefined), objective, and systematic method \nof  search  for  knowledge,  or  formulation  of  a  theory  that  is  driven  by  inquisitiveness  for \nthat  which  is  unknown  and  useful  on  a  particular  aspect  so  as  to  make  an  original \ncontribution to expand the existing knowledge base. \n• Research involves formulation of hypothesis or proposition of solutions, data analysis, and \ndeductions; and ascertaining whether the conclusions fit the hypothesis. \n• Research is a process of creating, or formulating knowledge that does not yet exist. Thus \nresearch is an art of scientific investigation \nOBJECTIVES OF ENGINEERING RESEARCH \n \nThe purpose of research is to discover answers to questions through the application of scientific \nprocedures. The main aim of research is to find out the truth which is hidden and which has not \nbeen discovered as yet. Though each research study has its own specific purpose, we may think of \nresearch objectives as falling into a number of following broad groupings: \n1. Exploratory or Formulative research studies: To gain familiarity with a phenomenon or to \nachieve new insights into it \n2. Descriptive  research  studies:  To  portray  accurately  the  characteristics  of  a  particular \nindividual, situation or a group ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":9}}}],["f75a8eeb-d2ed-403f-acf7-4b4a4760b31e",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 2 \n \n \n3. Diagnostic research studies: To determine the frequency with which something occurs or \nwith which it is associated with something else \n4. Hypothesis-testing research studies: To test a hypothesis of a causal relationship between \nvariables \nThe objective of engineering research is \n \n• To solve new and important problems, and since the conclusion at the end of one’s research \noutcome has to be new, but when one starts, the conclusion is unknown. \n• Research objectives can sometimes be convoluted and difficult to follow. Knowing where \nand how to  find different types of information helps one solve  engineering problems, in \nboth academic and professional career. \n• Lack  of  investigation  into  engineering  guidelines,  standards,  and  best  practices  result  in \nfailures  with  severe  repercussions.  As  an  engineer,  the  ability  to  conduct  thorough  and \naccurate  research  while  clearly  communicating  the  results  is  extremely  important  in \ndecision making. \n• The  main  aim  of  the  research  is  to  apply  scientific  approaches  to  seek  answers  to  open \nquestions, and although each research study is particularly suited for a certain approach \n• The  objectives  of  engineering  research  should  be  to  develop  new  theoretical  or  applied \nknowledge and not necessarily limited to obtaining abilities to obtain the desired result. \n• The  objectives  should  be  framed  such  that  in  the  event  of  not  being  able  to  achieve  the \ndesired result that is being sought, one can fall back to understanding why it is not possible, \nbecause that is also a contribution toward ongoing research in solving that problem. \nMOTIVATION IN ENGINEERING RESEARCH \n \nThe possible motives may be the result of one or more of the following desires: \n \n• Studies have shown that intrinsic motivations like interest, challenge, learning, meaning, \npurpose, are linked to strong creative performance; \n• Extrinsic  motivating  factors  like  rewards  for  good  work  include  money,  fame,  awards, \npraise, and status are very strong motivators, but may block creativity. For example: ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":10}}}],["e95c86b7-40e5-4206-8683-c8366c81d9cc",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 3 \n \n \nResearch outcome may enable obtaining a patent which is a good way to become rich and \nfamous. \n• Influences from others like competition, collaboration, commitment, and encouragement \nare also motivating factors in research. For example: my friends are all doing research and \nso should I, or, a person that I dislike is doing well and I want to do better. \n• Personal motivation in solving unsolved problems, intellectual joy, service to community, \nand respectability are all driving factors. \nThe following factors would be a mix of extrinsic and intrinsic aspects: \n \n• Wanting to do better than what has been achieved in the world \n• Improve the state of the art in technology \n• Contribute to the improvement of society \n• Fulfillment of the historical legacy in the immediate socio-cultural context. \n \nSeveral other factors like government directives, funding opportunities in certain areas, and \nterms of employment, can motivate people to get involved in engineering research. \nTYPES OF ENGINEERING RESEARCH \n \nDescriptive versus Analytical: \n \n• Descriptive  research  includes  comparative  and  co  relational  methods,  and  fact-finding \ninquiries, to effectively  describe the present state of art. The researcher holds no control \nover the variables; rather only reports as it is. \n• Descriptive research also includes attempts to determine causes even though the variables \ncannot be controlled. \n• On  the  contrary,  in  analytical  research,  already  available  facts  for  analysis  and  critical \nevaluation are utilized. Some research studies can be both descriptive and analytical \nApplied versus Fundamental: \n \n• Research can either be applied research or fundamental (basic or pure) research. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":11}}}],["f6c343e1-65ce-4d21-8e6a-d281011744f5",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 4 \n \n \n• Applied  research  seeks  to  solve  an  immediate  problem  facing  the  organization,  whereas \nfundamental research is concerned with generalizations and formulation of a theory. \n• Research concerning natural phenomena or relating to pure mathematics are examples of \nfundamental research. \n• Research  to  identify  social  or  economic  trends,  or  those  that  find  out  whether  certain \ncommunications will be read and understood are examples of applied research. \n• The  primary  objective  of  applied  research  is  to  determine  a  solution  for  compelling \nproblems  in  actual  practice,  while  basic  research  is  aimed  at  seeking  information  which \ncould have a broad base of applications in the medium to long term. \nQuantitative versus Qualitative: \n \n• Quantitative  research  uses  statistical  observations  of  a  sufficiently  large  number  of \nrepresentative cases to draw any conclusions \n• While qualitative researchers rely on a few non representative cases or verbal narrative in \nbehavioral studies such as clustering effect in intersections in Transportation engineering \nto make a proposition. \nConceptual vs. Empirical \n \n• Conceptual research is that related to some abstract idea(s) or theory. \n• It is generally used by philosophers and thinkers to develop new concepts or to reinterpret \nexisting ones. \n• On  the  other  hand,  empirical  research  relies  on  experience  or  observation  alone,  often \nwithout due regard for system and theory. \n• It is data-based research, coming up with conclusions which are capable of being verified \nby observation or experiment. We can also call it as experimental type of research. \n• In such a research it is necessary to get at facts firsthand, at their source, and actively to go \nabout doing certain things to stimulate the production of desired information. \n• In such a research, the researcher must first provide himself with a working hypothesis or \nguess  as  to  the  probable  results.  He  then  works  to  get  enough  facts  (data)  to  prove  or \ndisprove his hypothesis. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":12}}}],["b44c7b88-456c-4b61-b685-2ae11f99279a",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 5 \n \n \n• He then sets up experimental designs which he thinks will manipulate the persons or the \nmaterials concerned so as to bring forth the desired information. \n• Such research is thus characterized by the experimenter’s control over the variables under \nstudy and his deliberate manipulation of one of them to study its effects. \n• Empirical research is appropriate when proof is sought that certain variables affect other \nvariables  in  some  way.  Evidence  gathered  through  experiments  or  empirical  studies  is \ntoday considered to be the most powerful support possible for a given hypothesis. \nENGINEERING RESEARCH PROCESS \n \nResearch process consists of series of actions or steps necessary to effectively carry out research \nand the desired sequencing of these steps. \n \n \n \n \nThe chart indicates that the research process consists of a number of closely related activities, as \nshown through I to VII. But such activities overlap continuously rather than following a strictly \nprescribed sequence \n1. Formulating the research problem: There are two types of research problems, viz., those \nwhich relate to states of nature and those which relate to relationships between ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":13}}}],["f40cce3e-9463-4bb1-88dd-c3320be60f3e",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 6 \n \n \nvariables. At the very outset the researcher must single out the problem he wants to study, \ni.e., he must decide the general area of interest or aspect of a subject-matter that he would \nlike to inquire into. \n2. Extensive literature survey: Once the problem is formulated, a brief summary of it should \nbe written down. It is compulsory for a research worker writing a thesis for a Ph.D. degree \nto write a synopsis of the topic and submit it to the necessary Committee or the Research \nBoard  for  approval.  At  this  juncture  the  researcher  should  undertake  extensive  literature \nsurvey connected with the problem. \n3. Development of working hypotheses: After extensive literature survey, researcher should \nstate in clear terms the working hypothesis or hypotheses. Working hypothesis is tentative \nassumption made in order to draw out and test its logical or empirical consequences. \nHypothesis should be very specific and limited to the piece of research in hand because it \nhas to be tested. The role of the hypothesis is to guide the researcher by delimiting the area \nof research and to keep him on the right track. It sharpens his thinking and focuses attention \non the more important facets of the problem. \n4. Preparing the research design: The research problem having been formulated in clear cut \nterms, the researcher will be required to prepare a research design, i.e., he will have to state \nthe conceptual  structure within  which  research  would  be conducted. The preparation  of \nsuch  a  design  facilitates  research  to  be  as  efficient  as  possible  yielding  maximal \ninformation. In other words, the function of research design is to provide for the collection \nof relevant evidence with minimal expenditure of effort, time and money. \n5. Determining sample design: The researcher must decide the way of selecting a sample or \nwhat is popularly known as the sample design. In other words, a sample design is a definite \nplan determined before any data are actually collected for obtaining a sample from a given \npopulation.  Sampling  can  be  done  choosing  a  particular  unit,  random  unit  selection, \nsystematic pattern, homogenous group (stratified  sampling), quota, cluster or area, multi \nstages and sequential. \n6. Collecting the data: In dealing with any real life problem it is often found that data at hand \nare inadequate, and hence, it becomes necessary to collect data that are appropriate. There \nare several ways of collecting the appropriate data which differ considerably in ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":14}}}],["cba9625d-9b37-48eb-a5d6-60c069eab3bf",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 7 \n \n \ncontext of money costs, time and other resources at the disposal of the researcher. Primary \ndata  can  be  collected  either  through  experiment  or  through  survey.  If  the  researcher \nconducts an experiment, he observes some quantitative measurements, or the data, with the \nhelp of which he examines the truth contained in his hypothesis. But in the case of a survey, \ndata can be collected by any one or more of the following ways by observation, through \npersonal interview, through telephonic interview, by mailing the questionnaire etc \n7. Execution  of  the  project:  It  is  a  very  important  step  in  the  research  process.  If  the \nexecution  of  the  project  proceeds  on  correct  lines,  the  data  to  be  collected  would  be \nadequate  and  dependable.  The  researcher  should  see  that  the  project  is  executed  in  a \nsystematic manner and in time. A careful watch should be kept for unanticipated factors in \norder to keep the survey as much realistic as possible. \n8. Analysis  of  data: After  the  data  have  been  collected,  the  researcher  turns  to  the  task  of \nanalyzing them. The analysis of data requires a number of closely related operations such \nas  establishment  of  categories,  the  application  of  these  categories  to  raw  data  through \ncoding,  tabulation  and  then  drawing  statistical  inferences.  The  unwieldy  data  should \nnecessarily  be  condensed  into  a  few  manageable  groups  and  tables  for  further  analysis. \nThus, researcher should classify the raw data into some purposeful and usable categories. \n9. Hypothesis-testing: After analyzing the data as stated above, the researcher is in a position \nto test the hypotheses, if any, he had formulated earlier. Do the facts support the hypotheses \nor they happen to be contrary? This is the usual question which should be answered while \ntesting hypotheses. Various tests, such as Chi square test, t-test, F-test, have been developed \nby statisticians for the purpose. The hypotheses  may be tested through the use of one or \nmore of such tests, depending upon the nature and object of research inquiry. Hypothesis-\ntesting will result in either accepting the hypothesis or in rejecting it. \n10. Generalizations and interpretation: If a hypothesis is tested and upheld several times, it \nmay be possible for the researcher to arrive at generalization, i.e., to build a theory. As a \nmatter of fact, the real value of research lies in its ability to arrive at certain generalizations ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":15}}}],["a85daac8-d0ce-4be8-97ca-28fc6d21154d",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 8 \n \n \n11. Preparation of the report or the thesis: Finally, the researcher has to prepare the report \nof what has been done by him. Writing of report must be done with great care keeping in \nview the following: \n• The layout of the report should be as follows: (i) the preliminary pages; (ii) the main text, \nand (iii) the end matter. \n• In   its   preliminary   pages   the   report   should   carry   title   and   date   followed   by \nacknowledgements and foreword. Then there should be a table of contents followed by a \nlist of tables and list of graphs and charts, if any, given in the report. \n• The main text of the report should have the following parts: \n(a) Introduction: It should contain a clear statement of the objective of the research and an \nexplanation of the methodology adopted in accomplishing the research. The scope of the \nstudy along with various limitations should as well be stated in this part. \n(b) Summary  of  findings:  After  introduction  there  would  appear  a  statement  of  findings \nand recommendations in non-technical language. If the findings are extensive, they should \nbe summarized. \n(c) Main report: The main body of the report should be presented in logical sequence and \nbroken-down into readily identifiable sections. \n(d) Conclusion: Towards the end of the main text, researcher should again put down the \nresults of his research clearly and precisely. In fact, it is the final summing up. \n• At  the  end  of  the  report,  appendices  should  be  enlisted  in  respect  of  all  technical  data. \nBibliography, i.e., list of books, journals, reports, etc., consulted, should also be given in \nthe end. Index should also be given specially in a published research report. \nFINDING AND SOLVING A WORTHWHILE PROBLEM \n \n• A researcher may start out with the research problems stated by the Supervisor or posed by \nothers that are yet to be solved. Alternately, it may involve rethinking of a basic theory, or \nneed to be formulated or put together from the information provided in a group of papers \nsuggested by the Supervisor. \n• Research scholars are faced with the task of finding an appropriate problem on which to \nbegin their research. Skills needed to accomplish such a task at the outset, while taking care \nof possible implications are critically important but often not taught ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":16}}}],["4d0f4941-604b-416a-9135-0cc61c442003",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 9 \n \n \n• Once  the  problem  is  vaguely  identified,  the  process  of  literature  survey  and  technical \nreading would take place for more certainty of the worthiness of the intended problem. \n• However,  an  initial  spark  is  ideally  required  before  the  process  of  literature  survey  may \nduly begin. \n• Sometimes,  an  oral  presentation  by  somebody  which  is  followed  by  asking  questions  or \nintrospection provides this perspective which reading papers do not. \n• At  other  times,  a  development  in  another  subject  may  have  produced  a  tool  or  a  result \nwhich  has  direct  implications  to  the  researcher’s  subject  and  may  lead  to  problem \nidentification. \n• A worthwhile research problem would have one or more attributes. \n• It could be non intuitive/counterintuitive even to someone who knows the area, something \nthat the research community had been expecting for sometime, a major simplification of a \ncentral  part  of  the  theory,  a  new  result  which  would  start  off  a  new  subject  or  an  area, \nprovides a new method or improves upon known methods of doing something which has \npractical applications, or a result which stops further work in an area. \n• The  researcher  has  to  be  convinced  that  the  problem  is  worthwhile  before  beginning  to \ntackle it because best efforts come when the work is worth doing, and the problem and/or \nsolution has a better chance of being accepted by the research community. \n• Not  all  problems  that  one  solves  will  be  great,  and  sometimes  major  advancements  are \nmade  through  solutions  to  small  problems  dealt  with  effectively.  Some  problems  are \nuniversally  considered  hard  and  open,  and  have  deep  implications  and  connections  to \ndifferent concepts. \n• The  reality  is  that  most  researchers  in  their  lifetime  do  not  get  into  such  problems. \nHowever, hard problems get solved only because people tackle them. \n• The question a researcher has to grapple with whether the time investment is worth it given \nthat the likely outcome is negative, and so it is a difficult personal decision to make. \n• At the same time, even in the case of failure to solve the intended hard problem, there may \nbe partial/side results that serve the immediate need of producing some results for ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":17}}}],["c703e731-f306-478e-963f-e5f6a1d66acf",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 10 \n \n \nthe dissertation. George Pólya (1887–1985) suggested a 4-step procedure for \nmathematical problem-solving, which is relevant to engineering researchers as well. \nThe recommended steps to solve a research problem are \n \n• Understand the problem, restate it as if it’s your own, visualize the problem by drawing \nfigures, and determine if something more is needed. \n• One  must  start  somewhere  and  systematically  explore  possible  strategies  to  solve  the \nproblem or a simpler version of it while looking for patterns. \n• Execute the plan to see if it works, and if it does not then start over with another approach. \nHaving delved into the problem and returned to it multiple times, one might have a flash \nof insight or a new idea to solve the problem. \n• Looking back and reflecting helps in understanding and assimilating the strategy, and is a \nsort of investment into the future. \nETHICS IN ENGINEERING RESEARCH \n \n• Ethics generally refers to a set of rules distinguishing acceptable and unacceptable conduct, \ndistinguishing right from wrong as such \n• Most people learn such norms in their formative years, but moral development continues \nthrough different stages of growth. Although everyone recognizes some common ethical \nnorms, but there is difference in interpretation and application. \n• Ethical  principles  can  be  used  for  evaluation,  proposition  or  interpretation  of  laws. \nAlthough  ethics  are  not  laws,  but  laws  often  follow  ethics  because  ethics  are  our  shared \nvalues. \n• International norms for the ethical conduct of research have been there since the adoption \nof the Nuremberg Code in 1947. \n• According to Whitbeck, the issues related to research credit dates back to the establishment \nof the British Royal Society (BRS) in the seventeenth century to refine the methods and \npractices of modern science. This event altered the timing and credit issues on the release \nof  research  results  since  BRS  gave  priority  to  whoever  first  submitted  findings  for \npublication, rather than trying to find out who had first discovered. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":18}}}],["72146861-dc67-48a5-9939-96593b78158d",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 11 \n \n \n• Whitbeck  raised  two  simple  but  significant  questions  to  address  the  tricky  issue  of \nauthorship in research: \no Who should be included as an author and \no The appropriate order of listing of authors. \n• In an increasingly interconnected world, the issue of co-authorship is very relevant to all \nresearchers. There are issues around individuals who may be deeply involved during the \nconduct of the research work, but may not contribute in the drafting phase \n• Government  bodies  and  universities  worldwide  have  adopted  certain  codes  for  research \nethics. Research ethics and the responsible conduct of research are often erroneously used \ninterchangeably. \n• Research  ethics  examines  the  appropriate  application  of  research  outcomes,  while \nresponsible conduct of research deals with the way the work is undertaken. \nETHICS IN ENGINEERING RESEARCH PRACTICE \n \n• Technological developments raise a whole range of ethical concerns such as privacy issues \nand  data  related  to  surveillance  systems,  and  so  engineering  researchers  need  to  make \nethical  decisions  and are  answerable  for  the  repercussions  borne  out  of  their  research  as \noutcomes. \n• The reason that ethics matter in data used in engineering research is usually because there \nis  impact  on  humans.  Certain  practices  may  be  acceptable  to  certain  people  in  certain \nsituations, and the reasons for unacceptability may be perfectly valid. \n• We  have  unprecedented  access  to  data  today,  and  unprecedented  options  for  analysis  of \nthese data and consequences in engineering research related to such data. Are there things \nthat are possible to do with this data, that we agree we should not do? \n• Engineering ethics gives us the rule book; tells us, how to decide what is okay to do and \nwhat is not. Engineering research is not work in isolation to the technological development \ntaking place. \n• Researchers make many choices that matter from an ethical perspective and influence the \neffects of technology in many different ways: \no By   setting   the   ethically   right   requirements   at   the   very   outset,   engineering \nresearchers can ultimately influence the effects of the developed technology. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":19}}}],["9153e299-18e3-4b09-a3b9-43cf7b204eed",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 12 \n \n \no Influence  may  also  be  applied  by  researchers  through  design  (a  process  that \ntranslates  the  requirements  into  a  blueprint  to  fulfill  those  requirements).  During \nthe design process, decision is to be made about the priority in importance of the \nrequirements taking ethical aspects into consideration. \no Thirdly,  engineering  researchers  have  to  choose  between  different  alternatives \nfulfilling similar functions. \n• Research outcomes often have unintended and undesirable side effects. It is a vital ethical \nresponsibility of researchers to ensure that hazards/risks associated with the technologies \nthat they develop, are minimized and alternative safer mechanisms are considered. \n• If  possible,  the  designs  should  be  made  inherently  safe  such  that  they  avoid  dangers,  or \ncome  with  safety  factors,  and  multiple  independent  safety  barriers,  or  if  possible  a \nsupervisory mechanism to take control if the primary process fails. \nTYPES OF RESEARCH MISCONDUCT \n \nEngineering  research  should  be  conducted  to  improve  the  state-of-the-art  of  technologies. \nResearch integrity encompasses dealing fairly with others, honesty about the methods and results, \nreplicating the results wherever possible so as to avoid errors, protecting the welfare of research \nsubjects, ensuring laboratory safety, and so forth. In order to prevent mistakes, peer reviews should \ntake place before the research output is published. \nThere may be different types of research misconduct as described, which can be summarized as \nfollows: \n• Fabrication  (Illegitimate  creation  of  data): Fabrication  is  the  act  of  conjuring  data  or \nexperiments  with  a  belief  of  knowledge  about  what  the  conclusion  of  the  analysis  or \nexperiments would be, but cannot wait  for the results possibly due to timeline pressures \nfrom supervisor or customers. \n• Falsification (Inappropriate alteration of data): Falsification is the misrepresentation or \nmisinterpretation, or illegitimate alteration of data or experiments, even if partly, to support \na  desired  hypothesis  even  when  the  actual  data  received  from  experiments suggest \notherwise. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":20}}}],["e22269a5-f4bc-49f5-bebb-2ff2ba2f1a62",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 13 \n \n \nFalsification  and  fabrication  of  data  and  results,  hamper  engineering  research  and  cause \nfalse  empirical  data  to  percolate  in  the  literature,  wreck trustworthiness  of  individuals \ninvolved, incur additional costs, impede research progress, and cause actual and avoidable \ndelays in technical advancement. \nMisleading  data  can  also  crop  up  due  to  poor  design  of  experiments  or  incorrect \nmeasurement practices. \n• Plagiarism  (Taking  other’s  work  sans  attribution): Plagiarism  takes  place  when \nsomeone uses or reuses the work (including portions) of others (text, data, tables, figures, \nillustrations or concepts) as if it were his/her own without explicit acknowledgement. \nVerbatim copying or reusing one’s own published work is termed as self-plagiarism and is \nalso an unacceptable practice in scientific literature. \nThe  increasing  availability  of  scientific  content  on  the  internet  seems  to  encourage \nplagiarism in certain cases, but also enables detection of such practices through automated \nsoftware packages. How are supervisors, reviewers or editors alerted to plagiarism? \n(i) Original author comes to know and informs everyone concerned. \n(ii) Sometimes a reviewer finds out about it during the review process. \n(iii) Or, readers who come across the article or book, while doing research. \n \nAlthough  there  are  many  free  tools  and  also paid  tools  available  that  one  can  procure \ninstitutional  license  of,  one  cannot  conclusively  identify  plagiarism,  but  can  only  get  a \nsimilarity score which is a metric that provides a score of the amount of similarity between \nalready published content and the unpublished content under scrutiny. \nHowever, a low similarity score does not guarantee that the document is plagiarism free. It \ntakes a human eye to ascertain whether the content has been plagiarized or not. \nIt  is  important  to  see  the  individual  scores  of  the  sources,  not  just  the  overall  similarity \nindex. Setting a standard of a maximum allowable similarity index is inadequate usage of \nthe tool. Patchwork plagiarism is more difficult to evaluate. \nThere  are  simple  and  ethical  ways  to  avoid  a  high  similarity  count  on  an  about  to  be \nsubmitted manuscript. Sometimes, certain published content is perfect for one’s research \npaper, perhaps in making a connection or fortifying the argument presented. The published \nmaterial is available for the purpose of being used fairly. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":21}}}],["e83a2260-1d0a-4c23-8dc9-b1fce62c8dbc",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 14 \n \n \nOne is not expected to churn out research outcomes in thin air. \nHowever, whatever is relevant can be reported by paraphrasing in one’s own words, that \nis, without verbatim copy. \nOne can also summarize the relevant content and naturally, the summary invariably would \nuse one’s own words. In all these cases, citing the original source is important. However, \nmerely because one has cited a source, it does not mean that one can copy sentences (or \nparagraphs) of the original content verbatim. \nA  researcher  should  practice  writing  in  such  a  way  that  the  reader  can  recognize  the \ndifference between the ideas or results of the authors and those that are from other sources. \nSuch a practice enables one to judge whether one is disproportionately using or relying on \ncontent from existing literature. \n• Other Aspects of Research Misconduct: Serious deviations from accepted conduct \ncould be construed as research misconduct. When there is both deception and damage, a \nfraud is deemed to have taken place. Sooner or later ethical violations get exposed. \nSimultaneous submission of the same article to two different journals also violates \npublication policies. \nAnother issue is that when mistakes are found in an article or any published content, they \nare generally not reported for public access unless a researcher is driven enough to build \non that mistake and provide a correct version of the same which is not always the primary \nobjective of the researcher. \nETHICAL ISSUES RELATED TO AUTHORSHIP \n \n• Academic  authorship  involves  communicating  scholarly  work,  establishing  priority  for \ntheir  discoveries,  and  building  peer-reputation,  and  comes  with  intrinsic  burden  of \nacceptance  of  the  responsibility  for  the  contents  of  the  work.  It  is  the  primary  basis of \nevaluation for employment, promotion, and other honors. \n• There  is  several  important  research  conduct  and  ethics  related  issues  connected  to \nauthorship of research papers and are summarized herewith in the context of engineering \nresearch. \n• Credit for research contributions is attributed in three major ways in research publications: \nby authorship (of the intended publication), citation (of previously ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":22}}}],["e31d9697-a470-4464-af54-2bc554258208",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 15 \n \n \npublished or formally presented work), and through a written acknowledgment (of some \ninputs to the present research). \n• Authorship establishes both accountability and gives due credit. A person is expected to be \nlisted as an author only when associated as a significant contributor in research design, data \ninterpretation, or writing of the paper. Including “guest” or “gift” (co-authorship bestowed \non someone with little or no contribution to the work) authors dilutes the contribution of \nthose who actually did the work, inappropriately inflates credentials of the listed authors, \nand is ethically a red flag highlighting research misconduct. \n• Sometimes, the primary author dubiously bestows co-authorship on a junior faculty or a \nstudent to boost their chances of employment or promotion, which can be termed as Career-\nboost authorship. \n• There is also an unfortunate malpractice of co-authorship that can be described as “Career-\npreservation authorship” wherein a head of the department, a dean, a provost, or other \nadministrators are added as Coauthors because of quid pro quo arrangement wherein the \nprincipal author benefits from a “good relation” with the superiors and the administrator \nbenefits  from  authorship  without  doing  the  required  work  for  it. Sometimes,  an  actual \ncontributor abstains from the list of authors due to no disclosed conflict of interest within \nthe organization. Such co-authorships can be termed as ghost co-authorship. Full disclosure \nof all those involved in the research is important so that evaluation can happen both on the \nbasis of findings, and also whether there was influence from the conflicts. \n• In another type of questionable authorship, some researchers list one another as coauthors \nas  a  reciprocal  gesture  with  no  real  collaboration  except  minimal  reading  and  editing, \nwithout truly reviewing the work threadbare. \n• Some  authors,  in  trying  to  acquire  a  sole-authored  work,  despite  relying  on  significant \ncontribution   to   the   research   work   from   others,   recognize   that   effort   only   by   an \nacknowledgment, thereby misrepresenting the contributions of the listed authors. \n• The unrecognized “author” is as a consequence, unavailable to readers for elaboration. \n• All  listed  authors  have  the  full  obligation  of  all  contents  of  a  research  article,  and  so \nnaturally, they should also be made aware of a journal submission by the corresponding \nauthor. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":23}}}],["826f6ab2-6d71-4296-8957-85fa8c480cae",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 16 \n \n \n• It  is  imperative  that  their  consent  is  sought  with  respect  to  the  content  and  that  they  be \nagreeable to the submission. \n• In case of misconduct like inappropriate authorship, while the perpetrator is easier to find, \nthe degree of appropriate accountability of the coauthors is not always obvious. Being able \nto quantify the contributions so as to appropriately recognize and ascertain the degree of \nassociated accountability of each coauthor, is appealing. \n• Double  submission  is  an  important  ethical  issue  related  to  authorship,  which  involves \nsubmission  of  a  paper  to  two  forums  simultaneously.  The  motivation  is  to  increase \npublication possibility and possibly decrease time to publication. Reputed journals want to \npublish  original  papers,  i.e.,  papers  which  have  not  appeared  elsewhere,  and  strongly \ndiscourage double submission. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":24}}}],["16166afe-c982-4697-92ca-bfe1f547330c",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 17 \n \n \nMODULE 2: LITERATURE REVIEW AND TECHNICAL READING, \nATTRIBUTIONS AND CITATIONS \nSyllabus \nLiterature Review and Technical Reading, New and Existing Knowledge, Analysis and Synthesis \nof  Prior  Art,  Bibliographic  Databases:  Web  of  Science,  Google  and  Google  Scholar,  Effective \nSearch: The Way Forward, Introduction to Technical Reading, Conceptualizing Research, Critical \nand  Creative  Reading,  Taking  Notes  While  Reading,  Reading  Mathematics  and  Algorithms, \nReading a Datasheet. \nAttributions  and  Citations:  Giving  Credit  Wherever  Due,  Citations:  Functions  and  Attributes, \nImpact of Title and Keywords on Citations, Knowledge Flow through Citation, Citing Datasets, \nStyles  for  Citations,  Acknowledgments  and  Attributions,  What  Should  Be  Acknowledged, \nAcknowledgments in, Books Dissertations, Dedication or Acknowledgments. \n \n \n \nLITERATURE REVIEW AND TECHNICAL READING \n \n• The primary goal of literature review is to know the use of content/ideas/approaches in the \nliterature to correctly identify the problem that is vaguely known beforehand, to advocate \na  specific  approach  adapted  to  understanding  the  problem,  and  to  access  the  choice  of \nmethods used. \n• It  also  helps  the  researcher  understand  clearly  that  the  research  to  be  undertaken  would \ncontribute something new and innovative. \n• The  quality  of  such  review  can  be  determined  by  evaluating  if  it  includes  appropriate \nbreadth and depth of the area under study, clarity, rigor, consistency, effective analysis. \nNEW AND EXISTING KNOWLEDGE \n \n• New knowledge in research can only be interpreted within the context of what is already \nknown, and cannot exist without the foundation of existing knowledge. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":25}}}],["c92b1399-28f3-4dd0-99f2-0343bc224537",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 18 \n \n \n• The  new  knowledge  can  have  vastly  different  interpretations  depending  on  what  the \nresearcher’s background, and one’s perception of that new knowledge can change from \nindifference to excitement (or vice versa), depending on what else one knows. \n• The  significance  can  normally  be  argued  from  the  point  of  view  that  there  is  indeed  an \nexisting problem and that it is known by looking at what already exists in the field. \n• The existing knowledge is needed to make the case that there is a problem and that it is \nimportant. \n• One  can  infer  that  the  knowledge  that  is  sought  to  be  produced  does  not  yet  exist  by \ndescribing what other knowledge already exists and by pointing out that this part is missing \nso that what we have is original. To do this, one again needs the existing knowledge: the \ncontext, the significance, the originality, and the tools. \n• Normally, one finds this knowledge by reading and surveying the literature in the field that \nwas established long ago and also about the more recent knowledge which is in fact always \nchanging. \n• With this foundation in place, the new knowledge that one will make will be much more \ndifficult to challenge than without that strong foundation in place which is ensured with \nlots of references to the literature. \n• Often,  but  not  always,  the  textbooks  contain  the  older  established  knowledge  and  the \nresearch  papers  the  newer  work.  Reading  the  textbooks  on  one’s  topic  provide  the \nestablished  knowledge  and  the  background  to  be  able  to  read  the  newer  work  usually \nrecorded in the research papers \n• The  research  paper  is  written  for  other  researchers  out  on  the  edge  of  knowledge and  it \nassumes that the reader already knows a lot in that field \n• The review process must explain how a research item builds on another one. An effective \nreview  of  literature  ensures  a  firm  foundation  for  advancing  knowledge,  facilitates \ntheoretical growth, eliminates as areas that might be of interest, and opens new avenues of \npossible work \n• Generally, a good literature survey is the first expectation of a supervisor from the research \nstudent, and when done well can create a good impression that the state of art in the chosen \nfield is well understood ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":26}}}],["fd168a47-95cf-4576-92df-dc01dad635e1",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 19 \n \n \n• A  good  literature  review  would  not  draw  hasty  conclusions  and  look  into  the  individual \nreferences to determine the underlying causes/assumptions/mechanisms in each of them so \nas to synthesize the available information in a much more meaningful way \n• A good literature survey is typically a two-step process as enumerated below: \no Identify  the  major  topics  or  subtopics  or  concepts  relevant  to  the  subject  under \nconsideration. \no Place  the  citation  of  the  relevant  source  (article/patent/website/data,  etc.)  in  the \ncorrect category of the concept/topic/subtopic \n• It could be that as one is reading and comes across something that one considers to be very \nimportant for one’s work. Naturally, one highlights that section or underlines it, or put an \nasterisk in the margin, so that one could come back to it later. Effectively, one is saying \nthat it is important and hence the marking so as not to forget it. \n• A  comprehensive  literature  survey  should  methodically  analyze  and  synthesize  quality \narchived work, provide a firm foundation to a topic of interest and the choice of suitable \nresearch  methodologies,  and  demonstrate  that  the  proposed  work  would  make  a  novel \ncontribution to the overall field of research. \nANALYSIS AND SYNTHESIS OF PRIOR ART \n \n• After collecting the sources, usually articles, intended to be used in the literature review, \nthe researcher is ready to break down each article and identify the useful content in it, and \nthen synthesize the collection of articles (integrate them and identify the conclusions that \ncan be made from the articles as a group). \n• A  researcher  should  analyze  the  relevant  information  ascertained  in  below  table  by \nundertaking the following steps: \no Understanding the hypothesis, \no Understanding the models and the experimental conditions used, \no Making connections, \no Comparing and contrasting the various information, and \no Finding out the strong points and the loopholes. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":27}}}],["c910db97-0d64-48e2-9049-895fe1f44431",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 20 \n \n \n \n \n \n• A literature survey grid of N topics and M sources is shown above to help crystallize the \ninformation in different categories. \n• It  is  always  good  to  be  suspicious  of  the  claims  made  in  the  sources  that  have  been \nthoroughly reviewed, especially in the case of tall claims. \n• If one is amenable to easily accept whatever is available in the literature, one may find it \ndifficult to go beyond it in one’s own work and may also fail to carefully analyze with a \nsuspicious bent of mind one’s own results subsequently. \n• The  goal  of  literature  survey  is  to  bring  out  something  new  to  work  on  through  the \nidentification  of  unsolved  issues,  determine  the  problems  in  the  existing  models  or \nexperimental designs, and present a novel idea and recommendations. \n• No matter where one gets the available information, one needs to critically evaluate each \nresource that the researcher wishes to cite. This methodology analyzes available materials \nto determine suitability for the intended research. \n• Relying on refereed articles published in scholarly journals or granted patents can save the \nresearcher a lot of time. \n• Here are a few criteria that could help the researcher in the evaluation of the information \nunder study: \no Authority: What are the author’s credentials and affiliation? Who publishes the \ninformation? \no Accuracy: Based on what one already knows about the topic or from reading other \nsources, does the information seem credible? Does the author cite other sources in \na reference list or bibliography, to support the information presented? \no Scope: Is the source at an appropriate comprehension or research level? ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":28}}}],["63336476-5a5c-43ea-bc5e-a2e923c16061",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 21 \n \n \nBIBLIOGRAPHIC DATABASES \n \n• “Bibliographic databases” refer to “abstracting and indexing services” useful for collecting \ncitation-related  information  and  possibly  abstracts  of  research  articles  from  scholarly \nliterature and making them available through search. \n• Performing simultaneous searches through such large databases may allow researchers to \novertly rely on any one database and be limited by the intrinsic shortcoming of any one of \nthem for quality research. \n• A researcher should be able to quickly identify the databases that are of use in the idea or \nproblem that one wishes to explore. \nWeb of Science \n \n• Web of Science (formerly known as ISI or Thomson Reuters) includes multiple databases, \nas well as specialized tools. \n• It is a good search tool for scholarly materials requiring institutional license and allows the \nresearcher  to  search  in  a  particular  topic  of  interest,  which  can  be  made  by  selection in \nfields that are available in drop down menu such as title, topic, author, address, etc. \n• The tool also allows sorting by number of citations (highest to lowest), publication date. \n• Put quotes around phrases, add more keywords, or use the “Refine Results” panel on the \nleft to narrow down the search by keyword, phrases in quotation marks, type of material \nsuch as peer-reviewed journal articles, date, language, and more. \n•  “Cited reference search” option enables a researcher to trace articles which have cited a \nformerly published paper. Using this element, it is possible to find how a familiar idea has \nbeen applied, improved, or extended subsequently. \n• A structured search like this that enables narrowing and refining what one is looking for is \neffective  to  ensure  that  the  results  throw  up  relevant  sources  and  time  spent  in  studying \nthose is likely to be well utilized. \n• Based on the researcher’s need the search result can be broadened or narrowed down using \nthe built-in fields provided in this website. \n• When  clicked  on  any  of  the  search  results,  this  website  provides  the  title  of  the  paper, \nauthors, the type of journal, volume, issue number and year of publication, abstract, ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":29}}}],["d7ea6c6c-4755-4873-b93b-9d8c0f914574",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 22 \n \n \nkeywords, etc., so that the researcher has enough information to decide if it is worthwhile \nto acquire the full version of the paper. \nGoogle and Google Scholar \n \n• Google is a great place to start one’s search when one is starting out on a topic. It can be \nhelpful  in  finding  freely  available  information,  such  as  reports  from  governments, \norganizations, companies, and so on. However, there are limitations: \no It’s a “black box” of information. It searches everything on the Internet, with no \nquality control—one does not know where results are coming from. \no There are limited search functionality and refinement options. \n• Google Scholar limits one’s search to scholarly literature. However, there are limitations: \no Some of the results are not actually scholarly. An article may look scholarly at \nfirst glance, but is not a good source upon further inspection. \no It is not comprehensive. Some publishers do not make their content available to \nGoogle Scholar. \no There are limited search functionality and refinement options. \n• There are search operators that can be used to help narrow down the results. These help \none to find more relevant and useful sources of information. \n• Operators can be combined within searches. Here are some basic ones that one can use: \no OR - Broadens search by capturing synonyms or variant spellings of a concept. \no Brackets/Parentheses ( ) - Gather OR’d synonyms of a concept together, while \ncombining them with another concept. \no Quotation marks “ ” - Narrow the search by finding words together as a phrase, \ninstead of separately. \no Site - limits the search to results from a specific domain or website. \no File type - limits the search to results with a specific file extension one could look \nfor pdf’s, PowerPoint presentations, Excel spreadsheets, and so on. \n• The Search Tools button at the top of the Google results gives you a variety of other \noptions, such as limiting the results by date. \n• To find the best resources on a topic, one should search in academic databases, in \naddition to Google. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":30}}}],["56759625-e6b7-4b09-8f7c-8ad161e360a9",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 23 \n \n \n• Databases provide access to journal articles and conference proceedings, as well as other \nscholarly resources. \n• One gets more relevant and focused results, because they have better quality control and \nsearch functionality. One should choose a database based on subject area, date coverage, \nand publication type. Interfaces vary between databases, but the search techniques remain \nessentially the same. \nEFFECTIVE SEARCH: THE WAY FORWARD \n \n• A scholarly publication is one wherein the published outcome is authored by researchers \nin a specific field of skill. Such work cites all source contents used and is generally peer \nreviewed for accuracy and validity before publication. \n• Essentially,  the  audience  for  such  works  is  fellow  experts  and  students  in  the  field.  The \ncontent is typically more complex and advanced than those found in general magazines. \n• While  most  of  the  engineering  researchers  need  to  refer  articles  that  appear  in  scholarly \njournals, books or other peer-reviewed sources, there is also a substantially useful content \nin  more  popular  publications.  These  are  informal  in  approach  and  aim  to  reach  a  large \nnumber of readers including both the experts in the field and also amateurs, but the content \nfocuses on news and trends in the field. \n• Research  outcomes  are  not  typically  first  disseminated  here  but  are  usually  meant  for \ngeneral reading. A researcher should use all search tools for comprehensive search. \n• A  researcher  must  consider  what  type  of  information  is  needed,  and  where  it  could  be \nfound. Not all information is available online. Some information is only available in print. \n• It can take time for scholarly and peer-reviewed information to be published. One might \nnot be able to find scholarly information about something currently being reported in the \nnews.  The  information  may  not  be  available,  or  studies  on  a  topic  of  interest to  the \nresearcher have not occurred. \n• Searching is an iterative process: \no Experiment with different keywords and operators \no Evaluate and assess results, use filters \no Modify the search as needed; and ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":31}}}],["f9631412-4d80-4e93-9f7c-cd2cd8cd758b",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 24 \n \n \no When relevant articles are found, look at their citations and references. \n• After  the  search  is  complete,  the  researcher  needs  to  engage  in  critical  and  thorough \nreading,  making  observation  of  the  salient  points  in  those  sources,  and  summarize  the \nfindings. \n• A detailed comparison and contrast of the findings is also required to be done. \n• This entire process may be needed to be done multiple times. \n• The conclusion of the entire process of literature survey includes a summary of the relevant \nand important work done, and also the identification of the missing links and the challenges \nin the open problems in the area under study. \n• One  must  note  that  the  literature  survey  is  a  continuous  and  cyclical  process  that  may \ninvolve the researcher going back and forth till the end of the research project. \n• It  is  very  important  to  not  lose  sight  of  the  purpose  of  an  extensive  search  or  literature \nsurvey, for it is possible to spend a very significant amount of one’s time doing so and \nactually falsely think that one is working hard. \n• Nothing will come of it unless one is an active reader and spends sufficient time to develop \none’s own ideas build on what one has read. \n• It  is  not  as  if  literature  survey  ends  and  then  research  begins,  for  new  literature  keeps \nappearing, and as one’s understanding of the problem grows, one finds new connections \nand related/evolving problems which may need more search. \nINTRODUCTION TO TECHNICAL READING \n \n• It  is  obvious  that  the  number  of  papers  relevant  to  a  particular  researcher  is  very  few, \ncompared to the actual number of research papers available from peer-reviewed technical \nsources. \n• It  is  also  important  to  know  where  to  read  from;  relying  on  refereed  journals  and  books \npublished by reputed publishers is always better than relying on easily available random \narticles off the web. \n• While  reading  an  engineering  research  paper,  the  goal  is  to  understand  the  technical \ncontributions  that  the  authors  are  making.  Given  the  abundance  of  journal  articles,  it  is \nuseful to adopt a quick, purposeful, and useful way of reading these manuscripts. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":32}}}],["e9d5b1e9-7e0b-4064-8ed6-8ddfef2a6e7f",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 25 \n \n \n• It is not the same as reading a newspaper. It may require rereading the paper multiple times \nand one might expect to spend many hours reading the paper. \n• Amount of time to be spent will get ascertained after an initial skimming through the paper \nto decide whether it is worth careful reading. \n• There will also be papers where it is not worth reading all the details in the first instance. \nIt  is  quite  possible  that  the  details  are  of  limited  value,  or  simply  one  does  not  feel \ncompetent to understand the information yet. \n• Start  out  the  skimming  process  by  reading  the  title  and  keywords  (these  are  anyways; \nprobably what caught the initial attention in the first place). If on reading these, it does not \nsufficiently seem to be interesting; it is better to stop reading and look for something else \nto read. \n• One should then read the abstract to get an overview of the paper in minimum time. Again, \nif  it  does  not  seem  sufficiently  important  to  the  field  of  study,  one  should  stop  reading \nfurther. \n• If  the  abstract  is  of  interest,  one  should  skip  most  of  the  paper  and  go  straight  to  the \nconclusions  to  find  if  the  paper  is  relevant  to  the  intended  purpose,  and  if  so,  then  one \nshould read the figures, tables, and the captions therein, because these would not take much \ntime but would provide a broad enough idea as to what was done in the paper. \n• If the paper has continued to be of interest so far, then one is now ready to delve into the \nIntroduction  section  to  know  the  background  information  about  the  work  and  also  to \nascertain why the authors did that particular study and in what ways the paper furthers the \nstate of the art. \n• The next sections to read are the Results and Discussion sections which is really the heart \nof the paper. One should really read further sections like the Experimental Setup/Modeling, \netc.,  only  if  one  is  really  interested  and  wishes  to  understand  exactly  what  was  done  to \nbetter understand the meaning of the data and its interpretation. \n• A researcher will always need to be searching for the relevant literature and keeping up to \ndate  with  it.  If  one  is  busy  with  a  small  project,  the  advisor might  just  give  a  single \nimportant  paper  to  read.  But  with  a  larger  one,  you  will  be  searching  for  one’s  own \nliterature to read. For this one will need a strategy as there is just too much work out there \nto read everything. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":33}}}],["ef9683e3-06a3-4e26-8ab9-70d438153113",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 26 \n \n \nCONCEPTUALIZING RESEARCH \n \n• The characteristics of a research objective are that it must have new knowledge at the center \nand  that  it  must  be  accepted by the  community of other  researchers  and  recognized  as \nsignificant. \n• Besides being original and significant, a good research problem should also be solvable or \nachievable. This requirement already asks us to think about the method and the tools that \ncould be used to obtain that new knowledge. \n• Now,  the  significance  and  the  originality  and  all  the  theory  that  we  read  and  tools  and \nmethods that we need to take on a problem, all of these normally come from the existing \nrecorded literature and knowledge in the field. \n• Coming up with a good research objective, conceptualizing the research that meets all of \nthese requirements is a tough thing to do. It means that one must already be aware of what \nis in the literature. That is, by the time one actually has a good research objective, one is \nprobably  already  an  expert  at  the  edge  of  knowledge  else  it  is  difficult  to  say  with \nconfidence that one has a good research objective. \n• So, when working at the research (Ph.D) level, one needs to be prepared to become that \nexpert, one needs to be continually reading the literature so as to bring together the three \nparts: \no Significant problem, \no The knowledge that will address it, and \no A possible way to make that new knowledge. \n• How  these  three  aspects  would  come  together  will  be  different  for  every  person  doing \nresearch  and  it  will  be  different  in  every  field,  but  the  only  way  to  be  that expert  is  by \nimmersing oneself in the literature and knowing about what already exists in the field. \n• However,  if  one  is  working  on  a  research  project  that  is  of  a  smaller  scope,  then \nconceptualizing the research is possibly too tough to do, and one does not have the time \nthat it takes to become that expert at the edge of knowledge. \n• In this case, the researcher needs the help of someone else, typically the supervisor who \nmay already be an expert and an active researcher in that field, and may advise on what a \ngood research objective might be. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":34}}}],["dca14c99-6214-4292-8798-54821aa8e1c9",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 27 \n \n \n• An established researcher in any field should be able to immediately point to the landmark \nliterature that one should read first. Otherwise one would need to spend a lot of time reading \nthe literature to discover. \nCRITICAL AND CREATIVE READING \n \n• Reading  a  research  paper  is  a  critical  process.  The  reader  should  not  be  under  the \nassumption  that  reported  results  or  arguments  are  correct.  Rather,  being  suspicious  and \nasking appropriate questions is in fact a good thing. \n• Have  the  authors  attempted  to  solve  the  right  problem?  Are  there simpler  solutions  that \nhave not been considered? What are the limitations (both stated and ignored) of the solution \nand are there any missing links? Are the assumptions that were made reasonable? Is there \na logical flow to the paper or is there a flaw in the reasoning? These need to be ascertained \napart from the relevance and the importance of the work, by careful reading. \n• Use of judgmental approach and boldness to make judgments is needed while reading. \n• Flexibility to discard previous erroneous judgments is also critical. \n• Additionally, it is important to ascertain whether  the data presented in the paper is right \ndata  to  substantiate  the  argument  that  was  made  in  the  paper  and  whether  the  data  was \ngathered and interpreted in a correct manner. \n• Critical reading is relatively easy. It is relatively easier to critically read to find the mistakes \nthan to read it so as to find the good ideas in the paper. Anyone who has been a regular \nreviewer of journal articles would agree to such a statement. \n• Reading creatively is harder, and requires a positive approach in search. In creative reading, \nthe idea is to actively look for other applications, interesting generalizations, or extended \nwork  which  the  authors  might  have  missed?  Are  there  plausible  modifications  that  may \nthrow up important practical challenges? One might be able to decipher properly if one \nwould  like  to  start  researching  an  extended  part  of  this  work,  and  what  should  be  the \nimmediate next aspect to focus upon. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":35}}}],["8e56dd17-5f99-401a-992c-840269435666",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 28 \n \n \nTAKING NOTES WHILE READING \n \n• A researcher reads to write and writes well only if the reading skills are good. \n• The bridge between reading and actually writing a paper is the act of taking notes during \nand shortly after the process of reading. \n• There is a well-known saying that the faintest writing is better than the best memory, and \nit applies to researchers who need to read and build on that knowledge to write building on \nthe notes taken. \n• Many researchers take notes on the margins of their copies of papers or even digitally on \nan article aggregator tool. \n• In each research paper, there are a lot of things that one might like to highlight for later use \nsuch as definitions, explanations, and concepts. \n• If  there  are  questions  of  criticisms,  these  need  to  be  written  down  so  as  to  avoid  being \nforgotten later on. Such efforts pay significantly when one has to go back and reread the \nsame content after a long time. \n• On completing a thorough reading, a good technical reading should end with a summary \nof the paper in a few sentences describing the contributions. \n• But  to  elucidate  the  technical  merit,  the  paper  needs  to  be  looked  at  from  comparative \nperspective with respect to existing works in that specific area. \n• A thorough reading should bring out whether there are new ideas in the paper, or if existing \nideas  were  implemented  through  experiments  or  in  a  new  application,  or  if  different \nexisting ideas were brought together under a novel framework. \n• Obviously, the type of contribution a paper is actually making can be determined better by \nhaving read other papers in the area. \nREADING MATHEMATICS AND ALGORITHMS \n \n• Mathematics is often the foundation of new advances, for evolution and development of \nengineering  research  and  practice.  An  engineering  researcher  generally  cannot  avoid \nmathematical derivations or proofs as part of research work. \n• In fact, these are the heart of any technical paper. Therefore, one should avoid skimming \nthem. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":36}}}],["9c584786-3f02-4203-bbf1-c0dcd2df8623",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 29 \n \n \n• By meticulous reading of the proofs or algorithms, after having identified the relevance of \nthe paper, one can develop sound understanding about the problem that the authors have \nattempted to solve. \n• Implementation  of  an  intricate  algorithm  in  programming  languages  such  as  C,  C++  or \nJava is prone to errors. \n• And  even  if  the  researcher  is  confident  about  the  paper  in  hand,  and  thinks  that  the \nalgorithm will work, there is a fair chance that it will not work at all. So one may wish to \ncode it quickly to check if it actually works. \nREADING A DATASHEET \n \n• Researchers in different fields of engineering will need to read certain types of documents. \nFor  example,  mechanical  and  civil  engineers  would  need  to  read  drawings  related  to \nmechanical  parts  and  buildings.  Researchers  in  the  field  of  electronics  need  to read \ndatasheets. \n• On occasions, researchers in other fields may also need to incorporate a certain electronic \npart in which case careful reading of the datasheet is imperative. \n• The same principles like initial skimming of the datasheet are required to ascertain whether \nfurther careful reading is needed. \n• Datasheets  are  instruction  manuals  for  electronic  components,  which  (hopefully)  details \nwhat  a  component  does  and  how  one  may  use  it.  Datasheets  enable  a  researcher  (or  a \nworking professional) to design a circuit or debug any given circuit with that component. \n• The first page of the datasheet usually summarizes a part’s function and features, basic \nspecifications, and usually provides a functional block diagram with the internal functions \nof the part. \n• A pin out provides the physical location of a part’s pins, with special mark for pin 1 so that \nthe part can be correctly plugged into the circuit. Some parts also provide graphs showing \nperformance versus various criteria (supply voltage, temperature, etc.), and safe region for \nreliable operation which should be carefully read and noted by the researcher. \n• One should be also in the lookout for truth tables which describe what sort of inputs provide \nwhat types of outputs, and also timing diagrams which lay out how and at what speed data \nis sent and received from the part. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":37}}}],["c44bd214-f96b-4c1a-907b-3d7d57f6756b",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 30 \n \n \n• Datasheets usually end with accurate dimensions of the packages a part is available in. This \nis useful for printed circuit board (PCB) layout. When working with a new part, or when \ndeciding which part to use in the research work, it is recommended to carefully read that \npart’s datasheet to come up with a bit of shortcut that may potentially save many hours later \non. \nATTRIBUTES AND CITATION: Giving credits wherever due \n \n• Academic writing, by definition, must follow certain rules and conventions. \n• Among the most important of these are the rules and conventions about citing, \nreferencing, attributing, and acknowledging the works of others. \n• That means giving proper credit wherever due. \n• Citing is the practice of quoting from, referring to other authors’ works and ideas in the \ntext of our work in such a way that the context is clear to the reader. \n• Referencing is the listing of the full publication details of a published work that is cited \nso as to give background information to the readers. \n• Acknowledgment in research publications indicates contributions to scientific work. \n• However, acknowledgment, attributions, and citations differ in the manner of their \napplication. \nCITATIONS: FUNCTIONS AND ATTRIBUTES \n \n• Citations (references) credit others for their work, while allowing the readers to trace the \nsource publication if needed. \n• Any portion of someone else’s work or ideas in papers, patents, or presentations must be \nused in any new document only by clearly citing the source. \n• This applies to all forms of written sources in the form of texts, images, sounds, etc. and \nfailure to do may be considered plagiarism \n• When a bibliography of previously published patents or papers is placed in the new \nworks of a researcher, a connection is established between the new and previous work. \n• As per relevance to context, the researcher provides due credit through the use of a \ncitation. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":38}}}],["3d784843-c400-41ed-b578-76247fbd90ea",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 31 \n \n \n• Citations  help  the  readers  to  verify  the  quality  and  importance  of  the  new  work  and \njustification  of  the  findings.  It  is  a  way  to  tell  readers  that  certain  material  in  the \nresearcher’s present work has come from another source and as an ethical responsibility; \nappropriate credit has been given to the original author or writer. \n• Materials that can be cited include journal papers, conference proceeding, books, theses, \nnewspaper articles, websites, or other online resources and personal communication. \n• Preferably, citations should be given at the end of a sentence or the end of a paragraph as \ncan be seen even in this particular paragraph. Citation must contain enough details so that \nreaders can easily find the referenced material. \n• A researcher needs to cite each source twice: \n(i) in-text citation, in the text of the article exactly where the source is quoted \nor paraphrased, and \n(ii) a second time in the references, typically at the end of the chapter or a book \nor at the end of a research article \n• LaTeX,   a   document   preparation   system   often   used   by   engineering   researchers   to \nautomatically  format  documents  that  comply  with  standard  formatting  needs,  is  very \neffective to track and update citations \n• There are three main functions of citation: \n(i) Verification  function:  Authors  have  a  scope  for  finding  intentional  or \nunintentional  distortion  of  research  or  misleading  statements.  Citation \noffers the readers a chance to ascertain if the original source is justified or \nnot, and if that assertion is properly described in the present work \n(ii) Acknowledgment function: Researchers primarily receive credit for their \nwork   through   citations.   Citations   play   crucial   role   in   promotion   of \nindividual  researchers  and  their  continued  employment.  Many  reputed \norganizations   and   institutes   provide   research   funding   based   on   the \nreputations of the researchers. Citations help all researchers to enhance their \nreputation and provide detailed background of the research work. \n(iii) Documentation  function:  Citations  are  also  used  to  document  scientific \nconcepts and historical progress of any particular technology over the years ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":39}}}],["2516daea-e295-42f0-a4fa-36db4c0dc39d",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 32 \n \n \n• Citations  are  the  currency  that  authors  would  wish  to  accumulate  and  the  technical \ncommunity gives them credit for these contributions. When other authors make citations, \nthey honor those who initiated the ideas \n• Authors  should  cite  sources  to  indicate  significance  of  the  work  to  the  reader.  Relevant \ncitations help authors develop an easily understandable argument and prevent the need to \nnavigate through work irrelevant to the reader’s interest areas \n• There  are  certain  cases  when  references  do  not  fulfill  the  actual  goal  of  citations  and \nacknowledgments, and thus do not benefit the reader. \no Spurious citations: In certain cases, when citation is not required or an appropriate \none is not found, if the author nevertheless goes ahead with including one anyways, \nit would be considered as a spurious citation \no Biased citations: When authors cite thework of their friends or colleagues despite \nthere being no significant connection between the two works, or when they do not \ncite  work  of  genuine  significance  because  they  do  not  wish  to  give  credit  in  the \nform of citation to certain individuals, then such actions can be classified as biased \ncitations. \no Self-citations: There is nothing wrong in citing one’s prior work if the citation is \nreally  relevant.  Self-citation  of  prior  papers  is  natural  because  the  latest  paper  is \noften a part of a larger research project which is ongoing \no Coercive citations: Despite shortcomings, impact factors remain a primary method \nof quantification of research. One side effect is that it creates an incentive for editors \nto indulge in coercion to add citations to the editor’s journal \nIMPACT OF TITLES AND KEYWORDS ON CITATION \n \n• The citation rate of any research paper depends on various factors including significance \nand  availability  of  the  journal,  publication  types,  research  area,  and  importance  of  the \npublished research work. \n• Other factors like length of the title, type of the title, and selected keywords also impact \nthe citation count. Title is the most important attribute of any research paper. \n• It is the main indication of the research area or subject and is used by researcher as a source \nof information during literature survey. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":40}}}],["826acdad-53dd-43a8-a677-43d7fa87e1df",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 33 \n \n \n• Title plays important role in marketing and makes research papers traceable. \n• A  good  title  is  informative,  represents  a  paper  effectively  to  readers,  and  gains  their \nattention. Some titles are informative but do not capture attention of readers, some titles \nare attractive but not informative or related to the readers’ research area. \n• The download count and citation of a research paper might be influenced by title. \n• There are three different aspects which provide a particular behavior to the title: \no Types of the title, \no Length of the title, and \no Presence of specific markers \n• Longer titles mainly include the study methodology and/or results in more detail, and so \nattract more attention and citations \n• In general, titles containing a question mark, colon, and reference to a specific geographical \nregion  are  associated  with  lower  citation rates,  also  result-describing  titles  usually  get \ncitations than method-describing titles. \n• Additionally, review articles and original articles usually receive more citations than short \ncommunication articles. \n• At least two keywords in the title can increase the chance of finding and reading the article \nas well as get more citations. \n• Keywords represent essential information as well as main content of the article, which are \nrelevant  to  the  area  of  research.  Search  engines,  journal,  digital  libraries,  and indexing \nservices use keywords for categorization of the research topic and to direct the work to the \nrelevant audience. \nKNOWLEDGE FLOW THROUGH CITATION \n \n• Knowledge  flows  through  verbal  communications,  books,  documents,  video,  audio,  and \nimages, which plays a powerful role in research community in promoting the formulation \nof new knowledge. \n• In engineering research, knowledge flow is primarily in the form of books, thesis, articles, \npatents,  and  reports.  Citing  a  source  is  important  for  transmission  of  knowledge  from \nprevious work to an innovation ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":41}}}],["d9c3f483-2b98-4d16-9183-a4f4348c04d6",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 34 \n \n \n• Knowledge flow happens between co-authors during research collaboration, among other \nresearchers   through   their   paper   citation   network,   and   also   between   institutions, \ndepartments, research fields or topics, and elements of research \n \n \n• If  paper  A  is  cited  by  paper  B,  then  knowledge  flows  through  citation  networks  across \ninstitutions. \n• The  complex  interdisciplinary  nature  of  research  encourages  scholars  to  cooperate  with \neach  other  to  grab  more  advantages  through  collaboration,  thereby  improving  quality  of \nthe research \n• The  below  figure  shows  a  relationship  between  co-authorship  and  different  types  of \ncitations.  Three  articles  (X,  Y,  and  Z)  and  five  references  (X1,  X2,  X3,  Y1,  and  Y2)  of \narticle X and Y, respectively, are considered. A, B, and C are authors of article X, and D, \nE, F, G, and also A are authors of article Y. Article Z has two authors H and E. References \nX1, X2, X3, Y1, and Y2 have authors (A, P), (H, R), (D), (Q, B, F), and (R), respectively. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":42}}}],["921727dc-2360-4c53-bbe1-92addca03b3e",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 35 \n \n \n \n \n \nCITING DATASETS \n \n• The nature of engineering research has evolved rapidly and now relies heavily on data to \njustify claims and provide experimental evidences and so data citations must fetch proper \ncredit to the creator of the dataset as citations of other objects like research articles. \n• Data citations should have provisions to give credit and legal attribution to all contributors, \nenable identification and access, while recognizing that a specific style may not apply to \nall data. \n• Ascertaining  the  ownership  of  data  can  be  a  complicated  issue  especially  with  large \ndatasets, and issues of funding can also make it a difficult matter. \n• A researcher should obtain necessary permission for using data from a particular source. \n• Citations related to datasets should include enough information so that a reader could find \nthe same dataset again in the future, even if the link provided no longer works. \n• It is proper to include a mixture of general and specific information to enable a reader to \nbe certain that the search result is the same dataset that was sought. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":43}}}],["a3423919-2b2d-4f1e-af70-2ac04bc2b03c",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 36 \n \n \n \n \n \nSTYLES FOR CITATION \n \n• Citation  styles  differ  primarily  in  the  order,  and  syntax  of  information  about  references, \ndepending on difference in priorities attributed to concision, readability, dates, authors, and \npublications. \n• Some of the most common styles for citation \nASCE style (American Society of Civil Engineers) \n \nIEEE style (Institute of Electrical and Electronics Engineers \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":44}}}],["1e3ef94d-4f54-4b9e-9c03-e828bc231bbb",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 37 \n \n \nACKNOWLEDGMENT AND ATTRIBUTION \n \n• Acknowledgment section is a place to provide a brief appreciation of the contribution of \nsomeone or an organization or funding body to the present work. \n• If no particular guideline is available for the intended publication, then it can be introduced \nat the end of the text or as a footnote. \n• Acknowledgment  is  a  common  practice  to  recognize  persons  or agencies  for  being \nresponsible in some form or other for completion of a publishable research outcome. \n• Acknowledgment  displays  a   relationship  among  people,   agencies,  institutions,  and \nresearch.  In  some  case,  certain  individuals  may  help  in  the  research  work  but  may  not \ndeserve  to  be  included  as  authors.  As  a  sign  of  gratitude,  such  contributions  should  be \nacknowledged \n• Acknowledgments and attributions are also very important in the publications of journal \nor conference papers. Giving proper credit wherever it is due is very important and even if \nthe contribution is minor, it should not be neglected. \n• In   engineering   research,   acknowledgments   are   meant   for   participating   technicians, \nstudents,  funding  agency,  grant  number,  institution,  or  anyone  who  provide  scientific \ninputs, shared unpublished results, provided equipment, or participated in discussions. \nWHAT SHOULD BE ACKNOWLEDGED \n \n• Every author should know that what should/should not be acknowledged. \n• Author  should  acknowledge  quotation,  ideas,  facts, paraphrasing,  funding  organization, \noral discussion or support, laboratory, and computer work. \n• Quotation:  In  technical  writing  such  as  in  the  field  of  engineering,  quotes  are  used  very \nrarely. Quotations are of two types: \no Direct quotations are used when author use actual words or sentences in the same \norder  as  the  original  one.  Author  should  use  quotation  marks  for  the  words  or \nsentences with proper acknowledgment. \no Indirect quotation summarizes or paraphrases the actual quote. In such cases, it is \nimportant to acknowledge with proper name and date. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":45}}}],["78fc5676-167c-4512-966e-64f9205a8b8c",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 38 \n \n \n• Authors  should  acknowledge  people  who  give  appropriate  contribution  in  their  research \nwork.  Non-research  work  contributions  are  not  generally  acknowledged  in  a  scientific \npaper  but  it  may  be  in  a  thesis.  Persons  must  be  acknowledged  by  authors,  who  gave  a \nscientific  or  technical  guidance,  take  part  in  some  discussions,  or  shared  information  to \nauthor.  Authors  should  acknowledge  assistants,  students,  or  technicians,  who  helped \nexperimentally and theoretically during the research work. \n• If the researcher received grant from a funding agency and if those funds were used in the \nwork  reported  in  the  publication,  then  such  support  should  always  be  acknowledged  by \nproviding  full  details  of  the  funding  program  and  grant  number  in  the  acknowledgment \nsection. The authors should also gratefully acknowledge use of the services and facilities \nof any center or organization with which they are not formally affiliated to. \n• An example of acknowledgment of grant received is as follows: \n \n \n \n• Many technical journals explicitly discourage authors to thank the reviewers in their article \nsubmissions. This could be construed as favoritism or an attempt to encourage reviewers \nto accept their manuscript for reasons other than scientific merit. \n• Acknowledging that results have been presented elsewhere: If the results were presented \nas  an  abstract  in  a  journal,  then  there  should  be  a  suitable  citation.  If  the  results  were \npresented as part of scientific meeting, symposium, or other gathering, then some relevant \ninformation should be provided. \n• At the very least, the name of the gathering and year should be cited. Other helpful items \ninclude  the  location  of  the  gathering  (city  and  state  or  country)  and  the  full  date  of  the \noccasion. \n• By acknowledging all help received in one’s research work, the author(s) demonstrate \nintegrity as a researcher, which in turn encourages continued collaboration from those who \nhelped out in different ways. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":46}}}],["7ad85185-1b73-4ed8-8d85-fa4fd1895e09",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 39 \n \n \n• Failure to acknowledge funding may result in the discontinuation of current funding and/or \nineligibility to receive future funding for a certain number of years or indefinitely. \nACKNOWLEDGEMENTS IN BOOKS / DISSERTATION \n \n• A page of acknowledgments is usually included at the beginning of a thesis/ dissertation \nimmediately following the table of contents. \n• These  acknowledgments  are  longer  than  the  one  or  two  sentence  statements  in  journal \npapers or articles in conference proceedings. \n• These  detailed  acknowledgments  enable  the  researcher  to  thank  all  those  who  have \ncontributed  in  completion  of  the  research  work.  Careful  thought  needs  to  be  given \nconcerning those whose inputs are to be acknowledged and in what order. \n• Generally,  one  should  express  appreciation  in  a  concise  manner  and  avoid  emotive \nlanguage. \n• The  following  are  often  acknowledged  in  these  types  of  acknowledgments:  main \nsupervisor,  second  supervisor,  peers  in  the  lab,  other  academic  staff  in  the  department, \ntechnical  or  support  staff  in  the  department,  colleagues  from  other  departments,  other \ninstitutions, or organizations, former students, family, and friends \n \n \nDEDICATION OR ACKNOWLEDGEMENTS \n \n• Dedication is almost never used in a journal paper, an article in conference proceedings, or \na patent, and it is used exclusively in larger documents like books, thesis, or dissertations. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":47}}}],["c616b255-e7d5-4383-b156-e03dc3a251ec",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 40 \n \n \n• While acknowledgments are reserved for those who helped out with the book in some way \nor another (editing, moral support, etc), a dedication is to whomever the author would like \nit to be dedicated to, whether it is the author’s mother, the best friend, the pet  dog,  or \nAlmighty  God.  And  yes,  it  is  possible  to  dedicate  something  to  someone  while  also \nmentioning them in the acknowledgments. \n• For example, one may dedicate a book to one’s spouse, but acknowledge them for being \nthe moral support and putting up with when one gets stressed. \n• The acknowledgments in technical books can be sometimes as brief as the ones in journal \narticles. \n• The acknowledgment section of a technical report may be a paragraph that is longer than \na journal paper but shorter than dissertations. \n• Generally, the length of the acknowledgment may have some correlation with the length \nof the document. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":48}}}],["760e99ab-ac75-4819-8bba-22d193f030fa",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 41 \n \n \nMODULE 3: INTELLECTUAL PROPERTY RIGHTS, PATENTS AND \nPROCESS OF PATENTING \nSyllabus \nIntroduction to Intellectual Property: Role of IP in the Economic and Cultural Development of the \nSociety, IP Governance, IP as a Global Indicator of Innovation, Origin of IP, History of IP in India, \nMajor Amendments in IP Laws and Acts in India. \nPatents:  Conditions  for  Obtaining  a  Patent  Protection,  To  Patent  or  Not  to  Patent  an  Invention, \nRights  Associated  with  Patents,  Enforcement  of  Patent  Rights,  Inventions,  and  Eligible  for \nPatenting, Non-Patentable Matters, Patent Infringements, Avoid Public Disclosure of an Invention \nbefore Patenting. \nProcess  of  Patenting: Prior  Art  Search,  Choice  of  Application  to  be  Filed,  Patent  Application \nForms, Jurisdiction of Filing Patent Application, Publication, Pre-grant Opposition, Examination, \nGrant  of  a  Patent,  Validity  of  Patent  Protection,  Post-grant  Opposition,  Commercialization  of  a \nPatent, Need for a Patent Attorney/Agent, Can a Worldwide Patent be Obtained, Do I Need First \nto  File  a  Patent  in  India,  Patent  Related  Forms,  Fee Structure,  Types  of  Patent  Applications, \nCommonly Used Terms in Patenting, National Bodies Dealing with Patent Affairs, Utility Models \n \n  \n \nINTRODUCTION TO INTELLECTUAL PROPERTY \n \n• Intellectual  Property  (IP)  is  the  terminology  attributed  to  intangible  assets  having \ncommercial  value,  and arising  from  human  intelligence,  creativity,  and  imagination,  but \ntypically lacking physical form. \n• Intellectual Property Rights (IPR) is the privileges accorded to the creator/inventor (of IP) \nin conformance with the laws. These rights are given to the creator/inventor in exchange \nfor  revealing  the  process  of  creation/invention  in  the  public  domain.  The  inventor  is \nconferred  with  the  special  rights  to  use,  sell,  distribute,  offering  for  sale and  restricting \nothers from using the invention without his prior permission ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":49}}}],["02dfa018-2104-445d-9aac-fb7d4be80b45",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 42 \n \n \n• Broadly, IP comprises of two branches i.e. Copyrights and Related Rights and Industrial \nProperty Rights. \no Copyrights  and  Related  Rights  refer  to  the  creative  expressions  in  the  fields  of \nliterature  and  art,  such  as  books,  publications,  architecture,  music,  wood/stone \ncarvings, pictures, portrays sculptures, films and computer-based \nsoftware’s/databases. \no The  Industrial  Property  Rights  refer  to  the  Patents,  Trademarks,  Trade  Services, \nIndustrial Designs and Geographical Indications \n• Copyright:  Copyright  is  the  right  bestowed  on  the  owner  or  creator  in  relation  to \npublication,  and  distribution  of  a  piece  of  writing,  music,  picture  or  related  works. \nCopyright  also  applies  to  technical  contents  such  as  software,  datasheets  and  related \ndocuments. \n• Patents: A  patent  is  a  legal  record  that  bestows  the  holder  the  exclusive  right  over  an \ninvention as per the claims, in a limited geographical domain and for a limited duration by \nthwarting  possible  interested  parties  from  any  form  of  manufacture,  use  or  sale  of  the \nproduct or outcome of the invention \n• Trademarks: A  trademark  is  a  sign  that  suitably  differentiates  the  owner’s  goods  or \nservices from those of others \n• Trade services: Any services in relation to trade or any trade related financing, lending or \nother financial accommodation provided(or to be provided) by the bank, including but not \nlimited to issuance/amendment of letter of credit, document arrival under letter of credit, \napplication for negotiation and inquiries etc., \n• Industrial   Designs:   An   industrial   design   protection   is   related   to   certain   specific \nornamental  shapes  associated  with  products  whose  duplication  the  owner  may  wish  to \nprevent \n• Geographical  Indications: A  geographical  indication  (GI)  is  a  name  or  sign  used  on \nproducts which corresponds to a specific geographical location or origin. Items that meet \ngeographical  origin  and  quality  standards  may  be  endorsed  with  a  government-issued \nstamp which acts as official certification of the origins and standards of the product. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":50}}}],["4b24c592-3196-4638-9b62-d264f5572eb1",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 43 \n \n \nROLE OF IP IN THE ECONOMIC AND CULTURAL DEVELOPMENT OF THE \nSOCIETY \n• Creativity being the keystone of progress, no civilized society can afford to ignore the basic \nrequirement of encouraging the same. The economic and social development of a society \nis largely dependent on creativity. \n• The  protection  provided  by  the  IPR  to  the  creators/innovators  is  in  fact  an  act  of \nincentivization for encouraging them to create more and motivates others to create new. \n• However,  if  IPR  is  practiced  rigidly,  it  may  have  a  negative  impact  on  the  progress  of \nsociety. For example, compliance with the Trade-Related Aspects of Intellectual Property \nRights (TRIPS) Agreement has affected the farming community as they are unable to store \nseeds  for  the  next  crop.  Multinational  companies  regulate  the  price  of  seeds,  which  is \ngenerally beyond the reach of a majority of the farmers. \n• To  circumvent  the  negative  impact  of  IPR,  certain  laws,  exceptions  and  limitations \nassociated with IPR have been enacted to maintain a balance between the interests of the \ncreators/inventors and the community. \n• For  example,  farmers  rights  under  the  Protection  of  Plant  Varieties  and  Farmers  Rights \n(PVP&FR) Act, 2001 entitles them to many privileges, such as Rights on seeds provides \nrights  to  the  farmers  to  save  seeds,  use  seeds  and  share,  exchange  or  sell  seeds  to other \nfarmers. \n• Right to  protection  against  accusations  of  infringement  protects  the  farmers  from \ninfringement  and  other  legal  accusation  levied  upon  them  due  to  his  legal  ignorance  in \nusing other‘s plant varieties. \n• The use of copyrighted material for education and religious ceremonies is exempted from \nthe operation of the rights granted in the Copyright Act. \n• Similarly,  a  patent  can  be  revoked  in  favor  of  compulsory  licensing  by  the  government \nduring an emergency or a natural calamity. \n• In addition, if an invention/creation is not in the interest of society, it is not registered by \nthe government for grant of any rights associated with IP. For example, cloning of human \nembryos is banned for IP protection, and so is the creation of super microbial pathogens, \nwhich can play havoc with human lives. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":51}}}],["a23daf8f-c20a-422b-aaf9-420b021a7714",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 44 \n \n \nIP GOVERNANCE \n \n• Since IP is an integral component of human society, each and every nation has dedicated \nagencies  for  laying  out  the  guidelines,  implementation  and  enforcement  of  IP  related \nmatters. \n• In India, many organizations/agencies deal with various aspects of IP. The governance of \nall categories of IP, except the Plant Variety and Farmers Rights Act, is carried out by the \nDepartment for Promotion of Industry & Internal Trade (DPIIT) under the aegis of Ministry \nof Commerce and Industry, Govt. of India. \n• There are a few other dedicated organizations/departments established by the government \nto     promote     patent-ecosystem     (patent     awareness,     patent     filing     and     patent \ncommercialization)  in  India  e.g.  Technology  Information  Forecasting  and  Assessment \nCouncil (TIFAC), National Research Development Corporation (NRDC) and Cell for IPR \nPromotion and Management (CIPAM), etc. \n• In order to create a hassle-free exchange of IP related activities amongst all the nations, it \nis imperative to have minimum standards of rules and regulations pertaining to all aspects \nof IP including rights, empowerment, exceptions, etc. \n• To achieve this goal, the United Nations (UN) has established an organization called the \nWorld Intellectual Property Organization (WIPO). \n• This agency is at the forefront of imparting knowledge about IP and governs international \nfiling  and  registration   of   IP  through  various  Conventions  and  Treaties  like  Paris \nConventions, Patent Cooperation Treaty (PCT), Rome Convention, Berne Convention, etc. \nIP AS A GLOBAL INDICATOR OF INNOVATION \n \n• IP, especially patents, is considered as one of the important cogs in assessing the innovation \nindex of a nation. \n• The global ranking organizations always have IP or a subset of IP as one of the parameters \nfor understanding and grading the Science, Technology and Innovation (STI)  ecosystem \nof a nation. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":52}}}],["65f83bc8-bdfd-4a19-967e-9fab4f51add7",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 45 \n \n \n• For  example,  the  Scimago  (publically  available  online  portal  which  ranks  journals  and \ncountries based on the data taken from Scopus) 2020 report ranked India at 4th position in \nthe parameter of a number of Research Publications and 50th position in the parameter of \nIntellectual Property Rights. \n• The global ranking can be improved by sensitizing the teaching and scientific communities \nabout the importance of IP and creating infrastructure for the same in the institutes of higher \nlearning. \nORIGIN OF IP \n \n• Though there is no official record of the origin of IP, it is believed that a rudimentary form \nof IP was being practiced around 500 Before the Common Era (BCE) in Sybaris, a state of \nGreece. \n• The natives of Sybaris were granted a year‘s protection for using their intellect to create \n―any new improvement in luxury. \n• A  practical  and  pragmatic  approach  for  IP  governance  started  taking  shape  in  medieval \nEurope. In 1623, Britain passed an Intellectual Property Legislation which entitled guilds \n(association of artisans or merchants) to create innovations and bring them to market for \ntrade purposes. \n• However,  this  legislation  brought  a  lot  of  resentment  amongst  the  public,  and  thus  was \nreplaced  by  the  Statute  of  Monopolies‘,  which  gave  the  rights  to  the  original \ncreator/inventor for 14 years. Another legislation, Statute of Anne‘, was passed by the \nBritish parliament in 1710. \n• This  legislation  aimed  at  strengthening  copyrights  by  providing  rights  to the  authors  for \nrecreation and distribution of their work. The work could also be renewed for another 14 \nyears. \n• By the end of the 18th century and the beginning of the 19th century, almost every country \nstarted laying down IP legislation to protect their novel inventions and creations. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":53}}}],["98861dc0-7148-4f58-981e-8c74ece837b0",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 46 \n \n \nHISTORY OF IP IN INDIA \n \nPatents \n \n• The history of the Indian patent system dates back to the pre independence era of British \nrule.  The  first  patent  related  legislation  in  India  was  Act  VI  of  1856,  adapted  from  the \nBritish  Patent  Law  of  1852.  The  objective  of  this  legislation  was  to  encourage  the \ninventions of new and useful manufactures. \n• At the beginning of the 20th century, all the earlier Acts related to inventions and designs \nwere done away with the introduction of “The Indian Patents and Designs Act” 1911 (Act \nII of 1911). \n• As  per  this  Act,  the  governance  of  patents  was  placed  under  the  management  of  the \nController  of  Patents.  In  the  next  three  decades,  many  amendments  were  introduced  for \nreciprocal   arrangements   with   other   countries   for   securing   priority   dates.   These \namendments dealt with; \no Use of invention by the government \no Patent of Addition \no Enhancing the term of the patent from 14 years to 16 years. \no Filing of Provisional Application and submission of Complete Application \nwithin 9 months from the date of filing the application. \n• Keeping  the  national  interest  in  mind,  recommendations  were  made  in  1949  as  a \nmodification  to  existing  “The  Indian  Patents  and  Designs  Act”.  And  those \nrecommendations are as follows \no Misuse of patents rights needs to be prevented. \no There  must  be  a  clear  indication  in  the  Act  that  food,  medicine  and  surgical  and \ncurative  devices  should  be  made  available  to  the  masses  at  the  cheapest  rate  by \ngiving reasonable compensation to the owner of the patent. \no Amendments in Sections 22, 23 and 23A of the Patent and Design Act, 1911 on the \nlines of the UK Patent Act. \n• These recommendations were introduced in the Act XXXII of 1950. \n• Two years later, another amendment (Act LXX of 1952) was made to provide compulsory \nlicensing of patents related to food, drugs and chemicals killing insects and ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":54}}}],["9e1c923f-86e9-43dd-9b42-9da2ca623326",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 47 \n \n \nmicrobes. Based on these amendments, a bill was presented in the parliament in 1953 but \nwas rejected. \n• In  1957  a  committee  was  constituted  and  the  committee  submitted  its  report  to  the \ngovernment in 1959. It comprised of two segments addressing \no General aspects of the patent laws, and \no Bill rejected back in 1953. \n• The revised patent legislation was submitted to the Lok Sabha in 1965. After many hiccups, \nclarifications and modifications the Patents Act, 1970 \n• In 1999, The Patents (Amendment) Act, 1999 was introduced providing for the filing of \napplications for  ̳Product Patents‘ in the areas of drugs, pharmaceuticals and agrochemicals \n• The  new  Patent  Act  also  included  provisions  for  the  grant  of  Exclusive  Market  Rights \n(EMRs)  for  the  distribution  and  sale  of  pharma  products  on  fulfillment  of  certain \nconditions.  The  second  amendment  to  the  1970  Act  was  made  through  the  Patents \n(Amendment) Act, 2002 (Act 38 of 2002). This Act introduced new Patent Rules, 2003, \nthus replacing the earlier Patents Rules, 1972. \n• With the rapidly changing scenario of IPR at a global level, a need was felt to further amend \nthe Patent Act, 1970. The highlight of the Patents (Amendments) Act 2005 were: \no Product patent for inventions in all fields of technology. \no New forms of known substances excluded to prevent ever greening of the patent. \no Rationalization of the opposition procedure. \no Introduction of pre-grant opposition by representation. \no Introduction of post-grant opposition. \no Compulsory license for export purposes. \no Compulsory license for manufacture. \no Extension of grace period from 6 months to 12 months for filing a patent, if \npublished in government exhibition. \n \nCopyrights and related rights \n \n• The concept of copyrights started way back in the 15th century. However, the actual need \nfor copyrights law was felt only after the invention of printers and copiers. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":55}}}],["7506ef9a-4635-41bb-9cba-24a95f4f1a41",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 48 \n \n \n• Before the invention of printers, writing could be created only once. It was highly laborious \nand the risk of errors was involved in the manual process of copying by a scribe. \n• The evolution of copyrights law in India occurred in three phases. First, two phases were \nenacted during the British Raj. \no In  the  first  phase,  the  concept  of  copyrights  was  introduced  in  1847  through  an \nenactment during the East India Company‘s regime. The term of copyrights was \nfor  the  lifetime  of  the  author  plus  seven  years  after  death.  The  registration  of \ncopyright  was  mandatory  for  the  enforcement  of  rights  under  the  Act.  The \ngovernment could grant a compulsory license to publish a book if the owner of the \ncopyright, upon the death of the author, refused to allow its publication. \no In the second phase Indian legislature, under the British Raj, enacted the Copyright \nAct of 1914 based on the  Imperial Copyright Act (1911) of the  UK. An  Act  for \ncriminal sanction for an infringement was introduced. \no The  third  phase  of  the  copyrights  regime  was  witnessed  post  independence.  The \nCopyright Act 1957 was enacted, superseding the Indian Copyright Act, 1914, in \norder to suit the provisions of the Berne Convention (1886). \n• The 1957 Act has been amended six times (1983, 1984, 1992, 1994 and 1999, 2012), to \ncomply  with  WIPO  Copyright  Treaty  (WCT),  1996  and  WIPO  Performances  and \nPhonograms Treaty (WPPT), 1996. \n• India  is  an  active  member  of  nearly  all  significant  international  Conventions/Treaties \nrelated  to  Copyright  Law  e.g.  the  Berne  Convention  as  modified  in  Paris  in  1971,  the \nUniversal Copyright Convention (1951), the Rome Convention (1961), WCT, WPPT and \n(TRIPS, 1995). \nTrademarks \n \n• The first statutory law related to Trademarks (TM) in India was the Trade Marks Act, 1940, \nwhich was carved out from the Trade Marks Act, 1938 of the UK. \n• It was followed by the incorporation of provisions of TM stated in the Indian Penal Code, \nCriminal Procedure Code and the Sea Customs Act. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":56}}}],["3d9ec74b-bcae-4567-bee0-f5e74053dfed",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 49 \n \n \n• Later on, Trade Marks Act, 1940 was rechristened as Trade and Merchandise Marks Act, \n1958. \n• Nearly four decades later, this Act was repealed by the Trade Marks Act, 1999. The need \nfor this occurred to comply with the provisions of the TRIPS. It is the current governing \nlaw related to register TM. \nGeographical Indications \n \n• India, as a member of WTO, enacted the Geographical Indications of Goods (Registration \nand Protection) Act, 1999. \n• It  came  into  force  with  effect  from  15th  September  2003.  Geographical  Indicators  have \nbeen defined under Article 22 (1) of the WTO Agreement on TRIPS. \nIndustrial Design \n \n• The  need  to  protect  Industrial  Designs  (ID)  was  recognized  in  the  18th  century  and  the \nIndian legislation enacted the “Patterns and Designs Act” in 1872 for the first time. The \nAct was enacted to protect the rights over the creation of the designs and novel patterns by \nthe inventors. \n• The Act was replaced by the British Patents and Designs Act in 1907, which later became \nthe basis for the Indian Patents and Designs Act, 1911. \n• In 1970, a separate Act was enacted for the patent, i.e. the Patent Act, 1970. The Indian \nPatents and Designs Act, 1911, remained in force for designs only. \n• Finally, in the year 2000, a dedicated Act for the ID was passed, which came into force in \n2001. \nSemiconductor Integrated Circuits and Layout designs \n \n• In  the  21st  century, Information  Technology  (IT)  has  revolutionized  the  economic  and \nsocietal growth of the world economy. \n• The rapid and tremendous scientific advancements in the field of IT resulted in the creation \nof  a  new  class  of  IP  called  the  Layout-Design  of  the  Semiconductor  Integrated  Circuits. \nVarious organizations, including WTO and TRIPS Agreement laid down rules ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":57}}}],["34cba5af-19a5-4b89-93bf-5cffcfa97f02",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 50 \n \n \nand regulations regarding the protection of Semiconductor Integrated Circuits and Layout \nDesigns (SICLD) \n• India being a member of the WTO also passed an Act called the SICLD Act, 2000. This \nAct is TRIPS compliant and fulfils the conditions of the TRIPS agreement (Articles. 35 to \n38) concerning the protection of SICLD. \nPlant varieties \n \n• Till 1970s, not much emphasis was laid on patentable matter originating from animals and \nplants. However, microbes and microbial products/processes were patentable. \n• To include all kinds of biological materials under the ambit of patent laws, a decision to \nenact a new sui generis law under the International Convention for the Protection of New \nVarieties of Plants (UPOV, 1978) and UPOV, 1991 was taken. \n• These decisions were taken to address environmental and public interest concerns. \n• The Indian Patents Act, 1970 excludes ―plants and animals in whole or any part thereof \nother than microorganisms‖ from patentability. \n• To comply with the mandate of Article 27.3 (b) of TRIPS, India adopted the Protection of \nPlant Varieties and Farmers Rights (PPV&FR) Act, 2001 as a sui generis regime protecting \nnot only new plant varieties but also farmer’s rights. \nBiodiversity conservation \n \n• In 1927 the “Indian Forest Act” and later on the “Wildlife Protection Act” 1972 was \nenacted to provide legal protection to biodiversity. \n• In 1988, the “National Forest Policy” was passed, which brought revolutionary changes in \nthe conservation and management of biodiversity. \n• The Acts and policies in force to protect the environment and biodiversity in India include \nMining and Mineral Development Regulation Act, 1957; Water (prevention and control of \npollution)  Act,  1974;  Forest  Conservation  Act,  1980;  Biological  Diversity Act,  2002; \nScheduled Tribes and other Traditional Forest Dwellers (recognition of rights) Act, 2006; \nNational  Biodiversity Action  Plan,  2009;  National Environment  Policy,  2006  and  a  few \nmore. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":58}}}],["e2bd1e9f-e46d-493b-85ad-30c45b920b73",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 51 \n \n \nMAJOR AMENDMENTS IN IP LAWS AND ACTS IN INDIA \n \nIn  order  to  fill  the  gaps  existing  in  the  IP  Laws  and  Acts  and  also  to  introduce  new \nguidelines/directions based on the current scenario (socially and politically), each nation keeps on \nupdating the concerned IP Laws and Acts. Some of the salient amendments made in Indian Laws \nand Acts on IPR are mentioned below: \nSl. No Year Historical Proceedings \nPATENTS \n1 1856 \n▪ The Act VI of 1856 on the protection of inventions based on the \nBritish Patent Law of 1852. \n2 1859 \n▪ Rights renamed as \"Exclusive Privileges\" \n▪ Time for the priority increased from 6 months to 12 months. \n \n3 \n \n1883 \n▪ The Patterns and Designs Protection Act \n▪ Introduction of novelty in the invention. \n▪ A grace period of 6 months for the disclosure of the invention. \n4 1911 \n▪ Renamed as \"The Indian Patent and Design Act\" and brought under \nthe management of \"Controller of Patents\" \n \n5 \n \n1930 \n▪ Introduction of Patent of Addition. \n▪ Government can use the invention if required. \n▪ The term of patent protection increased from 14 to 16 years. \n6 1945 \n▪ Filing of the provisional specification to secure the priority date. \n▪ Provision of submitting complete specifications within 9 months. \n \n7 \n \n1949 \n▪ Dedicated Committee formed under the leadership of Justice Bakshi \nTek  Chand  for reviewing patent  system  as  per the national \nenvironment. \n \n \n8 \n \n \n1950 \n▪ A working statement needs to be submitted at the Patent Office \n▪ Endorsement of the Patents with the words \"License of Right” on the \napplication made by the government so that the Controller could grant \nthe license. \n \n9 \n \n1952 \n▪ Provision of \"Compulsory License\" in the areas of food, medicine and \ninsecticide germicide. \n▪ Process for producing substance or any invention relating to surgical ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":59}}}],["fef284c1-78cb-4dd6-967f-f94029b1c634",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 52 \n \n \n \n  \nor curative devices. \n \n10 \n \n1965 \n▪ After incorporation of the recommendation submitted by the \ncommittee formed in 1949, a new bill was introduced in Lok Sabha \nbut was not cleared. \n11 1967 \n▪ Again submitted to Parliamentary Committee. \n▪ 1911 Act remained applicable for Designs. \n12 1970 ▪ The Patent Act, 1970 passed by the Parliament Committee. \n13 1972 \n▪ The Patent Act, 1970 came into force with the introduction of patent \nrules. \n14 1995 \n▪ TRIPS Agreement was signed by India and got transition period 1995- \n2005 to make domestic laws compatible with TRIPS. \n \n \n \n \n \n15 \n \n \n \n \n \n1999 \n▪ Introducing the provisions for receiving the applications for the product \npatent in the field of pharmaceuticals and agro-chemicals (mail box)*. \n▪ Provisions  for  the  grant  of  EMRs  for  distribution  and  sale  of  pharma \nproducts on fulfillment of certain conditions. \n▪ Grant  of  EMR  subject  to  certain  conditions.  After  the  amendments \n(1999)   the   product   patents   related   to   the   pharmaceuticals   and \nagrochemicals were kept on hold for examination till 2005. It is called \na mailbox or black box. \n \n \n16 \n \n \n2002 \n▪ The uniform 20-year term of the patent for all inventions. \n▪ Disclosure of source and geographical origin of biological material \nmade compulsory. \n▪ Establishment of Appellate Board. \n▪ Compulsory License provisions strengthened. \n17 2003 ▪ The Patents Rules, 2003 were introduced. \n \n \n18 \n \n \n2005 \n▪ Product patent for inventions in all fields of technology including \nfood, drug, chemicals and microorganisms. \n▪ New forms of known substances excluded in order to prevent the ever- \ngreening of the patent. \n▪ Introduction of the pre-grant opposition. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":60}}}],["c1e7ef81-2eb3-4bff-84f4-07a6d15aff0a",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 53 \n \n \n \n  \n▪ Introduction of post-grant opposition. \n▪ Extension of grace period to 12 months. \nCOPYRIGHTS AND RELATED RIGHTS \n1 1847 \n▪ The concept of Copyrights in India was introduced. \n▪ Validity - Lifetime+7 years but not more than 42 years in total. \n2 1914 \n▪ Copyright Act, 1914 was introduced based on the \n▪ Imperial Copyright Act, 1911 of UK. \n3 1957 \n▪ Copyright Act, 1914 was replaced with Copyright Act, 1957 with \nminor modifications \n4 1984 ▪ Penalty on second and subsequent conviction \n5 1994 ▪ Registration of Copyright Society made mandatory \n \n \n6 \n \n \n2012 \n▪ To comply with international Treaties for copyrights protection in the \ndigital environment. \n▪ Right to receive royalties for authors and music composers. \n▪ Exception of copyrights for physically disabled persons to access any \nwork. \n7 2013 ▪ Copyrights Rules, 2013 introduced. \nTRADEMARKS \n1 1940 ▪ Trademarks Registry established in India. \n2 1958 \n▪ The Trade and Merchandise Marks Act, 1958 enacted as per TRIPS \nAgreement. \n3 1999 \n▪ Amended to avoid duplicity and ensure securing proprietors trade and \ngoodwill \n4 2002 ▪ Trademarks Rules introduced. \n5 2010 \n▪ Amended to comply with Madrid Protocol for international filing. \n▪ Provision for filing opposition of the registration within 4 months.\\ \n6 2013 ▪ Trademarks Rules introduced. \nGEOGRAPHICAL INDICATIONS \n1 1999 \n▪ Being a member of the World Trade Organization (TRIPS), GI of \ngoods (Registration and Protection) Act was introduced. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":61}}}],["5c0ac0dc-55a2-48d5-a225-99a623529783",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 54 \n \n \n \n2 2002 \n▪ The Geographical Indications of Goods (Registration and Protection) \nRules, 2002 was introduced. \n3 2003 \n▪ The Geographical Indications of Goods (Registration & Protection) \nAct came into force \nINDUSTRIAL DESIGNS/ DESIGNS \n1 1872 \n▪ Patterns and Designs Protection Act introduced for the protection of \nnew patterns and designs. \n2 1888 \n▪ Amended as Invention and Design Act, 1988 for the protection of new \ninventions and designs. \n3 1911 ▪ Renamed as The Indian Patent and Design Act. \n4 2000 \n▪ Design Act, 2000 was introduced; separated from the Indian Patent \nand Design Act. \n5 2001 ▪ Design Rules, 2001 introduced. \nSEMICONDUCTOR INTEGRATED CIRCUITS: LAYOUT DESIGNS (SICLD) \n1 2000 \n▪ Semiconductor Integrated Circuits Layout Design (SICLD) Act 2000 \nintroduced as a signatory of WTO. \n2 2001 ▪ SICLD Rules introduced. \nPROTECTION OF PLANT VARITIES AND FARMERS RIGHTS \n1 1970 \n▪ The Patent Act, 1970 excluded plants and animals in whole or in any \npart from patentability (in 1999 amendments). \n2 1991 \n▪ Enactment of protection of new varieties of plants on sui generis basis \non the lines of UPOV. \n3 2001 \n▪ In line with TRIPS Agreement enactment of PPV&FR Act was \nintroduced. \nBIOLOGICAL DIVERSITY \n1 2002 \n▪ The Biological Diversity Act, 2002 introduced on the lines of the \nConvention on Biological Diversity (CBD, 1992). \n2 2003 \n▪ Establishment of National Biodiversity Authority. \n▪ Designation of repositories under the Biological Diversity Act \n3 2004 ▪ Biological Diversity Rules introduced. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":62}}}],["8590046a-96ab-4029-a947-787b07e8cbde",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 55 \n \n \nPATENTS \n• A patent is an exclusive right granted for an innovation that generally provides a new way \nof doing something or offers a new technical solution to a problem. \n• The  exclusive  right  legally  protects  the  invention  from  being  copied  or  reproduced  by \nothers. \n• In return, the invention must be disclosed in an application in a manner sufficiently clear \nand complete to enable it to be replicated by a person with an ordinary level of skill in the \nrelevant field. \nCONDITIONS FOR OBTAINING A PATENT PROTECTION \n \nThere is a set criterion, as provided in Section 2(1)(j) of the Patents Act, 1970, which must be \nfulfilled for a product or a process to qualify for the grant of a patent. The criterion encompasses: \n• Novelty - Not part of ‘State of the Art’. The innovation claimed in the patent application \nis new and not known to anybody in the world. In other words, the innovation is \no not in the knowledge of the public, \no not published anywhere through any means of publication and \no not be claimed in any other specification by any other applicant. \n• Inventive step - Not obvious to the person (s) skilled in the art. The innovation is \no a technical advancement over the existing knowledge, \no possesses economic significance and, \no not obvious to a person skilled in the concerned subject. \n• Capable of industrial application - For the benefit of society. The invention is capable of \nbeing made or used in any industry. \nTO PATENT OR NOT TO PATENT AN INVENTION \n \n• Once an invention has been developed, the inventor has to decide whether to exploit the \ninvention for personal benefits as provided by the statutory laws of the country or put it in \nthe public domain. \n• By  and  large,  the  inventor  prefers  the  former  option.  Only  a  miniscule  of  inventions  is \nplaced in the public domain without claiming any benefits. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":63}}}],["e4193eaf-8327-419f-bce5-af39e74d1ad6",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 56 \n \n \n• In  the  latter  case,  anybody  can  exploit  the  innovation  for  commercial  or  societal  benefit \nwithout paying any money to the inventor. \n• If the owner of an invention wishes to seek monetary gains, he can choose from either of \nthe  two  options,  i.e.  patenting  or  Trade  Secret.  If  the  inventor  is  absolutely  sure  of \nmaintaining the secrecy of invention for a very long period (maybe 100 years or more) and \nthe probability of reverse engineering of the technology is nil or very low, then the “Trade \nSecret” category is preferred. \n• If the invention has a short life span or can be kept secret only for a small period of time (a \ncouple of years or so) or the probability of reverse engineering is high once the invention \nis in the public domain, then the “patent” category is preferred. \nRIGHTS ASSOCIATED WITH PATENTS \n \n• As per the Court of Law, a patent owner has the right to decide who may or may not use \nthe patented invention. \n• In other words, the patent protection provided by the law states that the invention cannot \nbe  commercially  made,  used,  distributed,  imported,  or  sold  by  others  without  the  patent \nowner's consent. \n• The patent owner may permit other parties to use the invention on mutually agreed terms. \n• As a matter of fact, the patent rights are negative rights as the owner is restricting others \nfrom using the patent in any manner without his prior permission. \n• The patent holder may choose to sue the infringing party to stop illegal use of the patent \nand also ask for compensation for the unauthorized use. \nENFORCEMENT OF PATENT RIGHTS \n \n• Enforcement is the process of ensuring compliance with laws, regulations, rules, \nstandards and social norms. \n• Patent rights are usually enforced by the judicial courts. \n• The Court of Law has the authority to stop patent infringement. \n• However, the main responsibility for monitoring, identifying and taking action against \ninfringers of a patent lies with the patent owner. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":64}}}],["a785eac5-e811-4eca-88c2-aa8956247946",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 57 \n \n \nINVENTIONS ELIGIBLE FOR PATENTING \n \n• Patents may be granted for inventions/technologies in any field, ranging from a paper clip \nor ballpoint pen to a nanotechnology chip or a Harvard mouse (mouse with cancer genes). \n• It is a general belief that patents are awarded only to major scientific breakthroughs. But, \nit is not true. \n• In fact, the majority of patents are granted to inventions displaying an improvement over \nthe existing invention. \n• For  example,  many  patents  can  be  awarded  to  a  single  molecule  e.g.  penicillin’s  (an \nantibiotic  that  kills  microbes)  and  its  derivatives.  The  derivatives  are  made  by  making \nsubtle changes in the structure of the penicillin resulting in new/improved properties, such \nas acid stability or temperature stability or killing a wide range of microbes (germs). The \nnew antibiotic molecules, known as second, third or fourth generation penicillin’s can also \nbe patented. \n• In our daily life, we use many patented items, such as toothbrush, toothpaste, shoes, pen, \neyeglasses,  textiles,  mobile  phones,  wrist  watch,  bicycle,  scooter,  car,  television,  cold \ndrinks, beverages and many more. \n• It is not uncommon that many products contain several inventions (patents) e.g. the laptop \ncomputer  involves  hundreds  of  inventions  working  together.  Similarly,  cars,  mobile \nphones and televisions have many patented components. \nNON-PATENTABLE MATTERS \n \nIn the Patent Act, 1970, there are some exclusion (product and processes) that cannot be \npatented, such as: \n• Invention contrary to public morality - a method for human cloning, a method for \ngambling. \n• Mere discovery - finding a new micro-organism occurring freely in nature, laws of \ngravity. \n• Mere discovery of a new form of a known substance - use of aspirin for heart \ntreatment. Aspirin was patented for reducing fever and mild pains. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":65}}}],["b871bfd1-0be0-48f0-9716-0b44d9a8c29a",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 58 \n \n \n• Frivolous invention - dough supplemented with herbs, merely changing  the taste of the \ndough, 100 years calendar, and bus timetable. \n• Arrangement  or  rearrangement - an  umbrella  fitted  with  a  fan,  a  torch  attached  to  a \nbucket. \n• Inventions  falling  within  Section  20(1)  of  the  Atomic  Energy  Act,  1962 - inventions \nrelating  to  compounds  of  Uranium,  Beryllium,  Thorium,  Plutonium,  Radium,  Graphite, \nLithium and more as notified by the Central Government from time to time. \n• Literary,  dramatic,  musical,  artistic  work - books,  sculptures,  drawings,  paintings, \ncomputer  programmer,  mathematical  calculations,  online  chatting  method,  method  of \nteaching, method of learning a language as they are the subject matter of Copyright Act. \n1957. \n• Topography of integrated circuits - protection of layout designs of integrated circuits is \nprovided separately under the Semiconductor Integrated Circuit Layout Designs Act, 2000. \n• Plants and animals - plants and animals in whole or any part including seeds, varieties \nand species and essentially biological processes for the production or propagation of plants \nand animals are excluded from the scope of protection under patents. \n• Traditional knowledge - an invention which in effect is traditional knowledge or which \nis an aggregation or duplication of known properties of traditionally known components \nare also excluded. \nPATENT INFRINGEMENTS \n \n• Once the patent is granted to the applicant, he owns the right to use or exploit the invention \nin any capacity. If anyone uses the invention without the prior permission of the owner, \nthat act will be considered an infringement of the invention. Infringements can be classified \ninto two categories \n• Direct Infringement - when a product is substantially close to any patented product or in \na case where the marketing or commercial use of the invention is carried out without the \npermission of the owner of the invention. \n• Indirect Infringement - When some amount of deceit or accidental infringement happens \nwithout any intention of infringement. If such an unlawful act has been ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":66}}}],["5eed714b-3abe-4212-aa91-9514a119518d",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 59 \n \n \ncommitted, the patentee holds the right to sue the infringer through judicial intervention. \nEvery country has certain laws to deal with such unlawful acts. Following reliefs are made \navailable to the patentee: \no Interlocutory/interim injunction. \no Damages or accounts of profits. \no Permanent injunction \n \nAVOID PUBLIC DISCLOSURE OF AN INVENTION BEFORE PATENTING \n \n• Generally,  an  invention  that  has  been  either  published  or  publicly  displayed  cannot  be \npatented, as the claimed invention will lose the Novelty ‘criterion. \n• However,  under  certain  circumstances,  the  Patents  Act  provides  a  grace  period  of  12 \nmonths  for  filing  a  patent  application  from  the  date  of  its  publication  in  a  journal  or \npresentation in a reputed scientific society or exhibition. \n• Sometimes, disclosure of an invention before filing a patent application is unavoidable, \ne.g. selling your invention to a potential investor or a business partner who would like to \nknow complete details of the invention in order to judge its commercial value. In such a \ncase, it is advisable to sign a Non-Disclosure Agreement (NDA) or any other confidential \nagreement to safeguards your interest \nPROCESS OF PATENTING \n \n• In India, the process of grant of a patent is a lengthy procedure that may take anywhere 3- \n4 years or more. The major steps involved in this process are listed in figure \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":67}}}],["dd2bbf3f-2f3c-4a53-bcd6-0f057d1719f5",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 60 \n \n \n• While  the  process  of  patenting  includes – Prior  art  search,  Choice  of  Application  to  be \nFiled,  Patent  Application  Forms,  Jurisdiction  of  Filing  Patent  Application,  Publication, \nPre-grant Opposition, Examination, Grant of a Patent, Validity of Patent Protection, Post- \ngrant Opposition \nPRIOR ART SEARCH \n \n• Before  an  inventor  embarks  upon  the  patent  filing  process,  he  has  to ensure  that  his \ninvention is novel as per the criterion for the grant of a patent. For this, he/she has to check \nwhether or not his invention already exists in the public domain. \n• For this, he/she needs to read patent documents and Non-Patent Literature (NPL), scientific \njournals/reports/magazines, etc. \n• The  information  lying  in  the  public  domain  in  any  form,  either  before  the  filing  of  the \npatent application or the priority date of the patent application claiming the invention, is \ntermed as Prior Art. \n• Conducting  a  prior  art  search  before  filing  the  patent  has  advantages  as  it  averts \ninfringement, tracks research and development and provides access to detailed information \non the invention. \n• The prior art search is carried out on the parameters such as novelty, patentability, state of \nthe art, infringement, validity and freedom to operate. \n• The  commonly  used  databases  for  prior  art  search  fall  in  two  categories  i.e.  Patents \nDatabases and NPL. The patent databases are \no Indian Patent Advanced Search System (InPASS- \nhttp://ipindiaservices.gov.in/publicsearch/). \no Patentscope (WIPO- https://www.wipo.int/patentscope/en/). \no Espacenet (EU- https://worldwide.espacenet.com/patent/). \no USPTO (USA- https://www.uspto.gov/). \no Google Patents Advanced Search (https://patents.google.com/advanced). \no Orbit Intelligence (https://www.questel.com/business-intelligence-software/orbit- \nintelligence/). \no Derwent Innovation (https://clarivate.com/derwent/solutions/derwent- \ninnovation/). ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":68}}}],["650cb5d2-d63e-4aac-b692-506459750886",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 61 \n \n \no PROQUEST (https://about.proquest.com/search/?searchKeyword=patent+). \n• Non-Patent Literature (NPL) \no Scholarly publications: Handbooks, Textbooks, Withdrawn, Patents, \nEncyclopedias,  Journals  (IEEE,  Research  Gate,  Springer,  Wiley  Online  Library, \netc.), Dissertations, NCBI‘s, PubMed, Conference Proceedings, Technical Reports, \nPublic Conferences, etc. \no Industry/trade publications: Industry reviews and public disclosures (Social media, \nYouTube, Books, Magazines, Datasheets, Blueprints, etc.). \no Others: Newspapers, Websites, Technology blogs, Researchers websites, etc. \no Although, majority of NPL data is available freely on the public forum, some of the \njournals are paid and can be accessed after paying the subscription. \no Major Patent Office’s such as the United States Patent and Trademark Office's \n(USPTO),  European  Patent  Office  (EPO),  Japan  Patent  Office  (JPO),  etc.  are \nmaintaining in house NPL databases to make patents examination more effective \nCHOICE OF APPLICATION TO BE FILED \n \nOnce a decision has been made to patent the invention, the next step is, what kind of application \nneeds  to  be  filed  i.e.  provisional  patent  application  or  complete  (Final)  patent  application - \ngenerally, the provisional patent application is preferred for the following reasons: \n• It is cheaper, takes less time, and involves fewer formalities. \n• Any improvements made in the invention after the filing of the provisional application can \nbe  included  in  the  final application.  In  other  words,  the  provisional  application  does  not \nrequire complete specifications of the inventions. The application can be filed even though \nsome data is yet to be collected from pending experiments. \n• A provisional application allows you to secure a priority date for the patent applied. \n \nPATENT APPLICATION FORMS \n \n• As per the Patent Act, 1970 (Section 39) and the Patents Rules, 2003 (Rule 7, 54, 135 and \nsub  rule  (1)  of  rule  20,  the  application  for  the  grant  of  patent  is  filed  using  Form-1  and \nForm-2. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":69}}}],["e4f388c2-8c9f-47a1-90a4-f440e095f544",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 62 \n \n \n• The information sought in Form-1 is general in nature i.e. Title of Application, Names of \nApplicant(s) and Inventor(s), Type of Application (Ordinary, Convention, PCT-NP (PCT- \nNational Phase), Divisional, Patent of Addition, etc.). \n• Whereas Form-2 seeks technical information and whether to file the provisional application \nor complete the application. For Provisional Application, only Description of the Invention \nand the Abstract is to be furnished. Whereas, Complete Application requires Description \nof  the  Invention,  Abstract,  Claims  and  the  manner  in  which invention  have  to  be \nperformed. \n• The Claims of the patent are a very crucial part of the specifications because they define \nthe actual boundary of the invention. \n• Claims specify what is actually claimed by the invention and what is being sought to be \nprotected. It clearly describes what the patent does and does not cover \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":70}}}],["adbdbea1-13ee-4844-b1c0-2c14475bbb6e",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 63 \n \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":71}}}],["29c1a1a4-819b-4b1f-a2ee-76b88fa88b31",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 64 \n \n \n \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":72}}}],["4d6d74cd-9989-40f4-a76f-81c8aa4493c8",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 65 \n \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":73}}}],["42ebf312-7876-4ea2-9b59-577f535439e8",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 66 \n \n \nJURISDICTION OF FILING PATENT APPLICATION \n \nRegion States Address \n \n \n \n \nNORTH \n \nHaryana, Himachal Pradesh, Punjab, \nRajasthan, Uttar Pradesh, \nUttarakhand, Delhi and the Union \nTerritory of Chandigarh, Jammu and \nKashmir and Ladakh. \nIntellectual Property Office Building, Plot \nNo. 32, \nSector 14, Dwarka, \nNew Delhi-110078 \nPhone: 011-28032491 \nFax: 011-28034301 \nEmail: delhi-patent@nic.in \n \n \n \nSOUTH \n \nAndhra Pradesh, Karnataka, Kerala, \nTamil Nadu, Telangana and the \nUnion Territories of Pondicherry \nand Lakshadweep \nPatent Office Intellectual Property Building \nG.S.T. Road, Guindy, Chennai-600032 \nPhone: 044-22505242 \nFax: 044-22502066 \nEmail: chennaipatent@nic.in \n \n \n \nWEST \n \nMaharashtra, Gujarat, Madhya \nPradesh, Goa and Chhattisgarh and \nthe Union Territories of Daman and \nDiu & Dadra and Nagar Haveli \nBoudhik Sampada Bhawan, Antop Hill, S. M. \nRoad, Mumbai - 400 037. \nPhone: 022- 24153651, 24148165 \nFax: 022-24130387 \nEmail: mumbaipatent@nic.in \n \n \n \nREST OF \nINDIA \n \n \n \n \nRemaining States \nIntellectual Property Office Building, CP-2 \nSector V, Salt Lake City, Kolkata-700091 \nPhone: 033-23679101, \n033-23671987 \nFax: 033-23671988 \nEmail: kolkatapatent@nic.in \nPUBLICATION \n \n• Once the patent application has been filed at the Regional Patent Office, the patent \napplication is kept secret for 18 months in the Patent Office. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":74}}}],["b770c220-d42f-4918-8974-b45868f7eb7d",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 67 \n \n \n• After the expiry of 18 months (from the date of filing of the application or the priority \nclaimed date, whichever is earlier), the application is published in the Official Journal \nof Patent Office (http://www.ipindia.nic.in/journalpatents.html). \n• The purpose of publishing the application is to inform the public about the invention. \nThe publication of an application is a mandatory step. \nPRE-GRANT OPPOSITION \n \n• If anybody has an objection to the invention claimed in the patent application, he/she can \nchallenge the application by approaching the Controller of Patents within 6 months from \nthe date of publication. It is termed as Pre-grant Opposition. \n• Depending  on  the  outcome  of  the  case,  the  patent  application  may  be  rejected  or \nrecommended for the next step, i.e. patent examination. \n• Although   the   patent   application   is   kept   secret   for   18   months,   but   under   special \ncircumstances,  this  period  can  be  reduced  when  the  patentee/applicant  plans  to  sell  or \nlicense the patent or seek an investor). \n• For this, the applicant has to fill a Form-9 and submit it to the Controller General. \n \nEXAMINATION \n \n• Patent examination is a critical step in the process of grant of a patent. All the important \ncriteria (novel, inventive step, etc.) are scrutinized by the professionals depending on the \ncontent of the invention. \n• Usually,  the  examiner  raises  certain  queries/doubts  which  need  to  be  addressed  by  the \ninventors. Once the examiner is satisfied with the answers received from the inventors, the \napplication is recommended for the grant of a patent. \n• It  is  pertinent  to  mention  that  a  patent  application  is  not  examined  automatically  after \nclearing the publication stage. The applicant or his representative has to make a request for \nexamination of the patent by filing Form-18A and submitting the same within 48 months \nfrom the date of filing of the application ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":75}}}],["cf648f01-eb07-41b4-8b16-9adef93522fc",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 68 \n \n \nGRANT OF PATENT \n \n• After fulfilling all the requirements for the grant of a patent, including all objections/queries \nraised by the Patent Examiner and the public at large, the patent is granted to the applicant. \n• The granted patent is published in the Official Journal of the Patent Office. \n• This  journal  is  published  every  Friday  and  contains  information  related  to  patent \napplications  published  under  section  (u/s)  11A,  post-grant  publication,  restoration  of \npatent,  notifications,  list  of  non-working  patents  and  public  notices  issued  by  the  Patent \nOffice. \nVALIDITY OF PATENT PROTECTION \n \n• The  patent protection  is granted  to  an  applicant  for  a  limited  period,  generally  20  years, \nstarting from the date of filing of the application. \n• Once a patent is granted for an invention in India, the next vital step is to ensure that it is \nrenewed annually by paying Patent Renewal Fee as per Section 53, Rule 80 of the Indian \nPatents Act, till the expiry of the patent grant period. \n• Non-payment of Patent Renewal Fee might result in the cancellation of the patent. \n• In some countries, patent protection may be extended beyond 20 years. \n• The extension aims to compensate for the time expended on the administrative approval \nprocedure  before  products  can  be  put  on  the  market.  The  time  taken  for  this  procedure \nmeans  that  the  patent  owner  may  sometimes  not  be  able  to  benefit  from  his  right  for a \nconsiderable period after the grant of the patent. \nPOST GRANT OPPOSITION \n \n• Once the patent has been granted by the Patent Office, it still can be challenged by \nanyone within one year from the date of publication of the grant of the patent. \n• The granted patent can be challenged either via a Patent Office or in a Court of Law. \n• These bodies may invalidate or revoke a patent upon a successful challenge by the \ninterested party on the grounds mentioned below: ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":76}}}],["3bdd22f4-8464-47c8-bbb8-94cb9b448e01",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 69 \n \n \no The applicant for the patent wrongfully obtained the invention or any part of the \ninvention. \no The invention claimed has been published before the priority date. \no The invention claimed was publicly known / used before the priority date. \no The invention claimed is obvious and does not involve an inventive step. \no The subject of the claim is not patentable as per Chapter II of the Patent Act, \n1970. \no The details/specifications of the invention do not sufficiently and clearly describe \nthe invention. \n \nCOMMERCIALIZATION OF A PATENT \n \n• The  patent  owner  may  grant  permission  to  an  individual/organization/industry  to  make, \nuse,  and  sell  his  patented  invention.  This  takes  place  according  to  agreed  terms  and \nconditions between the involving parties. \n• A patent owner may grant a license to a third party for the reasons mentioned below: \no The patent owner has a decent job e.g. university professor and has no desire or \naptitude to exploit the patent on his own. \no The patent owner may not have the necessary manufacturing facilities. \no The manufacturing facility is not able to meet the market demand. \no The patent owner wishes to concentrate on one geographic market; for other \ngeographical markets, he may choose to license the patent rights. \n• Once the patent is granted, the patentee (person holding the rights to the patent) enjoys the \nexclusive rights to use the patented invention. \n• Only  the  patentee  has  the  right  to  license  or  deal  with  the  patent  for  any  deliberations. \nAlthough, the validity of the granted patent is for 20 years (from the date of filing a patent \napplication), but the patentee is required to furnish information (Form-27), on an annual \nbasis   relating   to   the   commercialization/selling   of   the   patent.   It   is   called   as \nWorking/Licensing of the Patent. \n• The licensing of a patent can be exclusive or non-exclusive. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":77}}}],["df1ddefc-872e-4bc8-ac74-ca0505844ac0",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 70 \n \n \n• In an Exclusive License, the patent is sold to only one individual/organization for a fixed \ntime period. During this time period, no other person or entity can exploit the relevant IP \nexcept the named licensee. \n• In   Non-Exclusive   License,   a   patentee   can   sell   his   patent   rights   to   as   many \nindividuals/parties as he likes. If the patentee is not able to commercialize his patent within \nthree years from the date of the grant of a patent, any person may submit an application to \nthe Controller of Patents for grant of Compulsory Licensing (of the patent), subject to the \nfulfillment of following conditions: \no Reasonable requirements of the public concerning the patented invention have not \nbeen satisfied. \no The patented invention is not available to the public at a reasonable price. \no The patented invention is not worked in the territory of India. \n \nNEED FOR PATENT ATTORNEY / AGENT \n \n• In general, applicants can prepare their patent applications and file them without assistance \nfrom a patent attorney. \n• However, given the complexity of patent documents, it is advisable to seek legal assistance \nfrom a patent attorney/agent when drafting a patent application. \n• Furthermore, the legislation of many countries requires that an applicant, whose ordinary \nresidence or principal place of business is outside the country, be represented by an attorney \nor agent qualified in the country (which usually means an agent or attorney who resides \nand practices in that country \nCAN A WORLDWIDE PATENT BE OBTAINED? \n \n• There is no such term as Universal Patent or World Patent or International Patent as the \npatent rights are territorial. \n• An application for a patent must be filed with a Patent Office of the country in which one \nwishes   to   seek   patent   protection.   Unfortunately,   this   option   becomes   laborious, \ncumbersome, time consuming and expensive if one wishes to file a patent application in \nmany countries. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":78}}}],["5a82dcbc-e879-4b06-916d-a09b0331bc5b",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 71 \n \n \n• To ease out this issue, many Regional Offices have been established which receive patent \napplications  on  behalf  of  a  group  of  nations  e.g.  European  Patent  Office  and  African \nRegional Intellectual Property Organization. \n• A single application is sufficient to cover many nations that are members of a particular \nregional office/organization. \n• However,  if  one  wishes  to  seek  patent  protection  in  several  countries worldwide,  it  is \npreferred to file an international patent under the Patent Cooperation Treaty (PCT). \n• The only condition is that the applicant‘s country should be a member of PCT. India, along \nwith over 190 nations, is a member of PCT. \nDO I NEED FIRST TO FILE A PATENT IN INDIA \n \n• Yes,  in  general,  Indian  residents  are  required  to  file  the  patent  application  first  in  India. \nSubsequently, they may file for patent protection in other countries. \n• But for this, prior approval is needed from the Patent Office. However, this approval can \nbe waived off under the following circumstances: \no The applicant is not an Indian resident. \no If 6 weeks have expired since the patent application was filed in India by an Indian \nresident. \no If two or more inventors are working on an invention in a foreign country and one \nof  the  inventors  is  an  Indian  resident.  The  invention  does  not  have  a  potential \nmarket  in  India  and  hence  does  not  wish  to  file  the  patent  in  India.  In  such  a \nscenario, the Indian resident has to seek Foreign Filing Permission (FFP) from an \nIndian Patent Office. \no In case of international collaboration, if one part of the invention originated in India \nand the inventor is an Indian resident, he has to seek permission to file the patent \noutside India. \no If the invention is related to defense or atomic energy or utility model, the inventor/s \nneeds to seek permission from the Indian Patent Office because inventions related \nto these domains are not the subject matter of patentability in India. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":79}}}],["0a9b8bc8-e938-4957-a9cb-299caccf243c",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 72 \n \n \nPATENT RELATED FORMS \n \n• There are over 30 patent-related forms. Some of them are mentioned below. \n \n \nFEES STRUCTURE \n \n• As per the patent Act, 1970 and The Patents Rules (1972), the requisite fee has been \nspecified based on the type of form/s to be submitted to the Office. \n• Electronically filed applications are 10% cheaper than physical filing. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":80}}}],["167273d4-2ed9-4a79-9a95-d85ff58567f9",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 73 \n \n \n \n \n \nTYPES OF PATENT APPLICATIONS \n \n• Provisional  Application - A  patent  application  filed  when  the  invention  is  not  fully \nfinalized  and  some  part  of  the  invention  is  still  under  experimentation.  Such  type  of \napplication helps to obtain the priority date for the invention. \n• Ordinary Application - A patent application filed with complete specifications and claims \nbut without claiming any priority date. \n• PCT Application - An international application filed in accordance with  PCT. A single \napplication  can  be  filed  to  seek  patent  protection  and  claim  priority  in  all  the  member \ncountries of PCT. \n• Divisional  Application - When  an  application  claims  more  than  one  invention,  the \napplicant on his own or to meet the official objection on the ground of plurality may ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":81}}}],["02e30c37-5281-49a7-bfa3-1c1029e22c50",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 74 \n \n \ndivide the application and file two or more applications. This application divided out of the \nparent one is known as a Divisional Application. \n• Patent of Addition Application - When an invention is a slight modification of the earlier \ninvention  for  which  the  patentee  has  already  applied  for  or  has  obtained  a  patent,  the \napplicant can go for Patent of Addition, if the modification in the invention is new. Benefit \n- There is no need to pay a separate renewal fee for the Patent of Addition, during the term \nof the main patent. It expires along with the main patent. \n• Convention Application - If a patent application has been filed in the Indian Patent Office \nand the applicant wishes to file the same invention in the one or more Convention countries \n(e.g. Paris Convention) by claiming the same priority date on which application was filed \nin India, such an application is known as Convention Application. The applicant has to file \nConvention Application within 12 months from the date of filing in India to claim the same \npriority date. \nCOMMONLY USED TERMS IN PATENTING \n \nSl. No Terms Definition \n1 Inventor Creator of an invention \n2 Applicant \nOrganization/individual/industry that files a patent \napplication or applies for a patent \n3 Patentee A person/organization who owns the patent (granted) \n \n4 \n \nLicensee \nOrganization/individual/industry which obtains a license \nof the patent from the Patentee for commercialization \npurpose \n5 Assignee A person in whose name patent has been assigned legally \n6 In force \nThe applicant is paying the annuity (renewal fee) for the \npatent to keep it alive (Active Patent) \n7 Working of a patent \nThe  selling  of  a  patent  to  an  individual/party  for \ncommercial exploitation is called as working of a patent \n \n8 \n \nPatent Specification \nPatent specification is a written description of the \ninvention and the way of representation and process of \nmaking and using the same ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":82}}}],["491bb2b7-8f7c-4761-8e38-677143f154f6",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 75 \n \n \n \n9 Priority right \nIt is a time-limited right, activated by the first filing of an \napplication for a patent \n10 Priority date \nThe claimed date on which the first application for the \ninvention is filed \n \n \n11 \n \n \nPatent claims \nClaims  can  be  defined  as  the  scope  of  the  protection \nconferred by a patent, or the protection sought in a patent \napplication. The purpose of the claims is to define which \nsubject matter is protected by the patent \n \n12 \n \nNational phase application \nAn application filed to obtain patents in different \ncountries simultaneously based on a single \nInternational/PCT application \n \n13 \n \nPatent revocation \nThe revocation means cancellation of the patent due to \ncertain reasons, such as lack of patentability or \nwrongfully obtaining a patent \n \n14 \n \nRestoration of patent \nOnce a patent has been ceased (e.g. due to non-payment \nof the fee) it can be restored within a permitted period by \npaying the requisite fee \n \nNATIONAL BODIES DEALING WITH PATENT AFFAIRS \nThere are many departments/organizations/bodies dealing with various aspects of patents, namely, \n• The Indian Patent Office (IPO) - The Office of the Controller General of Patents, Designs \nand  Trade  Marks  generally  known  as  the  Indian  Patent  Office,  is  an  agency under the \nDepartment for Promotion of Industry and Internal Trade which administers the Indian law \nof Patents, Designs and Trade Marks. \n• Department for Promotion for Industry and Internal Trade (DPIIT) - DPIIT, earlier \nknown as the Department of Industrial Policy and Promotion (DIPP), under the Ministry \nof Commerce and Industry, Govt. of India, is the apex IP body. It came into existence in \n1995 and is the main body for regulating and administering the industrial sector. \n• Technology   Information,   Forecasting   and   Assessment   Council   (TIFAC) - The \nimportance of undertaking technology forecasting and assessment studies on a systematic ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":83}}}],["1a735d76-33f9-4616-8e83-ce503093607e",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \n \nRM & IPR – 21RMI56 \nPage 76 \n \n \nand continuing basis was highlighted in the Government of India‘s Technology Policy \nStatement  (TPS)  of  1983.  Therefore  in  1985,  TIFAC  was  established  as  an  autonomous \nbody, registered as a Society in 1988, under the Department of Science and Technology. It \nis an important cog in filling a critical gap in the overall Science and Technology system \nof India. Its mission is to assess the state-of-art of technologies and set directions for future \ntechnological developments in India in important socio-economic sectors \n• National  Research  Development  Corporation  (NRDC) - NRDC,  an  enterprise  of \nDepartment of Scientific & Industrial Research (DSIR), Govt. of India, was set up in 1953 \nwith a mandate to develop, promote and transfer/commercialize IP and technologies \nemanating from Higher Education Institutes (HEIs), R&D research laboratories/institutions \nand   Public   Sector   Undertakings   (PSUs).   NRDC   has   a   repository   of   2500   Indian \ntechnologies, filed over 1700 Patents and transferred about 5000 technologies in different \nsectors  in  India.  It  has  also  created  a  technology  data  bank (http://fccollc.com/nrdclive/) \ncontaining information regarding technologies available in various fields, such as electrical \n& electronics, mechanical, coil, mining, biotechnology, healthcare, leather, etc. \nUTILITY MODELS \n \n• In  many  cases,  a  new  invention  involves  an  incremental  improvement  over  the  existing \nproducts,  but  this  technical  improvement  is  not  sufficient  enough  to  pass  the  stringent \ncriterion of Novelty and Non-obviousness set aside for the grant of a patent. Such small \ninnovations can still be legally protected in some countries and termed as ‘Utility Models’ \nor ‘Petty Patents’ or ‘Innovation Patents’. \n• In this case, the criterion of Novelty and Non-obviousness are diluted or relinquished. But \nthe requirement of industrial application or utility is the same as that for patents. \n• Utility Model is a helpful tool for Micro, Small and Medium Enterprises (MSME) since \nthe grant of a Utility Model is usually less rigorous and involves minimal cost. \n• MSMEs  do  not  have  deep  pockets  to  carry  out  intensive  R&D  leading  to  the  grant  of \npatents. But their innovations are good enough for improving their products/processes and \nbringing more financial rewards. Such inventions pass the requirements set aside for Utility \nModels but not for patents. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":84}}}],["524158dd-7582-4310-912f-8a73bc40ea1b",{"pageContent":"Dr. Dilip R -Department of ECE , Dayananda Sagar Academy of Technology & Mgmt. \nRM & IPR – 21RMI56 \nPage 77 \n \n \n• The life of the Utility Model is less as compared to the patents. It varies from 7-15 years in \ndifferent countries. \n• Nearly  80  countries,  including  France,  Germany,  Japan,  South  Korea,  China,  Finland, \nRussian Federation and Spain, provide protection for Utility Models under their IPR laws. \n• India till date does not recognize utility patents. If these small patents are recognized under \nIP protection in India, it will catapult the number of patents (filed and granted) on annual \nbasis. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\21RMI56_Notes_(1)[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Producer":"iLovePDF","ModDate":"D:20240223192519+06'30'"},"metadata":null,"totalPages":85},"loc":{"pageNumber":85}}}],["2f40734d-4bf5-4040-a4ec-5b56dd57f071",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    1 \n       \n INFORMED  SEARCH STRATEGIES  \n \n3.5 INFORMED (HEURISTIC) SEARCH STRATEGIES  \nThis section shows how an informed search strategy—one that uses problem-specific \nknowledge beyond the definition of the problem itself—can find solutions more efficiently \nthan can an uninformed strategy. The general approach we consider is called best-first \nsearch. Best-first search is an instance of the general TREE-SEARCH or GRAPH-SEARCH \nalgorithm in which a node is selected for expansion based on an evaluation function, f(n). \nThe evaluation function is construed as a cost estimate, so the node with the lowest \nevaluation is expanded first. The implementation of best-first graph search is identical to \nthat for uniform-cost search (Figure 3.14), except for the use of f instead of g to order the \npriority queue. The choice of f determines the search strategy. (For example, as Exercise \n3.21  shows,  best-first  tree  search  includes  depth-first  search  as  a  special  case.) \n Most best-first algorithms include as a component of f a heuristic function, denoted \nh(n):  h(n) = estimated cost of the cheapest path from the state at node n to a goal state. \n  \n3.5.1 Greedy best-first search  \nGreedy best-first search tries to expand the node that is closest to the goal, on the grounds \nthat this is likely to lead to a solution quickly. Thus, it evaluates nodes by using just the \nheuristic function; that is, f(n) = h(n). Let us see how this works for route-finding problems \nin Romania; we use the straight line distance heuristic, which we will call hSLD . If the goal \nis Bucharest, we need to know the straight-line distances to Bucharest, which are shown \nin Figure 3.22. For example, hSLD (In(Arad)) = 366. Notice that the values of hSLD cannot \nbe computed from the problem description itself. Moreover, it takes a certain amount of \nexperience to know that hSLD is correlated with actual road distances and is, therefore, a \nuseful heuristic. Figure 3.23 shows the progress of a greedy best-first search using hSLD \nto find a path from Arad to Bucharest. The first node to be expanded from Arad will be \nSibiu because it is closer to Bucharest than either Zerind or Timisoara. The next node to \nbe expanded will be Fagaras because it is closest. Fagaras in turn generates Bucharest, \nwhich is the goal. For this particular problem, greedy best-first search using hSLD finds a \nsolution without ever expanding a node that is not on the solution path; hence, its search \ncost is minimal. It is not optimal, however: the path via Sibiu and Fagaras to Bucharest is \n32 kilometers longer than the path through Rimnicu Vilcea and Pitesti. This shows why \nthe algorithm is called “greedy”—at each step it tries to get as close to the goal as it can. \nGreedy best-first tree search is also incomplete even in a finite state space, much like \ndepth-first search. Consider the problem of getting from Iasi to Fagaras. The heuristic \nsuggests that Neamt be expanded first because it is closest to Fagaras, but it is a dead end. \nThe solution is to go first to Vaslui—a step that is actually farther from the goal according \nto the heuristic—and then to continue to Urziceni, Bucharest, and Fagaras. The algorithm \nwill never find this solution, however, because expanding Neamt puts Iasi back into the \nfrontier, Iasi is closer to Fagaras than Vaslui is, and so Iasi will be expanded again, leading \nvtucode.in\nModule 2","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":1}}}],["ce160dd4-3b52-4c68-b280-8630456cc3dd",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    2 \nto an infinite loop. (The graph search version is complete in finite spaces, but not in infinite \nones.) The worst-case time and space complexity for the tree version is O(bm), where m is \nthe maximum depth of the search space. With a good heuristic function, however, the \ncomplexity can be reduced substantially. The amount of the reduction depends on the \nparticular problem and on the quality of the heuristic \n \n3.5.2 A* search: Minimizing the total estimated solution cost \n The most widely known form of best-first search is called A∗ search (pronounced “A-star \nsearch”). It evaluates nodes by combining g(n), the cost to reach the node, and h(n), the \ncost to get from the node to the goal: \n f(n) = g(n) + h(n) . \n Since g(n) gives the path cost from the start node to node n, and h(n) is the estimated cost \nof the cheapest path from n to the goal, we have \n f(n) = estimated cost of the cheapest solution through n . Thus, if we are trying to find the \ncheapest solution, a reasonable thing to try first is the node with the lowest value of g(n) \n+ h(n). It turns out that this strategy is more than just reasonable: provided that the \nheuristic function h(n) satisfies certain conditions, A∗ search is both complete and optimal. \nThe algorithm is identical to UNIFORM-COST-SEARCH except that A∗ uses g + h instead of \ng. \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":2}}}],["65bc8eb9-e79c-4d40-8c4e-a287a9c46f85",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    3 \n \nConditions for optimality: Admissibility and consistency The first condition we require for \noptimality is that h(n) be an admissible heuristic. An admissible heuristic is one that never \noverestimates the cost to reach the goal. Because g(n) is the actual cost to reach n along \nthe current path, and f(n) = g(n) + h(n), we have as an immediate consequence that f(n) \nnever overestimates  the  true  cost  of  a  solution  along  the  current  path  through  n. \nAdmissible heuristics are by nature optimistic because they think the cost of solving the \nproblem is less than it actually is. An obvious example of an admissible heuristic is the \nstraight-line distance hSLD that we used in getting to Bucharest. Straight-line distance is \nadmissible because the shortest path between any two points is a straight line, so the \nstraight line cannot be an overestimate. In Figure 3.24, we show the progress of an A∗ tree \nsearch for Bucharest. The values of g are computed from the step costs in Figure 3.2, and \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":3}}}],["cc57067a-66c0-4892-a061-23c45e3d8885",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    4 \nthe values of hSLD are given in Figure 3.22. Notice in particular that Bucharest first appears \non the frontier at step (e), but it is not selected for expansion because its f-cost (450) is \nhigher than that of Pitesti (417). Another way to say this is that there might be a solution \nthrough Pitesti whose cost is as low as 417, so the algorithm will not settle for a solution \nthat costs 450. A second, slightly stronger condition called consistency (or sometimes \nmonotonicity) is required only for applications of A∗ to graph search.9 A heuristic h(n) is \nconsistent if, for every node n and every successor nof n generated by any action a, the \nestimated cost of reaching the goal from n is no greater than the step cost of getting to \nnplus the estimated cost of reaching the goal from n’ : \nh(n) ≤ c(n, a, n’ ) + h(n’ ) . \nThis is a form of the general triangle inequality, which stipulates that each side of a triangle \ncannot be longer than the sum of the other two sides. Here, the triangle is formed by n, n’, \nand the goal Gn closest to n. For an admissible heuristic, the inequality makes perfect \nsense: if there were a route from n to Gn via n’ that was cheaper than h(n), that would \nviolate the property that h(n) is a lower bound on the cost to reach Gn. It is fairly easy to \nshow (Exercise 3.29) that every consistent heuristic is also admissible. Consistency is \ntherefore a stricter requirement than admissibility, but one has to work quite hard to \nconcoct heuristics that are admissible but not consistent. All the admissible heuristics we \ndiscuss in this chapter are also consistent. Consider, for example, hSLD . We know that the \ngeneral triangle inequality is satisfied when each side is measured by the straight-line \ndistance and that the straight-line distance between n and n’ is no greater than c(n, a, n’ ). \nHence, hSLD is a consistent heuristic.  \nOptimality of A* As we mentioned earlier, A∗ has the following properties: the tree-search \nversion of A∗ is optimal if h(n) is admissible, while the graph-search version is optimal if \nh(n) is consistent. We show the second of these two claims since it is more useful. The \nargument essentially mirrors the argument for the optimality of uniform-cost search, with \ng replaced by f—just as in the A∗ algorithm itself. The first step is to establish the following: \nif h(n) is consistent, then the values of f(n) along any path are nondecreasing. The proof \nfollows directly from the definition of consistency. Suppose n is a successor of n; then g(n’ \n) = g(n) + c(n, a, n’ ) for some action a, and we have  \nf(n’) = g(n’ ) + h(n’ ) = g(n) + c(n, a, n’ ) + h(n’ ) ≥ g(n) + h(n) = f(n) . \n The next step is to prove that whenever A∗ selects a node n for expansion, the optimal \npath to that node has been found. Were this not the case, there would have to be another \nfrontier node n on the optimal path from the start node to n, by the graph separation \nproperty of \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":4}}}],["f9abc90a-a4cd-442c-a8ff-f94a9ee94508",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    5 \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":5}}}],["919733f8-e62f-49d4-aed2-69b821e74ac9",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    6 \n \nFigure 3.9; because f is nondecreasing along any path, nwould have lower f-cost than n and \nwould have been selected first. From the two preceding observations, it follows that the \nsequence of nodes expanded by A∗ using GRAPH-SEARCH is in nondecreasing order of f(n). \nHence, the first goal node selected for expansion must be an optimal solution because f is \nthe true cost for goal nodes (which have h = 0) and all later goal nodes will be at least as \nexpensive. The fact that f-costs are nondecreasing along any path also means that we can \ndraw contours in the state space, just like the contours in a topographic map. Figure 3.25 \nshows an example. Inside the contour labeled 400, all nodes have f(n) less than or equal to \n400, and so on. Then, because A∗ expands the frontier node of lowest f-cost, we can see \nthat an A∗ search fans out from the start node, adding nodes in concentric bands of \nincreasing f-cost. With uniform-cost search (A∗ search using h(n)=0), the bands will be \n“circular” around the start state. With more accurate heuristics, the bands will stretch \ntoward the goal state and become more narrowly focused around the optimal path. If C∗ is \nthe cost of the optimal solution path, then we can say the following:  \n• A∗ expands all nodes with f(n) < C∗. \n • A∗ might then expand some of the nodes right on the “goal contour” (where f(n) = C∗) \nbefore selecting a goal node. Completeness requires that there be only finitely many nodes \nwith cost less than or equal to C∗, a condition that is true if all step costs exceed some finite \nand if b is finite. Notice that A∗ expands no nodes with f(n) > C∗—for example, Timisoara \nis not expanded in Figure 3.24 even though it is a child of the root. We say that the subtree \nbelow \nTimisoara is pruned; because hSLD is admissible, the algorithm can safely ignore this \nsubtree  while  still  guaranteeing  optimality.  The  concept  of  pruning—eliminating \npossibilities from consideration without having to examine them—is important for many \nareas of AI. One final observation is that among optimal algorithms of this type—\nalgorithms  that  extend  search  paths  from  the  root  and  use  the  same  heuristic \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":6}}}],["6f09a373-2ca3-4630-bbef-f83eac459adb",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    7 \ninformation—A∗ is optimally efficient for any given consistent heuristic. That is, no other \noptimal algorithm is guaran- teed to expand fewer nodes than A∗ (except possibly through \ntie-breaking among nodes with f(n) = C∗). This is because any algorithm that does not \nexpand all nodes with f(n) < C∗ runs the risk of missing the optimal solution. That A∗ \nsearch is complete, optimal, and optimally efficient among all such algorithms is rather \nsatisfying. Unfortunately, it does not mean that A∗ is the answer to all our searching needs. \nThe catch is that, for most problems, the number of states within the goal contour search \nspace is still exponential in the length of the solution. The details of the analysis are beyond \nthe scope of this book, but the basic results are as follows. For problems with constant step \ncosts, the growth in run time as a function of the optimal solution depth d is analyzed in \nterms of the the absolute error or the relative error of the heuristic. The absolute error is \ndefined as Δ ≡ h∗ − h, where h∗ is the actual cost of getting from the root to the goal, and \nthe relative error is defined as ≡ (h∗ − h)/h∗. The complexity results depend very strongly \non the assumptions made about the state space. The simplest model studied is a state \nspace that has a single goal and is essentially a tree with reversible actions. (The 8-puzzle \nsatisfies the first and third of these assumptions.) In this case, the time complexity of A∗ is \nexponential in the maximum absolute error, that is, O(b^Δ). For constant step costs, we can \nwrite this as O(b^d), where d is the solution depth. For almost all heuristics in practical \nuse, the absolute error is at least proportional to the path cost h∗, so is constant or growing \nand the time complexity is exponential in d. We can also see the effect of a more accurate \nheuristic: O(b^d) = O((b^)^d), so the effective branching factor (defined more formally in \nthe next section) is b^. When the state space has many goal states—particularly near-\noptimal goal states—the search process can be led astray from the optimal path and there \nis an extra cost proportional to the number of goals whose cost is within a factor of the \noptimal cost. Finally, in the general case of a graph, the situation is even worse. There can \nbe exponentially many states with f(n) < C∗ even if the absolute error is bounded by a \nconstant. For example, consider a version of the vacuum world where the agent can clean \nup any square for unit cost without even having to visit it: in that case, squares can be \ncleaned in any order. With N initially dirty squares, there are 2N states where some subset \nhas been cleaned and all of them are on an optimal solution path—and hence satisfy f(n) \n< C∗—even if the heuristic has an error of 1. The complexity of A∗ often makes it \nimpractical to insist on finding an optimal solution. One can use variants of A∗ that find \nsuboptimal solutions quickly, or one can sometimes design heuristics that are more \naccurate but not strictly admissible. In any case, the use of a good heuristic still provides \nenormous savings compared to the use of an uninformed search. In Section 3.6, we look at \nthe question of designing good heuristics. Computation time is not, however, A∗’s main \ndrawback. Because it keeps all generated nodes in memory (as do all GRAPH-SEARCH \nalgorithms), A∗ usually runs out of space long before it runs out of time. For this reason, \nA∗ is not practical for many large-scale problems. There are, however, algorithms that \novercome the space problem without sacrificing optimality or completeness, at a small \ncost in execution time. We discuss these next. \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":7}}}],["eab1f8b8-7489-47b0-8233-5c5d998bc633",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    8 \n \n \n3.6 HEURISTIC FUNCTIONS  \nIn this section, we look at heuristics for the 8-puzzle, in order to shed light on the nature \nof heuristics in general. The 8-puzzle was one of the earliest heuristic search problems. As \nmentioned in Section 3.2, the object of the puzzle is to slide the tiles horizontally or \nvertically into the empty space until the configuration matches the goal configuration \n(Figure 3.28). The average solution cost for a randomly generated 8-puzzle instance is \nabout 22 steps. The branching factor is about 3. (When the empty tile is in the middle, four \nmoves are possible; when it is in a corner, two; and when it is along an edge, three.) This \nmeans that an exhaustive tree search to depth 22 would look at about 3^22 ≈ 3.1 × 10^10 \nstates. A graph search would cut this down by a factor of about 170,000 because only 9!/2 \n= 181, 440 distinct states are reachable. (See Exercise 3.4.) This is a manageable number, \nbut the corresponding number for the 15-puzzle is roughly 10^13, so the next order of \nbusiness is to find a good heuristic function. If we want to find the shortest solutions by \nusing A∗, we need a heuristic function that never overestimates the number of steps to the \ngoal. There is a long history of such heuristics for the 15-puzzle; here are two commonly \nused candidates:  \n• h1 = the number of misplaced tiles. For Figure 3.28, all of the eight tiles are out of position, \nso the start state would have h1 = 8. h1 is an admissible heuristic because it is clear that \nany tile that is out of place must be moved at least once.  \n• h2 = the sum of the distances of the tiles from their goal positions. Because tiles cannot \nmove along diagonals, the distance we will count is the sum of the horizontal and vertical \ndistances. This is sometimes called the city block distance or Manhattan distance. h2 is \nalso admissible because all any move can do is move one tile one step MANHATTAN \nDISTANCE closer to the goal. Tiles 1 to 8 in the start state give a Manhattan distance of h2 \n= 3 + 1 + 2 + 2 + 2 + 3 + 3 + 2 = 18 . As expected, neither of these overestimates the true \nsolution cost, which is 26. \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":8}}}],["c6f832ae-713d-44eb-b58d-786942b10e86",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    9 \n \n3.6.1 The effect of heuristic accuracy on performance \n One way to characterize the quality of a heuristic is the effective branching factor b∗. If the \ntotal number of nodes generated by A∗ for a particular problem is N and the solution depth \nis d, then b∗ is the branching factor that a uniform tree of depth d would have to have in \norder to contain N + 1 nodes. Thus, \n N +1=1+ b∗ + (b∗) ^2 + ··· + (b∗)^ d .  \nFor example, if A∗ finds a solution at depth 5 using 52 nodes, then the effective branching \nfactor is 1.92. The effective branching factor can vary across problem instances, but usually \nit is fairly constant for sufficiently hard problems. (The existence of an effective branching \nfactor follows from the result, mentioned earlier, that the number of nodes expanded by \nA∗ grows exponentially with solution depth.) Therefore, experimental measurements of \nb∗ on a small set of problems can provide a good guide to the heuristic’s overall usefulness. \nA welldesigned heuristic would have a value of b∗ close to 1, allowing fairly large problems \nto be solved at reasonable computational cost \nTo test the heuristic functions h1 and h2, we generated 1200 random problems with \nsolution lengths from 2 to 24 (100 for each even number) and solved them with iterative \ndeepening search and with A∗ tree search using both h1 and h2. Figure 3.29 gives the \naverage number of nodes generated by each strategy and the effective branching factor. \nThe results suggest that h2 is better than h1, and is far better than using iterative \ndeepening search. Even for small problems with d = 12, A∗ with h2 is 50,000 times more \nefficient than uninformed iterative deepening search \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":9}}}],["7cb4672b-7173-4a84-9c31-ddcddefec1b0",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    10 \n \nOne might ask whether h2 is always better than h1. The answer is “Essentially, yes.” It is \neasy to see from the definitions of the two heuristics that, for any node n, h2(n) ≥ h1(n). \nWe thus say that h2 dominates h1. Domination translates directly into efficiency: A∗ using \nh2 will never expand more nodes than A∗ using h1 (except possibly for some nodes with \nf(n) = C∗). The argument is simple. Recall the observation on page 97 that every node with \nf(n) < C∗ will surely be expanded. This is the same as saying that every node with h(n) < \nC∗ − g(n) will surely be expanded. But because h2 is at least as big as h1 for all nodes, every \nnode that is surely expanded by A∗ search with h2 will also surely be expanded with h1, \nand h1 might cause other nodes to be expanded as well. Hence, it is generally better to use \na heuristic function with higher values, provided it is consistent and that the computation \ntime for the heuristic is not too long. \n \n3.6.2 Generating admissible heuristics from relaxed problems \n We have seen that both h1 (misplaced tiles) and h2 (Manhattan distance) are fairly good \nheuristics for the 8-puzzle and that h2 is better. How might one have come up with h2? Is \nit possible for a computer to invent such a heuristic mechanically? h1 and h2 are estimates \nof the remaining path length for the 8-puzzle, but they are also perfectly accurate path \nlengths for simplified versions of the puzzle. If the rules of the puzzle were changed so that \na tile could move anywhere instead of just to the adjacent empty square, then h1 would \ngive the exact number of steps in the shortest solution. Similarly, if a tile could move one \nsquare in any direction, even onto an occupied square, then h2 would give the exact \nnumber of steps in the shortest solution. A problem with fewer restrictions on the actions \nis called a relaxed problem. The state-space graph of the relaxed problem is a supergraph \nof the original state space because the removal of restrictions creates added edges in the \ngraph. Because the relaxed problem adds edges to the state space, any optimal solution in \nthe original problem is, by definition, also a solution in the relaxed problem; but the \nrelaxed problem may have better solutions if the added edges provide short cuts. Hence, \nthe cost of an optimal solution to a relaxed problem is an admissible heuristic for the \noriginal problem. Furthermore, because the derived heuristic is an exact cost for the \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":10}}}],["27eaec16-3939-41e7-81a6-0a7f8ba6146b",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    11 \nrelaxed problem, it must obey the triangle inequality and is therefore consistent (see page \n95). If a problem definition is written down in a formal language, it is possible to construct \nrelaxed problems automatically.11 For example, if the 8-puzzle actions are described as A \ntile can move from square A to square B if A is horizontally or vertically adjacent to B and \nB is blank, we can generate three relaxed problems by removing one or both of the \nconditions: \n (a) A tile can move from square A to square B if A is adjacent to B.  \n(b) A tile can move from square A to square B if B is blank. \n (c) A tile can move from square A to square B. \n From (a), we can derive h2 (Manhattan distance). The reasoning is that h2 would be the \nproper score if we moved each tile in turn to its destination. The heuristic derived from (b) \nis discussed in Exercise 3.31. From (c), we can derive h1 (misplaced tiles) because it would \nbe the proper score if tiles could move to their intended destination in one step. Notice \nthat it is crucial that the relaxed problems generated by this technique can be solved \nessentially without search, because the relaxed rules allow the problem to be decomposed \ninto eight independent subproblems. If the relaxed problem is hard to solve, then the \nvalues of the corresponding heuristic will be expensive to obtain.12 A program called \nABSOLVER can generate heuristics automatically from problem definitions, using the \n“relaxed problem” method and various other techniques (Prieditis, 1993). ABSOLVER \ngenerated a new heuristic for the 8-puzzle that was better than any preexisting heuristic \nand found the first useful heuristic for the famous Rubik’s Cube puzzle. One problem with \ngenerating new heuristic functions is that one often fails to get a single “clearly best” \nheuristic. If a collection of admissible heuristics h1 ...hm is available for a problem and \nnone of them dominates any of the others, which should we choose? As it turns out, we \nneed not make a choice. We can have the best of all worlds, by defining \n h(n) = max{h1(n),...,hm(n)} . \n \nThis composite heuristic uses whichever function is most accurate on the node in question. \nBecause the component heuristics are admissible, h is admissible; it is also easy to prove \nthat h is consistent. Furthermore, h dominates all of its component heuristics. \n 3.6.3 Generating admissible heuristics from subproblems: Pattern databases \nAdmissible heuristics can also be derived from the solution cost of a subproblem of a given \nproblem. For example, Figure 3.30 shows a subproblem of the 8-puzzle instance in Figure \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":11}}}],["35e4538e-fa02-4162-8ef1-a87b4f8c19d2",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    12 \n3.28. The subproblem involves getting tiles 1, 2, 3, 4 into their correct positions. Clearly, \nthe cost of the optimal solution of this subproblem is a lower bound on the cost of the \ncomplete problem. It turns out to be more accurate than Manhattan distance in some cases. \nThe idea behind pattern databases is to store these exact solution costs for every possible \nsubproblem instance—in our example, every possible configuration of the four tiles and \nthe blank. (The locations of the other four tiles are irrelevant for the purposes of solving \nthe subproblem, but moves of those tiles do count toward the cost.) Then we compute an \nadmissible heuristic hDB for each complete state encountered during a search simply by \nlooking up the corresponding subproblem configuration in the database. The database \nitself is constructed by searching back13 from the goal and recording the cost of each new \npattern encountered; the expense of this search is amortized over many subsequent \nproblem instances. The choice of 1-2-3-4 is fairly arbitrary; we could also construct \ndatabases for 5-6-7-8, for 2-4-6-8, and so on. Each database yields an admissible heuristic, \nand these heuristics can be combined, as explained earlier, by taking the maximum value. \nA combined heuristic of this kind is much more accurate than the Manhattan distance; the \nnumber of nodes generated when solving random 15-puzzles can be reduced by a factor \nof 1000. One might wonder whether the heuristics obtained from the 1-2-3-4 database \nand the 5-6-7-8 could be added, since the two subproblems seem not to overlap. Would \nthis still give an admissible heuristic? The answer is no, because the solutions of the 1-2-\n3-4 subproblem and the 5-6-7-8 subproblem for a given state will almost certainly share \nsome moves—it is unlikely that 1-2-3-4 can be moved into place without touching 5-6-7-\n8, and vice versa. But what if we don’t count those moves? That is, we record not the total \ncost of solving the 1-2- 3-4 subproblem, but just the number of moves involving 1-2-3-4. \nThen it is easy to see that the sum of the two costs is still a lower bound on the cost of \nsolving the entire problem. This is the idea behind disjoint pattern databases. With such \ndatabases, it is possible to solve random 15-puzzles in a few milliseconds—the number of \nnodes generated is reduced by a factor of 10,000 compared with the use of Manhattan \ndistance. For 24-puzzles, a speedup of roughly a factor of a million can be obtained. Disjoint \npattern databases work for sliding-tile puzzles because the problem can be divided up in \nsuch a way that each move affects only one subproblem—because only one tile is moved \nat a time. For a problem such as Rubik’s Cube, this kind of subdivision is difficult because \neach move affects 8 or 9 of the 26 cubies. More general ways of defining additive, \nadmissible heuristics have been proposed that do apply to Rubik’s cube (Yang et al., 2008), \nbut they have not yielded a heuristic better than the best nonadditive heuristic for the \nproblem.  \n3.6.4 Learning heuristics from experience  \nA heuristic function h(n) is supposed to estimate the cost of a solution beginning from the \nstate at node n. How could an agent construct such a function? One solution was given in \nthe preceding sections—namely, to devise relaxed problems for which an optimal solution \ncan be found easily. Another solution is to learn from experience. “Experience” here means \nsolving lots of 8-puzzles, for instance. Each optimal solution to an 8-puzzle problem \nprovides examples from which h(n) can be learned. Each example consists of a state from \nthe solution path and the actual cost of the solution from that point. From these examples, \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":12}}}],["3e660b45-e0a8-44f6-8e49-ce58ef0d3d9c",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    13 \na learning algorithm can be used to construct a function h(n) that can (with luck) predict \nsolution costs for other states that arise during search. Techniques for doing just this using \nneural nets, decision trees, and other methods are demonstrated in Chapter 18. (The \nreinforcement learning methods described in Chapter 21 are also applicable.) Inductive \nlearning methods work best when supplied with features of a state that are relevant to \npredicting the state’s value, rather than with just the raw state description. For example, \nthe feature “number of misplaced tiles” might be helpful in predicting the actual distance \nof a state from the goal. Let’s call this feature x1(n). We could take 100 randomly generated \n8-puzzle configurations and gather statistics on their actual solution costs. We might find \nthat when x1(n) is 5, the average solution cost is around 14, and so on. Given these data, \nthe value of x1 can be used to predict h(n). Of course, we can use several features. A second \nfeature x2(n) might be “number of pairs of adjacent tiles that are not adjacent in the goal \nstate.” How should x1(n) and x2(n) be combined to predict h(n)? A common approach is \nto use a linear combination:  \nh(n) = c1x1(n) + c2x2(n) .  \nThe constants c1 and c2 are adjusted to give the best fit to the actual data on solution costs. \nOne expects both c1 and c2 to be positive because misplaced tiles and incorrect adjacent \npairs make the problem harder to solve. Notice that this heuristic does satisfy the condition \nthat h(n)=0 for goal states, but it is not necessarily admissible or consistent. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nINTRODUCTION TO MACHINE LEARNING \n \n1.1 NEED FOR MACHINE LEARNING \nBusiness organizations use huge amount of data for their daily activities. They have now \nstarted to use the latest technology, machine learning, to manage the data. \nMachine learning has become so popular because of three reasons: \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":13}}}],["7f7e796f-4354-43ea-97cc-fb146133274e",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    14 \n1. High volume of available data to manage: Big companies such as Facebook, \nTwitter,  and YouTube  generate  huge  amount  of  data  that  grows  at  a \nphenomenal rate. It is estimated that the data approximately gets doubled \nevery year. \n \n2. Second reason is that the cost of storage has reduced. The hardware cost has \nalso dropped. Therefore, it is easier now to capture, process, store, distribute, \nand transmit the digital information. \n3. Third reason for popularity of machine learning is the availability of complex \nalgorithms now.  Especially  with  the  advent  of  deep  learning,  many \nalgorithms are available for machine learning. \nlet us establish these terms - data, information, knowledge, intelligence, and wisdom \nusing a knowledge pyramid as shown in Figure 1.1. \n \nFigure 1.1: The Knowledge Pyramid \n All facts are data. Data can be numbers or text that can be processed by a computer. \nToday, organizations are accumulating vast and growing amounts of data with data \nsources such as flat files, databases, or data warehouses in different storage \nformats.  \n Processed data is called information. This includes patterns, associations, or \nrelationships among data. For example, sales data can be analyzed to extract \ninformation like which is the fast selling product.  \n Condensed information is called knowledge. For example, the historical patterns \nand future trends obtained in the above sales data can be called knowledge. Unless \nknowledge is extracted, data is of no use. Similarly, knowledge is not useful \nunless it is put into action.  \n Intelligence is the applied knowledge for actions. An actionable form of \nknowledge is called intelligence. Computer systems have been successful till this \nstage.  \n The ultimate objective of knowledge pyramid is wisdom that represents the \nmaturity of mind that is, so far, exhibited only by humans. \n \n \n \n \n \n \n \n \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":14}}}],["7169f5e4-11bf-479b-b452-0b67b6990f70",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    15 \nThe objective of machine learning is to process these archival data for \norganizations to take better decisions to design new products, improve the \nbusiness processes, and to develop effective decision support systems. \n \n1.2 MACHINE LEARNING EXPLAINED \nMachine  learning  is  an  important  sub-branch  of  Artificial  Intelligence  (AI).  A \nfrequently quoted definition of machine learning was by Arthur Samuel, one of the \npioneers of Artificial Intelligence. He stated that “Machine learning is the field of \nstudy that gives the computers ability to learn without being explicitly \nprogrammed.” \nThe key to this definition is that the systems should learn by itself without explicit \nprogramming. How is it possible? It is widely known that to perform a computation, \none needs to write programs that teach the computers how to do that computation. \nIn  conventional  programming, after  understanding  the  problem,  a  detailed \ndesign of the program such as a flowchart or an algorithm needs to be created and \nconverted into programs using a suitable programming language. This approach \ncould be difficult for many real-world problems such as puzzles, games, and complex \nimage recognition applications. Initially, artificial intelligence aims to understand \nthese problems and develop general purpose rules manually. Then, these rules are \nformulated into logic and implemented in a program to create intelligent systems. \nThis idea of developing intelligent systems by using logic and reasoning by converting \nan expert’s knowledge into a set of rules and programs is called an expert system. An \nexpert system like MYCIN was designed for medical diagnosis after converting the \nexpert knowledge of many doctors into a system. However, this approach did not \nprogress much as programs lacked real intelligence. The word MYCIN is derived from \nthe fact that most of the antibiotics’ names end with ‘mycin’. \nThe  above  approach  was  impractical  in  many  domains  as  programs  still \ndepended on human expertise and hence did not truly exhibit intelligence. Then, the \nmomentum shifted to machine learning in the form of data driven systems. The focus \nof AI is to develop intelligent systems by using data-driven approach, where data is \nused as an input to develop intelligent models. The models can then be used to predict \nnew inputs. Thus, the aim of machine learning is to learn a model or set of rules from \nthe given dataset automatically so that it can predict the unknown data correctly. \nAs humans take decisions based on an experience, computers make models based \non extracted patterns in the input data and then use these data-filled models for \nprediction and to take decisions. For computers, the learnt model is equivalent to \nhuman experience. This is shown in Figure 1.2. \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":15}}}],["acf53c61-4ac8-42d2-9df7-efdc60566caa",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    16 \n \n \n \nFigure 1.2: (a) A Learning System for Humans (b) A Learning System for \nMachine Learning \nOften, the quality of data determines the quality of experience and, therefore, the quality of the \nlearning system. In statistical learning, the relationship between the input x and output y is \nmodeled as a function in the form y = f(x). Here, f is the learning function that maps the input x to \noutput y. Learning of function f is the crucial aspect of forming a model in statistical learning. In \nmachine learning, this is simply called mapping of input to output. \nThe learning program summarizes the raw data in a model. Formally stated, a model is an explicit \ndescription of patterns within the data in the form of: \n1. Mathematical equation \n2. Relational diagrams like trees/graphs \n3. Logical if/else rules, or \n4. Groupings called clusters \nIn summary, a model can be a formula, procedure or representation that can generate data \ndecisions. The difference between pattern and model is that the former is local and applicable only to \ncertain attributes but the latter is global and fits the entire dataset. For example, a model can be helpful \nto examine whether a given email is spam or not. The point is that the model is generated automatically \nfrom the given data. \nAnother pioneer of AI, Tom Mitchell’s definition of machine learning states that, “A computer \nprogram is said to learn from experience E, with respect to task T and some performance measure \nP, if its performance on T measured by P improves with experience E.” The important components of this \ndefinition are experience E, task T, and performance measure P. \nFor example, the task T could be detecting an object in an image. The machine can gain the \nknowledge of object using training dataset of thousands of images. This is called experience E. So, \nthe focus is to use this experience E for this task of object detection T. The ability of the system to detect \nthe object is measured by performance measures like precision and recall. Based on the performance \nmeasures, course correction can be done to improve the performance of the system. \nModels of computer systems are equivalent to human experience. Experience is based on data. \nHumans gain experience by various means. They gain knowledge by rote learning. They observe others \nand imitate it. Humans gain a lot of knowledge from teachers and books. We learn many things by trial and \nerror. Once the knowledge is gained, when a new problem is encountered, humans search for similar \npast situations and then formulate the heuristics and use that for prediction. But, in systems, \nexperience is gathered by these steps: \n1. Collection of data \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":16}}}],["24364b9a-6144-4430-8af8-85da5556250e",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    17 \n2. Once data is gathered, abstract concepts are formed out of that data. Abstraction is used to \ngenerate concepts. This is equivalent to humans’ idea of objects, for example, we have some \nidea about how an elephant looks like. \n3. Generalization   converts   the   abstraction   into   an   actionable   form   of   intelligence. It can \nbe viewed as ordering of all possible concepts. So, generalization involves ranking of concepts, \ninferencing from them and formation of heuristics, an actionable aspect of intelligence. \nHeuristics are educated guesses for all tasks. For example, if one runs or encounters a danger, \nit is the resultant of human experience or his heuristics formation. In machines, it happens \nthe same way. \n4. Heuristics normally works! But, occasionally, it may fail too. It is not the fault of \nheuristics as it is just a ‘rule of thumb′. The course correction is done by taking \nevaluation measures. Evaluation checks the thoroughness of the models and to-do course \ncorrection, if necessary, to generate better formulations. \n \n1.3 MACHINE LEARNING IN RELATION TO OTHER FIELDS \nMachine learning uses the concepts of Artificial Intelligence, Data Science, and Statistics primarily. It is \nthe resultant of combined ideas of diverse fields. \n \n1.3.1 Machine Learning and Artificial Intelligence \nMachine learning is an important branch of AI, which is a much broader subject. The aim of AI is to \ndevelop intelligent agents. An agent can be a robot, humans, or any autonomous systems. Initially, the \nidea of AI was ambitious, that is, to develop intelligent systems like human beings. The focus was on \nlogic and logical inferences. It had seen many ups and downs. These down periods were called AI \nwinters. \nThe resurgence in AI happened due to development of data driven systems. The aim is to find \nrelations and regularities present in the data. Machine learning is the subbranch of AI, whose aim is to \nextract the patterns for prediction. It is a broad field that includes learning from examples and other \nareas like reinforcement learning. The relationship of AI and machine learning is shown in Figure 1.3. \nThe model can take an unknown instance and generate results. \nFigure 1.3: Relationship of AI with Machine Learning \nDeep learning is a subbranch of machine learning. In deep learning, the models are constructed using \nneural network technology. Neural networks are based on the human neuron models. Many neurons \nform a network connected with the activation functions that trigger further neurons to perform tasks. \n \nintelligence \n \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":17}}}],["5380a951-6b83-409e-87ba-52deeec0163c",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    18 \n1.3.2 Machine Learning, Data Science, Data Mining, and Data Analytics \nData science is an ‘Umbrella’ term that encompasses many fields. Machine learning starts with data. \nTherefore, data science and machine learning are interlinked. Machine learning is a branch of data \nscience. Data science deals with gathering of data for analysis. It is a broad field that includes: \nBig Data Data science concerns about collection of data. Big data is a field of data science that deals \nwith data’s following characteristics: \n1. Volume: Huge amount of data is generated by big companies like Facebook, Twitter, \nYouTube. \n2. Variety: Data is available in variety of forms like images, videos, and in different formats. \n3. Velocity: It refers to the speed at which the data is generated and processed. \nBig data is used by many machine learning algorithms for applications such as language trans- lation \nand image recognition. Big data influences the growth of subjects like Deep learning. Deep learning is \na branch of machine learning that deals with constructing models using neural networks. \n \nData Mining Data mining’s original genesis is in the business. Like while mining the earth one gets \ninto precious resources, it is often believed that unearthing of the data produces hidden infor- mation \nthat otherwise would have eluded the attention of the management. Nowadays, many consider that \ndata mining and machine learning are same. There is no difference between these fields except that \ndata mining aims to extract the hidden patterns that are present in the data, whereas, machine learning \naims to use it for prediction. \n \nData Analytics Another branch of data science is data analytics. It aims to extract useful knowledge \nfrom crude data. There are different types of analytics. Predictive data analytics is used for making \npredictions. Machine learning is closely related to this branch of analytics and shares almost all \nalgorithms. \nPattern Recognition It is an engineering field. It uses machine learning algorithms to extract the \nfeatures for pattern analysis and pattern classification. One can view pattern recognition as a specific \napplication of machine learning. \nThese relations are summarized in Figure 1.4. \nData science \n \n \n \n \nFigure 1.4: Relationship of Machine Learning with Other Major Fields \n \n1.3.3 Machine Learning and Statistics \nStatistics is a branch of mathematics that has a solid theoretical foundation regarding statistical learning. Like \nmachine learning (ML), it can learn from data. But the difference between statistics and ML is that statistical \n \nanalytics \n \n \n \n \n \n \n \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":18}}}],["d163af36-2361-405c-8b5e-b98ddfdce537",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    19 \n \nSupervised \n \n \n \n \n \n \n \n \nCluster \nanalysis \n \n \n \nSemi-supervised \n \nmethods look for regularity in data called patterns. Initially, statistics sets a hypothesis and performs \nexperiments to verify and validate the hypothesis in order to find relationships among data. \nStatistics requires knowledge of the statistical procedures and the guidance of a good statistician. \nIt  is  mathematics  intensive  and  models  are  often  complicated  equations  and  involve many \nassumptions. Statistical methods are developed in relation to the data being analyzed. In addition, \nstatistical methods are coherent and rigorous. It has strong theoretical foundations and interpretations \nthat require a strong statistical knowledge. \nMachine learning, comparatively, has less assumptions and requires less statistical knowledge. \nBut, it often requires interaction with various tools to automate the process of learning. \nNevertheless, there is a school of thought that machine learning is just the latest version of ‘old \nStatistics’ and hence this relationship should be recognized. \n \n1.4 TYPES OF MACHINE LEARNING \nWhat does the word ‘learn’ mean? Learning, like adaptation, occurs as the result of interaction of the \nprogram with its environment. It can be compared with the interaction between a teacher and a \nstudent. There are four types of machine learning as shown in Figure 1.5. \n \n \n \n \n \n \nFigure 1.5: Types of Machine Learning \nBefore discussing the types of learning, it is necessary to discuss about data. \n \nLabelled and Unlabeled Data Data is a raw fact. Normally, data is represented in the form of a \ntable. Data also can be referred to as a data point, sample, or an example. Each row of the table \nrepresents a data point. Features are attributes or characteristics of an object. Normally, the columns \nof the table are attributes. Out of all attributes, one attribute is important and is called a label. Label is \nthe feature that we aim to predict. Thus, there are two types of data – labelled and unlabeled. \n \nLabelled Data To illustrate labelled data, let us take one example dataset called Iris flower dataset or \nFisher’s Iris dataset. The dataset has 50 samples of Iris – with four attributes, length and width of sepals \nand petals. The target variable is called class. There are three classes – Iris setosa, Iris virginica, and \nIris versicolor. \nThe partial data of Iris dataset is shown in Table 1.1. \nTable 1.1: Iris Flower Dataset \n \n \n \nReinforcement \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":19}}}],["c3749e75-95e6-49e1-a1ee-11ea38444422",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    20 \n \nS.No. Length   of \nPetal \nWidth of \nPetal \nLength of \nSepal \nWidth of \nSepal \nClass \n1. 5.5 4.2 1.4 0.2 Setosa \n2. 7 3.2 4.7 1.4 Versicolor \n3. 7.3 2.9 6.3 1.8 Virginica \nA dataset need not be always numbers. It can be images or video frames. Deep neural networks can \nhandle images with labels. In the following Figure 1.6, the deep neural network takes images of dogs and \ncats with labels for classification. \n(a) \n \n(b) \n \nFigure 1.6: (a) Labelled Dataset (b) Unlabeled Dataset \nIn unlabeled data, there are no labels in the dataset. \n \n1.4.1 Supervised Learning \nSupervised algorithms use labelled dataset. As the name suggests, there is a supervisor or teacher \ncomponent in supervised learning. A supervisor provides labelled data so that the model is constructed \nand generates test data. \nIn supervised learning algorithms, learning takes place in two stages. In layman terms, during the first \nstage, the teacher communicates the information to the student that the student is supposed to master. \nThe student receives the information and understands it. During this stage, the teacher has no knowledge \nof whether the information is grasped by the student. \nThis leads to the second stage of learning. The teacher then asks the student a set of questions to \nfind out how much information has been grasped by the student. Based on these questions, \n \nthe student is tested, and the teacher informs the student about his assessment. This kind of learning is \ntypically called supervised learning. \nSupervised learning has two methods: \n1. Classification \n2. Regression \n \n \n \n  \n \nCat \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":20}}}],["75c5d784-e0ff-4bc4-8aff-f66538aa832e",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    21 \nClassification \nClassification is a supervised learning method. The input attributes of the classification algorithms are \ncalled independent variables. The target attribute is called label or dependent variable. The \nrelationship between the input and target variable is represented in the form of a structure which is \ncalled a classification model. So, the focus of classification is to predict the ‘label’ that is in a discrete \nform (a value from the set of finite values). An example is shown in Figure 1.7 where a classification \nalgorithm takes a set of labelled data images such as dogs and cats to construct a model that can later \nbe used to classify an unknown test image data. \n \n \n \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":21}}}],["a2426c77-7173-43ab-8192-8a592131745c",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    22 \ny\n-\naxis\n \n-\n \nProduct sales\n \ndata (y)\n \nIn classification, learning takes place in two stages. During the first stage, called training stage, the learning \nalgorithm takes a labelled dataset and starts learning. After the training set, samples are processed and \nthe model is generated. In the second stage, the constructed model is tested with test or unknown sample \nand assigned a label. This is the classification process. \nThis is illustrated in the above Figure 1.7. Initially, the classification learning algorithm learns with \nthe collection of labelled data and constructs the model. Then, a test case is selected, and the model \nassigns a label. \nSimilarly, in the case of Iris dataset, if the test is given as (6.3, 2.9, 5.6, 1.8, ?), the classification will \ngenerate the label for this. This is called classification. One of the examples of classification is – Image \nrecognition, which includes classification of diseases like cancer, classification of plants, etc. \nThe classification models can be categorized based on the implementation technology like decision \ntrees, probabilistic methods, distance measures, and soft computing methods. Classification models can \nalso be classified as generative models and discriminative models. Generative models deal with the \nprocess of data generation and its distribution. Probabilistic models are examples of \n \ngenerative models. Discriminative models do not care about the generation of data. Instead, they \nsimply concentrate on classifying the given data. \nSome of the key algorithms of classification are: \n• Decision Tree \n• Random Forest \n• Support Vector Machines \n• Naï ve Bayes \n• Artificial Neural Network and Deep Learning networks like CNN \n \nRegression Models \nRegression models, unlike classification algorithms, predict continuous variables like price. In \nother words, it is a number. A fitted regression model is shown in Figure 1.8 for a dataset that represent \nweeks input x and product sales y. \n4 \n \n3.5 \n \n3 \n \n2.5 \n \n2 \n \n1.5  \n \n1 \n1 2 3 4 5 \nx-axis - Week data (x) \nRegression line (y = 0.66X + 0.54) \n \nFigure 1.8: A Regression Model of the Form y = ax + b \nThe regression model takes input x and generates a model in the form of a fitted line of the form y \n= f(x). Here, x is the independent variable that may be one or more attributes and y is the dependent \nvariable. In Figure 1.8, linear regression takes the training set and tries to fit it with a line – product \nsales = 0.66  Week + 0.54. Here, 0.66 and 0.54 are all regression coefficients that are learnt from data. \nThe advantage of this model is that prediction for product sales (y) can be made for unknown week \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":22}}}],["18c42fac-c17b-4442-bc2a-a9ee353ffc35",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    23 \ndata (x). For example, the prediction for unknown eighth week can be made by substituting x as 8 in that \nregression formula to get y. \nOne of the most important regression algorithms is linear regression that is explained in the next \nsection. \nBoth regression and classification models are supervised algorithms. Both have a supervisor and the \nconcepts of training and testing are applicable to both. What is the difference between classification and \nregression models? The main difference is that regression models predict continuous variables such as \nproduct price, while classification concentrates on assigning labels such as class. \n1.4.2 Unsupervised Learning \nThe second kind of learning is by self-instruction. As the name suggests, there are no supervisor or \nteacher components. In the absence of a supervisor or teacher, self-instruction is the most common kind \nof learning process. This process of self-instruction is based on the concept of trial and error. \nHere, the program is supplied with objects, but no labels are defined. The algorithm itself observes \nthe examples and recognizes patterns based on the principles of grouping. Grouping is done in ways \nthat similar objects form the same group. \nCluster analysis and Dimensional reduction algorithms are examples of unsupervised algorithms. \n \nCluster Analysis \nCluster analysis is an example of unsupervised learning. It aims to group objects into disjoint clusters \nor groups. Cluster analysis clusters objects based on its attributes. All the data objects of the \npartitions are similar in some aspect and vary from the data objects in the other partitions significantly. \nSome of the examples of clustering processes are — segmentation of a region of interest in an \nimage, detection of abnormal growth in a medical image, and determining clusters of signatures in a \ngene database. \nAn example of clustering scheme is shown in Figure 1.9 where the clustering algorithm takes a set \nof dogs and cats images and groups it as two clusters-dogs and cats. It can be observed that the samples \nbelonging to a cluster are similar and samples are different radically across clusters. \n \n \n \nSome of the key clustering algorithms are: \n• k-means algorithm \n• Hierarchical algorithms \nDimensionality Reduction \nDimensionality reduction algorithms are examples of unsupervised algorithms. It takes a higher \ndimension data as input and outputs the data in lower dimension by taking advantage of the variance of the \ndata. It is a task of reducing the dataset with few features without losing the generality. \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":23}}}],["c6cbf59c-eefc-4559-ae4c-4092e413ba61",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    24 \nThe differences between supervised and unsupervised learning are listed in the following \nTable 1.2. \nTable 1.2: Differences between Supervised and Unsupervised Learning \n \nS.No. Supervised Learning Unsupervised Learning \n1. There is a supervisor component No supervisor component \n2. Uses Labelled data Uses Unlabelled data \n3. Assigns categories or labels Performs grouping process such that similar objects will \nbe in one cluster \n \n1.4.3 Semi-supervised Learning \nThere are circumstances where the dataset has a huge collection of unlabelled data and some labelled \ndata. Labelling is a costly process and difficult to perform by the humans. Semi-supervised algorithms use \nunlabelled data by assigning a pseudo-label. Then, the labelled and pseudo-labelled dataset can be \ncombined. \n1.4.4 Reinforcement Learning \nReinforcement learning mimics human beings. Like human beings use ears and eyes to perceive the world \nand take actions, reinforcement learning allows the agent to interact with the environment to get \nrewards. The agent can be human, animal, robot, or any independent program. The rewards enable the \nagent to gain experience. The agent aims to maximize the reward. \nThe reward can be positive or negative (Punishment). When the rewards are more, the behavior gets \nreinforced and learning becomes possible. \nConsider the following example of a Grid game as shown in Figure 1.10. \nBlock \n \n \nGoal \n \n \n \n \n \n \nDanger \n \n \nFigure 1.10: A Grid game \n   \n   \n   \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":24}}}],["11cb1f5b-b642-4481-8a89-ee4e72504872",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n \n                                                   \n \n                                                    25 \nIn this grid game, the gray tile indicates the danger, black is a block, and the tile with diagonal lines \nis the goal. The aim is to start, say from bottom-left grid, using the actions left, right, top and bottom to \nreach the goal state. \nTo solve this sort of problem, there is no data. The agent interacts with the environment to get \nexperience. In the above case, the agent tries to create a model by simulating many paths and finding \nrewarding paths. This experience helps in constructing a model. \nIt can be said in summary, compared to supervised learning, there is no supervisor or labelled \ndataset. Many sequential decisions need to be taken to reach the final decision. Therefore, \nreinforcement algorithms are reward-based, goal-oriented algorithms. \n \n \n1.5 CHALLENGES OF MACHINE LEARNING \nWhat are the challenges of machine learning? Let us discuss about them now. \n \nProblems that can be Dealt with Machine Learning \nComputers are better than humans in performing tasks like computation. For example, while calculating the \nsquare root of large numbers, an average human may blink but computers can display the result in seconds. \nComputers can play games like chess, GO, and even beat professional players of that game. \nHowever, humans are better than computers in many aspects like recognition. But, deep learning \nsystems challenge human beings in this aspect as well. Machines can recognize human faces in a \nsecond. Still, there are tasks where humans are better as machine learning systems still require quality \ndata for model construction. The quality of a learning system depends on the quality of data. This is a \nchallenge. Some of the challenges are listed below: \n1. Problems – Machine learning can deal with the ‘well-posed’ problems where specifications are \ncomplete and available. Computers cannot solve ‘ill-posed’ problems. \nConsider one simple example (shown in Table 1.3): \nTable 1.3: An Example \n \nInput (x\n1\n, x\n2\n) Output (y) \n1, 1 1 \n2, 1 2 \n3, 1 3 \n4, 1 4 \n5, 1 5 \nCan a model for this test data be multiplication? That is, y  x  x . Well! It is true! But, this is \n1 2 \nequally true that y may be y  x  x , or y  x \nx\n2\n. So, there are three functions that fit the data. \n1 2 1 \nThis means that the problem is ill-posed. To solve this problem, one needs more example to \ncheck the model. Puzzles and games that do not have sufficient specification may become an ill-\nposed problem and scientific computation has many ill-posed problems. \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":25}}}],["b62e55d5-cafd-4d34-927c-211929e51801",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n26 \n \n2. Huge data – This is a primary requirement of machine learning. Availability of a quality data is \na challenge. A quality data means it should be large and should not have data problems such \nas missing data or incorrect data. \n3. High computation power – With the availability of Big Data, the computational resource \nrequirement has also increased. Systems with Graphics Processing Unit (GPU) or even Tensor \nProcessing Unit (TPU) are required to execute machine learning algorithms. Also, machine \nlearning tasks have become complex and hence time complexity has increased, and that can \nbe solved only with high computing power. \n4. Complexity of the algorithms – The selection of algorithms, describing the algorithms, \napplication of algorithms to solve machine learning task, and comparison of algorithms have \nbecome necessary for machine learning or data scientists now. Algorithms have become a big \ntopic of discussion and it is a challenge for machine learning professionals to design, select, and \nevaluate optimal algorithms. \n5. Bias/Variance – Variance is the error of the model. This leads to a problem called bias/ \nvariance tradeoff. A model that fits the training data correctly but fails for test data, in general \nlacks generalization, is called overfitting. The reverse problem is called underfitting where the \nmodel fails for training data but has good generalization. Overfitting and underfitting are great \nchallenges for machine learning algorithms. \n \n1.6 MACHINE LEARNING PROCESS \nThe emerging process model for the data mining solutions for business organizations is CRISP-DM. Since \nmachine learning is like data mining, except for the aim, this process can be used for machine learning. \nCRISP-DM stands for Cross Industry Standard Process – Data Mining. This process involves six steps. \nThe steps are listed below in Figure 1.11. \n \n \n \n \n \n \nModel evaluation \n  \n \nModel deployment \nFigure 1.11: A Machine Learning/Data Mining Process \n \n \n \nUnderstand the \nbusiness \npreprocessing \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":26}}}],["69e7a072-90e2-4576-89ef-952c85e61eab",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n27 \n \n1. Understanding the business – This step involves understanding the objectives and \nrequirements of the business organization. Generally, a single data mining algorithm is enough \nfor giving the solution. This step also involves the formulation of the problem statement for \nthe data mining process. \n2. Understanding the data – It involves the steps like data collection, study of the charac teristics \nof the data, formulation of hypothesis, and matching of patterns to the selected hypothesis. \n3. Preparation of data – This step involves producing the final dataset by cleaning the raw data \nand preparation of data for the data mining process. The missing values may cause problems \nduring both training and testing phases. Missing data forces classifiers to produce inaccurate \nresults. This is a perennial problem for the classification models. Hence, suitable strategies \nshould be adopted to handle the missing data. \n4. Modelling – This step plays a role in the application of data mining algorithm for the data to \nobtain a model or pattern. \n5. Evaluate – This step involves the evaluation of the data mining results using statistical analysis \nand visualization methods. The performance of the classifier is determined by evaluating the \naccuracy of the classifier. The process of classification is a fuzzy issue. For example, \nclassification of emails requires extensive domain knowledge and requires domain experts. \nHence, performance of the classifier is very crucial. \n6. Deployment – This step involves the deployment of results of the data mining algorithm to \nimprove the existing process or for a new situation. \n \n1.7 MACHINE LEARNING APPLICATIONS \nMachine Learning technologies are used widely now in different domains. Machine learning appli cations \nare everywhere! One encounters many machine learning applications in the day-to-day life. Some \napplications are listed below: \n1. Sentiment analysis – This is an application of natural language processing (NLP) where the \nwords of documents are converted to sentiments like happy, sad, and angry which are captured \nby emoticons effectively. For movie reviews or product reviews, five stars or one star are \nautomatically attached using sentiment analysis programs. \n2. Recommendation systems – These are systems that make personalized purchases possible. For \nexample, Amazon recommends users to find related books or books bought by people who have \nthe same taste like you, and Netflix suggests shows or related movies of your taste. The \nrecommendation systems are based on machine learning. \n3. Voice assistants – Products like Amazon Alexa, Microsoft Cortana, Apple Siri, and Google \nAssistant are all examples of voice assistants. They take speech commands and perform tasks. \nThese chatbots are the result of machine learning technologies. \n4. Technologies like Google Maps and those used by Uber are all examples of machine learning \nwhich offer to locate and navigate shortest paths to reduce time. \nThe machine learning applications are enormous. The following Table 1.4 summarizes some of the \nmachine learning applications. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":27}}}],["42e8caca-b55c-4962-b7f6-b5a3685a16e0",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n28 \nTable 1.4: Applications’ Survey Table \n \nS.No. Problem Domain Applications \n1. Business Predicting the bankruptcy of a business firm \n2. Banking Prediction of bank loan defaulters and detecting credit card frauds \n3. Image Processing Image search engines, object identification, image classification, and \ngenerating synthetic images \n4. Audio/Voice Chatbots like Alexa, Microsoft Cortana. Developing chatbots for customer \nsupport, speech to text, and text to voice \n5. Telecommuni- \ncation \nTrend analysis and identification of bogus calls, fraudulent calls and \nits callers, churn analysis \n6. Marketing Retail sales analysis, market basket analysis, product performance \nanalysis, market segmentation analysis, and study of travel patterns of \ncustomers for marketing tours \n7. Games Game programs for Chess, GO, and Atari video games \n8. Natural Language \nTranslation \nGoogle Translate, Text summarization, and sentiment analysis \n9. Web  Analysis and \nServices \nIdentification of access patterns, detection of e-mail spams, viruses, \npersonalized  web  services,  search engines  like  Google,  detection  of \npromotion of user websites, and finding loyalty of users after web page \nlayout modification \n10. Medicine Prediction of diseases, given disease symptoms as cancer or diabetes. \nPrediction of effectiveness of the treatment using patient history and \nChatbots to interact with patients like IBM Watson uses machine learning \ntechnologies. \n11. Multimedia and \nSecurity \nFace recognition/identification, biometric projects like identification of \na person from a large image or video database, and applications involving \nmultimedia retrieval \n12. Scientific Domain Discovery of new galaxies, identification of groups of houses based on \nhouse type/geographical location, identification of earthquake \nepicenters, and identification of similar land use \n \nKey Terms:  \n• Machine Learning – A branch of AI that concerns about machines to learn automatically without being \nexplicitly programmed. \n• Data – A raw fact. \n• Model – An explicit description of patterns in a data. \n• Experience – A collection of knowledge and heuristics in humans and historical training data in case of \nmachines. \n• Predictive Modelling – A technique of developing models and making a prediction of unseen data. \n• Deep Learning – A branch of machine learning that deals with constructing models using neural \nnetworks. \n• Data Science – A field of study that encompasses capturing of data to its analysis covering all stages of \ndata management. \n• Data Analytics – A field of study that deals with analysis of data. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":28}}}],["09fadf68-ed7d-4e41-b00c-18833b3ba72e",{"pageContent":" \nAI&ML,  21CS54, 5\nth\n Semester \n \n \n29 \n• Big Data – A study of data that has characteristics of volume, variety, and velocity. \n \n• Statistics – A branch of mathematics that deals with learning from data using statistical methods. \n• Hypothesis – An initial assumption of an experiment. \n• Learning – Adapting to the environment that happens because of interaction of an agent with the \nenvironment. \n• Label – A target attribute. \n• Labelled Data – A data that is associated with a label. \n• Unlabelled Data – A data without labels. \n• Supervised Learning – A type of machine learning that uses labelled data and learns with the help of a \nsupervisor or teacher component. \n• Classification Program – A supervisory learning method that takes an unknown input and assigns a \nlabel for it. In simple words, finds the category of class of the input attributes. \n• Regression Analysis – A supervisory method that predicts the continuous variables based on the input \nvariables. \n• Unsupervised Learning – A type of machine leaning that uses unlabelled data and groups the attributes \nto clusters using a trial and error approach. \n• Cluster Analysis – A type of unsupervised approach that groups the objects based on attributes so \nthat similar objects or data points form a cluster. \n• Semi-supervised Learning – A type of machine learning that uses limited labelled and large unlabelled \ndata. It first labels unlabelled data using labelled data and combines it for learning purposes. \n• Reinforcement Learning – A type of machine learning that uses agents and environment interaction for \ncreating labelled data for learning. \n• Well-posed Problem – A problem that has well-defined specifications. Otherwise, the problem is called \nill-posed. \n• Bias/Variance – The inability of the machine learning algorithm to predict correctly due to lack of \ngeneralization is called bias. Variance is the error of the model for training data. This leads to problems \ncalled overfitting and underfitting. \n• Model Deployment – A method of deploying machine learning algorithms to improve the existing \nbusiness processes for a new situation. \n \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":29}}}],["79b3bacf-a1d7-4205-b5e4-3b34013335c0",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n30 \n \n \n \n2.1 WHAT IS DATA? \nAll facts are data. In computer systems, bits encode facts present in numbers, text, images, audio, \nand video. Data can be directly human interpretable (such as numbers or texts) or diffused data \nsuch as images or video that can be interpreted only by a computer.  \nData is available in different data sources like flat files, databases, or data warehouses. It can \neither be an operational data or a non-operational data. Operational data is the one that is \nencountered in normal business procedures  and processes. For example, daily sales data is \noperational data, on the other hand, non-operational data is the kind of data that is used for decision \nmaking.  \nData by itself is meaningless. It has to be processed to generate any information. A string of \nbytes is meaningless. Only when a label is attached like height of students of a class, the data \nbecomes meaningful. Processed data is called information that includes patterns, associations, or \nrelationships among data. For example, sales data can be analyzed to extract information like which \nproduct was sold larger in the last quarter of the year. \nElements of Big Data \nData whose volume is less and can be stored and processed by a small-scale computer is called ‘small \ndata’. These data are collected from several sources, and integrated and processed by a small-scale \ncomputer. Big data, on the other hand, is a larger data whose volume is much larger than ‘small data’ \nand is characterized as follows: \n1. Volume – Since there is a reduction in the cost of storing devices, there has been a \ntremendous growth of data. Small traditional data is measured in terms of gigabytes (GB) and \nterabytes (TB), but Big Data is measured in terms of petabytes (PB) and exabytes (EB). One exabyte \nis 1 million terabytes. \n2. Velocity – The fast arrival speed of data and its increase in data volume is noted as velocity. \nThe availability of IoT devices and Internet power ensures that the data is arriving at a faster rate. \nVelocity helps to understand the relative growth of big data and its accessibility by users, systems \nand applications.  \n3. Variety – The variety of Big Data includes:  \n• Form – There are many forms of data. Data types range from text, graph, audio, video, to \nmaps. There can be composite data too, where one media can have many other sources of \ndata, for example, a video can have an audio song. \n• Function – These are data from various sources like human conversations, transaction \nrecords, and old archive data. \n• Source of data – This is the third aspect of variety. There are many sources of data. Broadly, \nthe data source can be classified as open/public data, social media data and multimodal \ndata.  \n \nSome of the other forms of Vs that are often quoted in the literature as characteristics of   \nBig data are: \n4. Veracity of data – Veracity of data deals with aspects like conformity to the facts, truthfulness, \nbelievablity, and confidence in data. There may be many sources of error such as technical \nerrors, typographical errors, and human errors. So, veracity is one of  the most important \naspects of data. \n5. Validity – Validity is the accuracy of the data for taking decisions or for any other goals that \nare needed by the given problem.  \n6. Value – Value is the characteristic of big data that indicates the value of the information that \nis extracted from the data and its influence on the decisions that are taken based on it. \nThus, these 6 Vs are helpful to characterize the big data. The data quality of the numeric  \nattributes is determined by factors like precision, bias, and accuracy.  \n \nIntroduction to Machine Learning           21 ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":30}}}],["3cfa90dd-ad6c-4af2-842b-09fbcf107ca3",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n31 \n Precision is defined as the closeness of repeated measurements. Often, standard deviation is \nused to measure the precision.  \n Bias is a systematic result due to erroneous assumptions of the algorithms or procedures.  \n Accuracy is the degree of measurement of errors that refers to the closeness of measurements \nto the true value of the quantity. Normally, the significant digits used to store and manipulate \nindicate the accuracy of the measurement. \n \n2.1.1 Types of Data \nIn Big Data, there are three kinds of data. They are structured data, unstructured data, and semi-\nstructured data.  \n \nStructured Data \nIn structured data, data is stored in an organized manner such as a database where it is available in \nthe form of a table. The data can also be retrieved in an organized manner using tools like SQL. The \nstructured data frequently encountered in machine learning are listed below:  \n \nRecord Data A dataset is a collection of measurements taken from a process. We have a collection \nof objects in a dataset and each object has a set of measurements. The measurements can be \narranged in the form of a matrix. Rows in the matrix represent an object and can be called as entities, \ncases, or records. The columns of the dataset are called attributes, features, or fields. The table is \nfilled with observed data. Also, it is better to note the general jargons that are associated with the \ndataset. Label is the term that is used to describe the individual observations.  \n \nData Matrix It is a variation of the record type because it consists of numeric attributes.  The \nstandard matrix operations can be applied on these data. The data is thought of as points or vectors \nin the multidimensional space where every attribute is a dimension describing the object. \n \nGraph Data It involves the relationships among objects. For example, a web page can refer to \nanother web page. This can be modeled as a graph. The modes are web pages and the hyperlink is \nan edge that connects the nodes. \n \nOrdered Data Ordered data objects involve attributes that have an implicit order among them.  \nThe examples of ordered data are: \n Temporal data – It is the data whose attributes are associated with time. For example,  the \ncustomer purchasing patterns during festival time is sequential data. Time series data  is a \nspecial type of sequence data where the data is a series of measurements over time. \n  \n Sequence data – It is like sequential data but does not have time stamps. This data involves the \nsequence of words or letters. For example, DNA data is a sequence of four characters – A T G C.  \n \n Spatial data – It has attributes such as positions or areas. For example, maps are spatial data \nwhere the points are related by location. \n \n \nUnstructured Data \nUnstructured data includes video, image, and audio. It also includes textual documents, programs, \nand blog data. It is estimated that 80% of the data are unstructured data. \n \nSemi-Structured Data \nSemi-structured data are partially structured and partially unstructured. These include data like \nXML/JSON data, RSS feeds, and hierarchical data. \n \n2.1.2 Data Storage and Representation ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":31}}}],["befe85eb-9a55-43ac-a041-ab3e2401d3dc",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n32 \nOnce the dataset is assembled, it must be stored in a structure that is suitable for data analysis. The \ngoal of data storage management is to make data available for analysis. There are different \napproaches to organize and manage data in storage files and systems from flat file to data \nwarehouses. Some of them are listed below: \n \nFlat Files These are the simplest and most commonly available data source. It is also the cheapest \nway of organizing the data. These flat files are the files where data is stored in plain ASCII or EBCDIC \nformat. Minor changes of data in flat files affect the results of the data mining algorithms.  \nHence, flat file is suitable only for storing small dataset and not desirable if the dataset becomes \nlarger. \nSome of the popular spreadsheet formats are listed below: \n• CSV files – CSV stands for comma-separated value files where the values are separated by \ncommas. These are used by spreadsheet and database applications. The first row may have \nattributes and the rest of the rows represent the data.  \n• TSV files – TSV stands for Tab separated values files where values are separated by Tab. Both \nCSV and TSV files are generic in nature and can be shared. There are many tools like Google Sheets \nand Microsoft Excel to process these files. \nDatabase System It normally consists of database files and a database management system \n(DBMS). Database files contain original data and metadata. DBMS aims to manage data and improve \noperator performance by including various tools like database administrator, query processing, and \ntransaction manager. A relational database consists of sets of tables. The tables have rows and \ncolumns. The columns represent the attributes and rows represent tuples. A tuple corresponds to \neither an object or a relationship between objects. A user can access and manipulate the data in the \ndatabase using SQL.  \n \nDifferent types of databases are listed below: \n1 A transactional database is a collection of transactional records. Each record is a   \ntransaction. A transaction may have a time stamp, identifier and a set of items, which may have links \nto other tables. Normally, transaction databases are created for performing associational analysis \nthat indicates the correlation among the items.  \n2. Time-series database stores time related information like log files where data is associated \nwith a time stamp. This data represents the sequences of data, which represent values or events \nobtained over a period (for example, hourly, weekly or yearly) or repeated time span. Observing \nsales of product continuously may yield a time-series data. \n3. Spatial databases contain spatial information in a raster or vector format. Raster formats are \neither bitmaps or pixel maps. For example, images can be stored as a raster data.  On the other hand, \nthe vector format can be used to store maps as maps use basic geometric primitives like points, lines, \npolygons and so forth. \nWorld Wide Web (WWW) It provides a diverse, worldwide online information source.   \nThe objective of data mining algorithms is to mine interesting patterns of information present  in \nWWW. \nXML (eXtensible Markup Language) It is both human and machine interpretable data format that \ncan be used to represent data that needs to be shared across the platforms. \nData Stream It is dynamic data, which flows in and out of the observing environment. Typical \ncharacteristics of data stream are huge volume of data, dynamic, fixed order movement, and real-\ntime constraints.  \nRSS (Really Simple Syndication) It is a format for sharing instant feeds across services. \nJSON (JavaScript Object Notation) It is another useful data interchange format that is often used for \nmany machine learning algorithms. \n \n2.2 BIG DATA ANALYTICS AND TYPES OF ANALYTICS \nThe primary aim of data analysis is to assist business organizations to take decisions. For example, \na business organization may want to know which is the fastest selling product, in order for them to ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":32}}}],["4f200a6c-5c39-4eb7-a262-efb2ea819980",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n33 \nmarket activities. Data analysis is an activity that takes the data and generates useful information \nand insights for assisting the organizations. \nData analysis and data analytics are terms that are used interchangeably to refer to the same \nconcept. However, there is a subtle difference. Data analytics is a general term and data analysis is a \npart of it. Data analytics refers to the process of data collection, preprocessing and analysis.  It deals \nwith the complete cycle of data management. Data analysis is just analysis and is a part of  data \nanalytics. It takes historical data and does the analysis.  \nData analytics, instead, concentrates more on future and helps in prediction. \nThere are four types of data analytics:  \n1. Descriptive analytics \n2. Diagnostic analytics \n3. Predictive analytics \n4. Prescriptive analytics \n \nDescriptive Analytics It is about describing the main features of the data. After data collection is \ndone, descriptive analytics deals with the collected data and quantifies it. It is often stated that \nanalytics is essentially statistics. There are two aspects of statistics – Descriptive and Inference. \nDescriptive analytics only focuses on the description part of the data and not the inference part. \nDiagnostic Analytics It deals with the question – ‘Why?’. This is also known as causal analysis, as \nit aims to find out the cause and effect of the events. For example, if a product is not selling, \ndiagnostic analytics aims to find out the reason. There may be multiple reasons and associated \neffects are analyzed as part of it. \nPredictive Analytics It deals with the future. It deals with the question – ‘What will happen in \nfuture given this data?’. This involves the application of algorithms to identify the patterns to predict \nthe future. The entire course of machine learning is mostly about predictive analytics and forms the \ncore of this book. \nPrescriptive Analytics It is about the finding the best course of action for the business  \norganizations. Prescriptive analytics goes beyond prediction and helps in decision making by giving \na set of actions. It helps the organizations to plan better for the future and to mitigate the risks that \nare involved. \n \n2.3 BIG DATA ANALYSIS FRAMEWORK \nFor performing data analytics, many frameworks are proposed. All proposed analytics frameworks \nhave some common factors. Big data framework is a layered architecture. Such an architecture has \nmany advantages such as genericness. A 4-layer architecture has the following layers: \n1. Date connection layer \n2. Data management layer \n3. Data analytics later \n4. Presentation layer \nData Connection Layer It has data ingestion mechanisms and data connectors. Data ingestion  \nmeans taking raw data and importing it into appropriate data structures. It performs the tasks of \nETL process. By ETL, it means extract, transform and load operations.  \n \nData Management Layer It performs preprocessing of data. The purpose of this layer is to  \nallow parallel execution of queries, and read, write and data management tasks. There may be  \nmany schemes that can be implemented by this layer such as data-in-place, where the data is   \nnot moved at all, or constructing data repositories such as data warehouses and pull data   \non-demand mechanisms. \nData Analytic Layer It has many functionalities such as statistical tests, machine learning  \nalgorithms to understand, and construction of machine learning models. This layer implements  \nmany model validation mechanisms too. The processing is done as shown in Box 2.1. \n \nPresentation Layer It has mechanisms such as dashboards, and applications that display the  ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":33}}}],["b8f93337-e5a5-4913-bac3-b36b1c09c5cb",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n34 \nresults of analytical engines and machine learning algorithms. \nThus, the Big Data processing cycle involves data management that consists of the following  \nsteps.  \n1. Data collection \n2. Data preprocessing \n3. Applications of machine learning algorithm \n4. Interpretation of results and visualization of machine learning algorithm \nThis is an iterative process and is carried out on a permanent basis to ensure that data is suitable \nfor data mining. \nApplication and interpretation of machine learning algorithms constitute the basis for the rest  \nof the book. So, primarily, data collection and data preprocessing are covered as part of this chapter.  \n \n2.3.1 Data Collection \nThe first task of gathering datasets are the collection of data. It is often estimated that most of the \ntime is spent for collection of good quality data. A good quality data yields a better result. It is \noften difficult to characterize a ‘Good data’. ‘Good data’ is one that has the following properties: \n1. Timeliness – The data should be relevant and not stale or obsolete data. \n2. Relevancy – The data should be relevant and ready for the machine learning or data mining \nalgorithms. All the necessary information should be available and there should be no bias in \nthe data. \n3.     Knowledge about the data – The data should be understandable and interpretable, and should \nbe self-sufficient for the required application as desired by the domain knowledge engineer. \n \nBroadly, the data source can be classified as open/public data, social media data and multimodal \ndata. \n1. Open or public data source – It is a data source that does not have any stringent copyright  \nrules or restrictions. Its data can be primarily used for many purposes. Government census  \ndata are good examples of open data: \n• Digital libraries that have huge amount of text data as well as document images \n• Scientific domains with a huge collection of experimental data like genomic data   \nand biological data \n• Healthcare systems that use extensive databases like patient databases, health insurance  \ndata, doctors’ information, and bioinformatics information \n2. Social media – It is the data that is generated by various social media platforms like \nTwitter,  \nFacebook, YouTube, and Instagram. An enormous amount of data is generated by these  \nplatforms. \n3. Multimodal data – It includes data that involves many modes such as text, video, audio  \nand mixed types. Some of them are listed below: \n• Image archives contain larger image databases along with numeric and text data \n• The World Wide Web (WWW) has huge amount of data that is distributed on the Internet.  \nThese data are heterogeneous in nature. \n \n2.3.2 Data Preprocessing \nIn real world, the available data is ’dirty’. By this word ’dirty’, it means: \n• Incomplete data    •  Inaccurate data \n• Outlier data          •  Data with missing values \n• Data with inconsistent values        •  Duplicate data \nData preprocessing improves the quality of the data mining techniques. The raw data must  \nbe preprocessed to give accurate results. The process of detection and removal of errors in data  \nis called data cleaning. Data wrangling means making the data processable for machine learning  \nalgorithms. Some of the data errors include human errors such as typographical errors or \nincorrect  ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":34}}}],["712f68f2-d331-4519-8285-2bed7deebe85",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n35 \nmeasurement and structural errors like improper data formats. Data errors can also arise from  \nomission and duplication of attributes. Noise is a random component and involves distortion of   \na value or introduction of spurious objects. Often, the noise is used if the data is a spatial or   \ntemporal component. Certain deterministic distortions in the form of a streak are known as \nartifacts. \nConsider, for example, the following patient Table 2.1. The ‘bad’ or ‘dirty’ data can be observed  \nin this table. \n \n \nIt can be observed that data like Salary = ’ ’ is incomplete data. The DoB of patients, John, Andre, and \nRaju, is the missing data. The age of David is recorded as ‘5’ but his DoB indicates it is 10/10/1980. \nThis is called inconsistent data.  \n \nInconsistent data occurs due to problems in conversions, inconsistent formats, and difference in \nunits. Salary for John is -1500. It cannot be less than ‘0’. It is an instance of noisy data. Outliers are \ndata that exhibit the characteristics that are different from other data and have very unusual values. \nThe age of Raju cannot be 136. It might be a typographical error. It is often required to distinguish \nbetween noise and outlier data.  \nOutliers may be legitimate data and sometimes are of interest to the data mining algorithms. These \nerrors often come during data collection stage. These must be removed so that machine learning \nalgorithms yield better results as the quality of results is determined by the quality of input data. \nThis removal process is called data cleaning. \n \nMissing Data Analysis \nThe primary data cleaning process is missing data analysis. Data cleaning routines attempt to  fill \nup the missing values, smoothen the noise while identifying the outliers and correct the \ninconsistencies of the data. This enables data mining to avoid overfitting of the models.  \nThe procedures that are given below can solve the problem of missing data: \n1. Ignore the tuple – A tuple with missing data, especially the class label, is ignored. This  \nmethod is not effective when the percentage of the missing values increases. \n2. Fill in the values manually – Here, the domain expert can analyse the data tables and carry  \nout the analysis and fill in the values manually. But, this is time consuming and may not  \nbe feasible for larger sets. \n3. A global constant can be used to fill in the missing attributes. The missing values may be  \n’Unknown’ or be ’Infinity’. But, some data mining results may give spurious results by  \nanalysing these labels. \n4. The attribute value may be filled by the attribute value. Say, the average income can replace  \na missing value. \n5. Use the attribute mean for all samples belonging to the same class. Here, the average value  \nreplaces the missing values of all tuples that fall in this group. \n6. Use the most possible value to fill in the missing value. The most probable value can be  \nobtained from other methods like classification and decision tree prediction. \nSome of these methods introduce bias in the data. The filled value may not be correct and could  \nbe just an estimated value. Hence, the difference between the estimated and the original value is  \ncalled an error or bias. \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":35}}}],["63b8beef-e36d-483e-bd2d-241ff3b4d987",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n36 \nRemoval of Noisy or Outlier Data \nNoise is a random error or variance in a measured value. It can be removed by using binning,  \nwhich is a method where the given data values are sorted and distributed into equal frequency  \nbins. The bins are also called as buckets. The binning method then uses the neighbor values to  \nsmooth the noisy data.  \nSome of the techniques commonly used are ‘smoothing by means’ where the mean of the  \nbin removes the values of the bins, ‘smoothing by bin medians’ where the bin median replaces   \nthe bin values, and ‘smoothing by bin boundaries’ where the bin value is replaced by the closest   \nbin boundary. The maximum and minimum values are called bin boundaries. Binning methods  \nmay be used as a discretization technique. Example 2.1 illustrates this principle. \n \nExample 2.1:  Consider the following set: S = {12, 14, 19, 22, 24, 26, 28, 31, 34}. Apply various   \nbinning techniques and show the result. \nSolution: By equal-frequency bin method, the data should be distributed across bins. Let us  \nassume the bins of size 3, then the above data is distributed across the bins as shown below: \nBin 1 : 12 , 14, 19 \nBin 2 : 22, 24, 26 \nBin 3 : 28, 31, 32 \nBy smoothing bins method, the bins are replaced by the bin means. This method results in:  \nBin 1 : 15, 15, 15  \nBin 2 : 24, 24, 24 \nBin 3 : 30.3, 30.3, 30.3 \nUsing smoothing by bin boundaries method, the bins' values would be like: \nBin 1 : 12, 12, 19  \nBin 2 : 22, 22, 26 \nBin 3 : 28, 32, 32  \nAs per the method, the minimum and maximum values of the bin are determined, and it serves  \nas bin boundary and does not change. Rest of the values are transformed to the nearest value. It  \ncan be observed in Bin 1, the middle value 14 is compared with the boundary values 12 and 19 \nand changed to the closest value, that is 12. This process is repeated for all bins.  \n \nData Integration and Data Transformations \nData integration involves routines that merge data from multiple sources into a single data source.  \nSo, this may lead to redundant data. The main goal of data integration is to detect and remove  \nredundancies that arise from integration. Data transformation routines perform operations like  \nnormalization to improve the performance of the data mining algorithms. It is necessary to  \ntransform data so that it can be processed. This can be considered as a preliminary stage of data  \nconditioning. Normalization is one such technique. In normalization, the attribute values are \nscaled to fit in a range (say 0-1) to improve the performance of the data mining algorithm. Often, in \nneural networks, these techniques are used. Some of the normalization procedures used are: \n1. Min-Max  \n2. z-Score \nMin-Max Procedure It is a normalization technique where each variable V is normalized by its  \ndifference with the minimum value divided by the range to a new range, say 0–1. Often, neural  \nnetworks require this kind of normalization. The formula to implement this normalization is   \ngiven as: \n \n \nHere max-min is the range. Min and max are the minimum and maximum of the given data,   \nnew max and new min are the minimum and maximum of the target range, say 0 and 1. \n \nExample 2.2:  Consider the set: V = {88, 90, 92, 94}. Apply Min-Max procedure and map the marks  ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":36}}}],["06146bf3-00bf-41a0-8a1b-b948c776ecc4",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n37 \nto a new range 0–1. \nSolution: The minimum of the list V is 88 and maximum is 94. The new min and new max are   \n0 and 1, respectively. The mapping can be done using Eq. (2.1) as: \n \nSo, it can be observed that the marks {88, 90, 92, 94} are mapped to the new range {0, 0.33, 0.66, \n1}. Thus, the Min-Max normalization range is between 0 and 1. \n \nz-Score Normalization This procedure works by taking the difference between the field value  \nand mean value, and by scaling this difference by standard deviation of the attribute. \n \n  \nHere, s is the standard deviation of the list V and m is the mean of the list V. \n Example 2.3:  Consider the mark list V = {10, 20, 30}, convert the marks to z-score. \nSolution:  The mean and Sample Standard deviation (s) values of the list V are 20 and 10, respec- \ntively. So the z-scores of these marks are calculated using Eq. (2.2) as: \n \nHence, the z-score of the marks 10, 20, 30 are -1, 0 and 1, respectively. \n \nData Reduction \nData reduction reduces data size but produces the same results. There are different ways in which  \ndata reduction can be carried out such as data aggregation, feature selection, and dimensionality  \nreduction. \n \n2.4 DESCRIPTIVE STATISTICS \nDescriptive statistics is a branch of statistics that does dataset summarization. It is used to \nsummarize and describe data. Descriptive statistics are just descriptive and do not go beyond that.  \nIn other words, descriptive statistics do not bother too much about machine learning algorithms  \nand its functioning.  \nLet us discuss descriptive statistics with the fundamental concepts of datatypes. \nDataset and Data Types \nA dataset can be assumed to be a collection of data objects. The data objects may be records, \npoints, vectors, patterns, events, cases, samples or observations. These records contain many \nattributes.  An attribute can be defined as the property or characteristics of an object. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":37}}}],["80337401-f1ad-45e5-a46a-490d2920706a",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n38 \nFor example, consider the following database shown in sample Table 2.2. \n \nEvery attribute should be associated with a value. This process is called measurement.   \nThe type of attribute determines the data types, often referred to as measurement scale types.   \nThe data types are shown in Figure 2.1. \n \nBroadly, data can be classified into two types:  \n1. Categorical or qualitative data \n2. Numerical or quantitative data \n \nCategorical or Qualitative Data The categorical data can be divided into two types. They are  \nnominal type and ordinal type. \n•Nominal Data – In Table 2.2, patient ID is nominal data. Nominal data are symbols and  \ncannot be processed like a number. For example, the average of a patient ID does not make  \nany statistical sense. Nominal data type provides only information but has no ordering  \namong data. Only operations like (=, ≠) are meaningful for these data. For example, the  \npatient ID can be checked for equality and nothing else. \n•Ordinal Data – It provides enough information and has natural order. For example, Fever  \n= {Low, Medium, High} is an ordinal data. Certainly, low is less than medium and medium  \nis less than high, irrespective of the value. Any transformation can be applied to these data  \nto get a new value. \nNumeric or Qualitative Data It can be divided into two categories. They are interval type and  \nratio type. \n•Interval Data – Interval data is a numeric data for which the differences between values   \nare meaningful. For example, there is a difference between 30 degree and 40 degree. Only  \nthe permissible operations are + and -.  \n•Ratio Data – For ratio data, both differences and ratio are meaningful. The difference  \nbetween the ratio and interval data is the position of zero in the scale. For example,  \ntake the Centigrade-Fahrenheit conversion. The zeroes of both scales do not match.  \nHence, these are interval data.  \n \nAnother way of classifying the data is to classify it as: \n1.Discrete value data \n2.Continuous data \nDiscrete Data This kind of data is recorded as integers. For example, the responses of the survey  \ncan be discrete data. Employee identification number such as 10001 is discrete data. \nContinuous Data It can be fitted into a range and includes decimal point. For example, age is a  \ncontinuous data. Though age appears to be discrete data, one may be 12.5 years old and it makes  \nsense. Patient height and weight are all continuous data. \nThird way of classifying the data is based on the number of variables used in the dataset. Based  ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":38}}}],["255b9f7d-e79e-4ee6-8386-2a0ccd7fdcde",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n39 \non that, the data can be classified as univariate data, bivariate data, and multivariate data. This is  \nshown in Figure 2.2. \n \n \n \n2.5 UNIVARIATE DATA ANALYSIS AND VISUALIZATION \nUnivariate analysis is the simplest form of statistical analysis. As the name indicates, the dataset  \nhas only one variable. A variable can be called as a category. Univariate does not deal with cause or  \nrelationships. The aim of univariate analysis is to describe data and find patterns. \nUnivariate data description involves finding the frequency distributions, central tendency  \nmeasures, dispersion or variation, and shape of the data. \n \n2.5.1 Data Visualization \n Let us consider some forms of graphs  \n \nBar Chart A Bar chart (or Bar graph) is used to display the frequency distribution for variables.  \nBar charts are used to illustrate discrete data. The charts can also help to explain the counts of  \nnominal data. It also helps in comparing the frequency of different groups. \nThe bar chart for students' marks {45, 60, 60, 80, 85} with Student ID = {1, 2, 3, 4, 5} is shown  \nbelow in Figure 2.3.  \n \n \nPie Chart These are equally helpful in illustrating the univariate data. The percentage frequency  \ndistribution of students' marks {22, 22, 40, 40, 70, 70, 70, 85, 90, 90} is below in Figure 2.4. \n \nIt can be observed that the number of students with 22 marks are 2. The total number of  \nstudents are 10. So, 2/10 × 100 = 20% space in a pie of 100% is allotted for marks 22 in Figure 2.4. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":39}}}],["b4b943b2-ed32-4fdc-a486-ada55530fc2b",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n40 \nHistogram It plays an important role in data mining for showing frequency distributions.   \nThe histogram for students’ marks {45, 60, 60, 80, 85} in the group range of 0-25, 26-50, 51-75,  \n76-100 is given below in Figure 2.5. One can visually inspect from Figure 2.5 that the number of  \nstudents in the range 76-100 is 2. \n \nHistogram conveys useful information like nature of data and its mode. Mode indicates the  \npeak of dataset. In other words, histograms can be used as charts to show frequency, skewness  \npresent in the data, and shape. \n \nDot Plots These are similar to bar charts. They are less clustered as compared to bar charts,   \nas they illustrate the bars only with single points. The dot plot of English marks for five students \nwith ID as {1, 2, 3, 4, 5} and marks {45, 60, 60, 80, 85} is given in Figure 2.6. The advantage  \nis that by visual inspection one can find out who got more marks. \n \n2.5.2 Central Tendency \nTherefore, a condensation or summary of the data is necessary. This makes the data analysis easy \nand simple. One such summary is called central tendency. Thus, central tendency can explain the \ncharacteristics of data and that further helps in comparison. Mass data have tendency to \nconcentrate at certain values, normally in the central location. It is called measure of central \ntendency (or averages). Popular measures are mean, median and mode.  \n1.  Mean – Arithmetic average (or mean) is a measure of central tendency that represents the  \n‘center’ of the dataset.  Mathematically, the average of all the values in the sample (population) is \ndenoted as x. Let x1, x2, ... , xN be a set of ‘N’ values or observations, then the arithmetic mean is \ngiven as: \n \nFor example, the mean of the three numbers 10, 20, and 30 is 20 \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":40}}}],["8e8ee341-2e80-4a70-b28a-36f5841d2772",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n41 \n•Weighted mean – Unlike arithmetic mean that gives the weightage of all items equally,  \nweighted mean gives different importance to all items as the item importance varies.  \nHence, different weightage can be given to items. In case of frequency distribution, mid values of \nthe range are taken for computation. This is illustrated in the following computation. \n \nIn weighted mean, the mean is computed by adding the product of proportion and  \ngroup mean. It is mostly used when the sample sizes are unequal. \n \n•Geometric mean – Let x1, x2, ... , xN be a set of ‘N’ values or observations. Geometric mean   \nis the Nth root of the product of N items. The formula for computing geometric mean is  \ngiven as follows: \n \nHere, n is the number of items and xi are values. For example, if the values are 6 and 8,  the \ngeometric mean is given as In larger cases, computing geometric  mean is difficult. Hence, it is \nusually calculated as: \n \n \nThe problem of mean is its extreme sensitiveness to noise. Even small changes in the input  \naffect the mean drastically. Hence, often the top 2% is chopped off and then the mean is calcu- \nlated for a larger dataset.  \n \n2.  Median – The middle value in the distribution is called median. If the total number of items   \nin the distribution is odd, then the middle value is called median. A median class is that class \nwhere (N/2)th item is present. \nIn the continuous case, the median is given by the formula: \n \nMedian class is that class where N/2th item is present. Here, i is the class interval of the  \nmedian class and L1 is the lower limit of median class, f is the frequency of the median class, and  \ncf is the cumulative frequency of all classes preceding median.  \n3.  Mode – Mode is the value that occurs more frequently in the dataset. In other words, the  \nvalue that has the highest frequency is called mode.   \n \n2.5.3 Dispersion \nThe spreadout of a set of data around the central tendency (mean, median or mode) is called \ndispersion. Dispersion is represented by various ways such as range, variance, standard deviation,  \nand standard error. These are second order measures. The most common measures of the \ndispersion data are listed below: \n \n \nRange Range is the difference between the maximum and minimum of values of the given list   \nof data.  \n \nStandard Deviation The mean does not convey much more than a middle point. For example,  \nthe following datasets {10, 20, 30} and {10, 50, 0} both have a mean of 20. The difference between  \nthese two sets is the spread of data. Standard deviation is the average distance from the mean of \nthe dataset to each point.   ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":41}}}],["6d8b2352-eaac-47a6-ae03-dbd3e7d34745",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n42 \nThe formula for sample standard deviation is given by: \n \nHere, N is the size of the population, xi is observation or value from the population and m is  \nthe population mean. Often, N – 1 is used instead of N in the denominator of Eq. (2.8).  \n \nQuartiles and Inter Quartile Range It is sometimes convenient to subdivide the dataset using  \ncoordinates. Percentiles are about data that are less than the coordinates by some percentage of \nthe total value. kth percentile is the property that the k% of the data lies at or below Xi. For \nexample, median is 50th percentile and can be denoted as Q0.50. The 25th percentile is called first \nquartile (Q1) and the 75th percentile is called third quartile (Q3). Another measure that is useful \nto measure dispersion is Inter Quartile Range (IQR). The IQR is the difference between Q3 and Q1. \nInterquartile percentile = Q3 – Q1                                       (2.9) \nOutliers are normally the values falling apart at least by the amount 1.5 × IQR above the third  \nquartile or below the first quartile. \nInterquartile is defined by Q0.75 – Q0.25.                          (2.10) \n \nExample 2.4:  For patients’ age list {12, 14, 19, 22, 24, 26, 28, 31, 34}, find the IQR. \nSolution: The median is in the fifth position. In this case, 24 is the median. The first quartile is  \nmedian of the scores below the mean i.e., {12, 14, 19, 22}. Hence, it’s the median of the list below \n24. In this case, the median is the average of the second and third values, that is, Q0.25 = 16.5. \nSimilarly, the third quartile is the median of the values above the median, that is {26, 28, 31, 34}. \nSo, Q0.75 is the average of the seventh and eighth score. In this case, it is 28 + 31/2 = 59/2 = 29.5. \nHence, the IQR using Eq. (2.10) is: \n= Q0.75 – Q0.25 \n= 29.5-16.5 = 13 \n \nFive-point Summary and Box Plots The median, quartiles Q1 and Q3, and minimum   \nand maximum written in the order < Minimum, Q1, Median, Q3, Maximum > is known as   \nfive-point summary. \n \n Example 2.5:  Find the 5-point summary of the list {13, 11, 2, 3, 4, 8, 9}. \nSolution: The minimum is 2 and the maximum is 13. The Q1, Q2 and Q3 are 3, 8 and 11, respectively. \nHence, 5-point summary is {2, 3, 8, 11, 13}, that is, {minimum, Q1, median, Q3, maximum}. Box plots \nare useful for describing 5-point summary. The Box plot for the set is given in   \nFigure 2.7. \n \n2.5.4 Shape \nSkewness and Kurtosis (called moments) indicate the symmetry/asymmetry and peak location of  \nthe dataset.  \nSkewness \nThe measures of direction and degree of symmetry are called measures of third order. Ideally,  \nskewness should be zero as in ideal normal distribution. More often, the given dataset may not  ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":42}}}],["960c4e20-1d96-4a68-b97b-801c24ef8772",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n43 \nhave perfect symmetry (consider the following Figure 2.8). \n \n \nGenerally, for negatively skewed distribution, the median is more than the mean.  The relationship \nbetween skew and the relative size of the mean and median can be summarized by a convenient \nnumerical skew index known as Pearson 2 skewness coefficient. \n \nAlso, the following measure is more commonly used to measure skewness. Let X1, X2, ..., XN   \nbe a set of ‘N’ values or observations then the skewness can be given as: \n \nHere, m is the population mean and s is the population standard deviation of the univariate  \ndata. Sometimes, for bias correction instead of N, N - 1 is used. \n \nKurtosis \nKurtosis also indicates the peaks of data. If the data is high peak, then it indicates higher  kurtosis \nand vice versa.  Kurtosis is measured using the formula given below: \n \nIt can be observed that N - 1 is used instead of N in the numerator of Eq. (2.14) for bias correction. \nHere, x and s are the mean and standard deviation of the univariate data,  respectively. \nSome of the other useful measures for finding the shape of the univariate dataset are mean \nabsolute deviation (MAD) and coefficient of variation (CV). \n \nMean Absolute Deviation (MAD) \nMAD is another dispersion measure and is robust to outliers. Normally, the outlier point is \ndetected by computing the deviation from median and by dividing it by MAD. Here, the absolute \ndeviation between the data and mean is taken. Thus, the absolute deviation is given as: \n \nCoefficient of Variation (CV) \nCoefficient of variation is used to compare datasets with different units. CV is the ratio of standard  \ndeviation and mean, and %CV is the percentage of coefficient of variations. \n \n2.5.5 Special Univariate Plots \nThe ideal way to check the shape of the dataset is a stem and leaf plot. A stem and leaf plot are a \ndisplay that help us to know the shape and distribution of the data. In this method, each value is  \nsplit into a ’stem’ and a ’leaf’. The last digit is usually the leaf and digits to the left of the leaf mostly  \nform the stem. For example, marks 45 are divided into stem 4 and leaf 5 in Figure 2.9. \nThe stem and leaf plot for the English subject marks, say, {45, 60, 60, 80, 85} is given in   ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":43}}}],["19fdedd2-2277-45d5-a03c-3c6e02116b3c",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n44 \nFigure 2.9. \n \nIt can be seen from Figure 2.9 that the first column is stem and the second column is leaf.   \nFor the given English marks, two students with 60 marks are shown in stem and leaf plot as stem-\n6 with 2 leaves with 0.  The normal Q-Q plot for marks x = [13 11 2 3 4 8 9] is given below in  \nFigure 2.10. \n \n \n2.6 BIVARIATE DATA AND MULTIVARIATE DATA \nBivariate Data involves two variables. Bivariate data deals with causes of relationships. The aim is  \nto find relationships among data. Consider the following Table 2.3, with data of the temperature in  \na shop and sales of sweaters. \n \nHere, the aim of bivariate analysis is to find relationships among variables. The relationships can \nthen be used in comparisons, finding causes, and in further explorations. To do that, graphical \ndisplay of the data is necessary. One such graph method is called scatter plot. \n \nScatter plot is used to visualize bivariate data. It is useful to plot two variables with or without  ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":44}}}],["a76e5db5-56f0-4d49-bd86-ac9f09ae9fa2",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n45 \nnominal variables, to illustrate the trends, and also to show differences. It is a plot between \nexplanatory and response variables. It is a 2D graph showing the relationship between two \nvariables.  \n \nLine graphs are similar to scatter plots. The Line Chart for sales data is shown in Figure 2.12. \n \n2.6.1 Bivariate Statistics \nCovariance and Correlation are examples of bivariate statistics. Covariance is a measure of joint  \nprobability of random variables, say X and Y. Generally, random variables are represented in  \ncapital letters. It is defined as covariance(X, Y) or COV(X, Y) and is used to measure the variance  \nbetween two dimensions. The formula for finding co-variance for specific x, and y are: \n \n \nHere, xi and yi are data values from X and Y. E(X) and E(Y) are the mean values of xi and yi.   \nN is the number of given data. Also, the COV(X, Y) is same as COV(Y, X).  \n Example 2.6:  Find the covariance of data X = {1, 2, 3, 4, 5} and Y = {1, 4, 9, 16, 25}. \n \nThe covariance between X and Y is 12. It can be normalized to a value between -1 and +1. This  \nis done by dividing it by the correlation of variables. This is called Pearson correlation coefficient.   ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":45}}}],["2d68b9c8-770a-4f0e-85a1-4f219c2cae7c",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n46 \nSometimes, N - 1 is also can be used instead of N. In that case, the covariance is 60/4 = 15. \n \nCorrelation \nThe Pearson correlation coefficient is the most common test for determining any association  \nbetween two phenomena. It measures the strength and direction of a linear relationship between  \nthe x and y variables.  \n1.If the value is positive, it indicates that the dimensions increase together. \n2.If the value is negative, it indicates that while one-dimension increases, the other dimension  \ndecreases. \n3.If the value is zero, then it indicates that both the dimensions are independent of each  \nother. \nIf the dimensions are correlated, then it is better to remove one dimension as it is a redundant  \ndimension. \nIf the given attributes are X = (x1, x2, ... , xN) and Y = (y1, y2, ... , yN), then the Pearson correlation  \ncoefficient, that is denoted as r, is given as:  \n \n \nwhere, sX, sY are the standard deviations of X and Y. \n \n2.7 MULTIVARIATE STATISTICS \nIn machine learning, almost all datasets are multivariable. Multivariate data is the analysis of  \nmore than two observable variables, and often, thousands of multiple measurements need to be  \nconducted for one or more subjects. \n \nMultivariate data has three or more variables. The aim of the multivariate analysis is much  \nmore. They are regression analysis, factor analysis and multivariate analysis of variance that are  \nexplained in the subsequent chapters of this book.  \n \nHeatmap \nHeatmap is a graphical representation of 2D matrix. It takes a matrix as input and colours it. The \ndarker colours indicate very large values and lighter colours indicate smaller values.  The \nadvantage of this method is that humans perceive colours well. So, by colour shaping, larger values \ncan be perceived well. For example, in vehicle traffic data, heavy traffic regions can be \ndifferentiated from low traffic regions through heatmap.  \n \nIn Figure 2.13, patient data highlighting weight and health status is plotted. Here, X-axis  \nis weights and Y-axis is patient counts. The dark colour regions highlight patients’ weights vs  \npatient counts in health status. \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":46}}}],["2698929b-76e9-42fc-982c-2864953b44b8",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n47 \n \nPairplot \nPairplot or scatter matrix is a data visual technique for multivariate data. A scatter matrix consists  \nof several pair-wise scatter plots of variables of the multivariate data.  \nA random matrix of three columns is chosen and the relationships of the columns is plotted   \nas a pairplot (or scatter matrix) as shown below in Figure 2.14.  \n \n2.8 ESSENTIAL MATHEMATICS FOR MULTIVARIATE DATA \n \nMachine learning involves many mathematical concepts from the domain of Linear algebra,  \nStatistics, Probability and Information theory. The subsequent sections discuss important aspects  \nof linear algebra and probability. \n \n2.8.1 Linear Systems and Gaussian Elimination for Multivariate Data \nA linear system of equations is a group of equations with unknown variables.  \nLet Ax = y, then the solution x is given as: \n \n \nThis is true if y is not zero and A is not zero. The logic can be extended for N-set of equations  \nwith ‘n’ unknown variables. \nIt means if  A= and y=(y1 y2...yn), then the unknown variable x can be  ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":47}}}],["fd4b193f-9428-4b48-8616-876ee4669f74",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n48 \ncomputed as: \n \nIf there is a unique solution, then the system is called consistent independent. If there are various \nsolutions, then the system is called consistent dependant. If there are no solutions and if the \nequations are contradictory, then the system is called inconsistent.  \nFor solving large number of system of equations, Gaussian elimination can be used. The  \nprocedure for applying Gaussian elimination is given as follows: \n1.Write the given matrix. \n2.Append vector y to the matrix A. This matrix is called augmentation matrix. \n3.Keep the element a11 as pivot and eliminate all a11 in second row using the matrix operation, \n  \nThe same logic  \ncan be used to remove a11 in all other equations. \n4.Repeat the same logic and reduce it to reduced echelon form. Then, the unknown variable as: \n \n5.Then, the remaining unknown variables can be found by back-substitution as: \n \nThis part is called backward substitution. \n \nTo facilitate the application of Gaussian elimination method, the following row operations are  \napplied:  \n1.Swapping the rows \n2.Multiplying or dividing a row by a constant \n3.Replacing a row by adding or subtracting a multiple of another row to it \nThese concepts are illustrated in Example 2.8. \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":48}}}],["ee49fafc-5a90-48e6-9d3d-63e90e7453a8",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n49 \n \n2.8.2 Matrix Decomposition \nIt is often necessary to reduce a matrix to its constituent parts so that complex matrix operations  \ncan be performed.  \nThen, the matrix A can be decomposed as: \n \nwhere, Q is the matrix of eigen vectors, Λ is the diagonal matrix and QT is the transpose of matrix \nQ. \n \nLU Decomposition \nOne of the simplest matrix decomposition is LU decomposition where the matrix A can be \ndecomposed matrices: A = LU \nHere, L is the lower triangular matrix and U is the upper triangular matrix. The decomposition  \ncan be done using Gaussian elimination method as discussed in the previous section. First,  an \nidentity matrix is augmented to the given matrix. Then, row operations and Gaussian elimination   \nis applied to reduce the given matrix to get matrices L and U.  \nExample 2.9 illustrates the application of Gaussian elimination to get LU. \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":49}}}],["262d33d4-7913-453d-9b2d-09dd95f5da69",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n50 \n \nNow, it can be observed that the first matrix is L as it is the lower triangular matrix whose  \nvalues are the determiners used in the reduction of equations above such as 3, 3 and 2/3.   \nThe second matrix is U, the upper triangular matrix whose values are the values of the reduced  \nmatrix because of Gaussian elimination. \n \n2.8.3 Machine Learning and Importance of Probability and Statistics \nMachine learning is linked with statistics and probability. Like linear algebra, statistics is the heart \nof machine learning. The importance of statistics needs to be stressed as without statistics;  \n \nProbability Distributions \nA probability distribution of a variable, say X, summarizes the probability associated with X’s  \nevents. Distribution is a parameterized mathematical function. In other words, distribution is a  \nfunction that describes the relationship between the observations in a sample space. \nConsider a set of data. The data is said to follow a distribution if it obeys a mathematical  \nfunction that characterizes that distribution. The function can be used to calculate the probability  \nof individual observations.  \nProbability distributions are of two types: \n1.Discrete probability distribution \n2.Continuous probability distribution  \nThe relationships between the events for a continuous random variable and their probabilities  \n \nContinuous Probability Distributions  Normal, Rectangular, and Exponential distributions  \nfall under this category. \n \n1.  Normal Distribution – Normal distribution is a continuous probability distribution.   \nThis is also known as gaussian distribution or bell-shaped curve distribution. It is the   \nmost common distribution function. The shape of this distribution is a typical bell-shaped  ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":50}}}],["98d638a0-55ac-4160-ac1c-560cf9910b9f",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n51 \ncurve. In normal distribution, data tends to be around a central value with no bias on left  \nor right. The heights of the students, blood pressure of a population, and marks scored in  \na class can be approximated using normal distribution. \nPDF of the normal distribution is given as: \n \nHere, m is mean and s is the standard deviation. Normal distribution is characterized  \nby two parameters – mean and variance. \nOne important concept associated with normal distribution is z-score. It can be  \ncomputed as: \n \nThis is useful to normalize the data. \n \n2.  Rectangular Distribution – This is also known as uniform distribution. It has equal  \nprobabilities for all values in the range a, b. The uniform distribution is given as follows: \n \n3.Exponential Distribution – This is a continuous uniform distribution. This probability   \n   distribution is used to describe the time between events in a Poisson process. Exponential   \n   distribution is another special case of Gamma distribution with a fixed parameter of 1.   \n   This distribution is helpful in modelling of time until an event occurs. \nThe PDF is given as follows: \n \n \nDiscrete Distribution Binomial, Poisson, and Bernoulli distributions fall under this category. \n1.  Binomial Distribution – Binomial distribution is another distribution that is often encountered \nin machine learning. It has only two outcomes: success or failure. This is also called  \nBernoulli trial.  \nThe objective of this distribution is to find probability of getting success k out of n trials.  \nThe way to get success out of k out of n number of trials is given as: \n \n \nThe binomial distribution function is given as follows, where p is the probability of  \nsuccess and probability of failure is (1 - p). The probability of success in a certain number  \nof trials is given as:  \n \nCombining both, one gets PDF of binomial distribution as: \n \nHere, p is the probability of each choice, k is the number of choices, and n is the total  \nnumber of choices. The mean of binomial distribution is given below: \n \nAnd the variance is given as: \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":51}}}],["9cffa61c-497e-4814-85e9-7d0974952848",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n52 \nHence, the standard deviation is given as:  \n \n2. Poisson Distribution – It is another important distribution that is quite useful. Given an  \ninterval of time, this distribution is used to model the probability of a given number of  \nevents k. The mean rule l is inclusive of previous events. Some of the examples of Poisson  \ndistribution are number of emails received, number of customers visiting a shop and the  \nnumber of phone calls received by the office. \nThe PDF of Poisson distribution is given as follows: \n \n \n3.Bernoulli Distribution – This distribution models an experiment whose outcome is binary.  \nThe outcome is positive with p and negative with 1 - p. The PMF of this distribution is  \ngiven as: \n \nThe mean is p and variance is p(1 - p) = q \n \nDensity Estimation \nLet there be a set of observed values x1, x2, ... , xn from a larger set of data whose distribution is \nnot known. Density estimation is the problem of estimating the density function from an observed \ndata.  \nThere are two types of density estimation methods, namely parametric density estimation and  \nnon-parametric density estimation. \n \nParametric Density Estimation It assumes that the data is from a known probabilistic distri- \nbution and can be estimated as  Maximum likelihood function  \nis a parametric estimation method. \n \nMaximum Likelihood Estimation For a sample of observations, one can estimate the probability  \ndistribution. This is called density estimation. Maximum Likelihood Estimation (MLE) is a  \nprobabilistic framework that can be used for density estimation. This involves formulating   \na function called likelihood function which is the conditional probability of observing the   \nobserved samples and distribution function with its parameters. For example, if the observations  \nare X = {x1, x2, ... , xn}, then density estimation is the problem of choosing a PDF with suitable  \nparameters to describe the data. MLE treats this problem as a search or optimization problem  \nwhere the probability should be maximized for the joint probabilities of X and its parameter, theta. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":52}}}],["d155a2e8-7b64-4b5c-b4dd-88a4aeed5bd6",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n53 \n \n \nIf one assumes that the regression problem can be framed as predicting output y given input x,   \nthen for p(y/x), the MLE framework can be applied as: \n \n \nHere, h is the linear regression model. If Gaussian distribution is assumed as it is an obvious  \nfact that most of the data follow Gaussian distribution, then MLE can be stated as: \n \nHere, b is the regression coefficient and xi is the given sample. One can maximize this function  \nor minimize the negative log likelihood function to provide a solution for linear regression  \nproblem. The Eq. (2.37) yields the same answer of the least-square approach. \n \nGaussian Mixture Model and Expectation-Maximization (EM) Algorithm In machine learning,  \nclustering is one of the important tasks. It is discussed in Chapter 13. MLE framework is quite  \nuseful for designing model-based methods for clustering data. A model is a statistical method and  \ndata is assumed to be generated by a distribution model with its parameter, theta. There may be \nmany distributions involved and that is why it is called as mixture model.  \n \nGenerally, there can be many unspecified distributions with different set of parameters. The  \nEM algorithm has two stages: \n1. Expectation (E) Stage – In this stage, the expected PDF and its parameters are estimated   \nfor each latent variable. \n2.Maximization (M) stage – In this, the parameters are optimized using the MLE function. \nThis process is iterative, and the iteration is continued till all the latent variables are fitted   \nby probability distributions effectively along with the parameters. \n \nNon-parametric Density Estimation A non-parametric estimation can be generative   \nor discriminative. Parzen window is a generative estimation method that finds  as  \nconditional density. Discriminative methods directly compute  as posteriori probability.  \nParzen window and k-Nearest Neighbour (KNN) rule are examples of non-parametric density  \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":53}}}],["d4b36a83-9bc7-4f08-9989-ecc71db62726",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n54 \nestimation.  \nThis window can be replaced by any other function too. If Gaussian function is used, then it   \nis called Gaussian density function. \nKNN Estimation The KNN estimation is another non-parametric density estimation method.  \nHere, the initial parameter k is determined and based on that k-neighbours are determined.  \nThe probability density function estimate is the average of the values that are returned by   \nthe neighbours. \n \n2.9 OVERVIEW OF HYPOTHESIS \nData collection alone is not enough. Data must be interpreted to give a conclusion. The conclusion  \nshould be a structured outcome. This assumption of the outcome is called a hypothesis. Statistical  \nmethods are used to confirm or reject the hypothesis. The assumption of the statistical test is \ncalled null hypothesis. It is also called as hypothesis zero (H0). In other words, hypothesis is the \nexisting belief. The violation of this hypothesis is called first hypothesis (H1) or hypothesis one. \nThis is the hypothesis the researcher is trying to establish. \nThere are two types of hypothesis tests, parametric and non-parametric. Parametric tests are  \nbased on parameters such as mean and standard deviation. Non-parametric tests are dependent \non characteristics such as independence of events or data following certain distribution.  \nStatistical tests help to: \n1.Define null and alternate hypothesis \n2.Describe the hypothesis using parameters \n3.Identify the statistical test and statistics \n4.Decide the criteria called significance value a \n5.Compute p-value (probability value) \n6.Take the final decision of accepting or rejecting the hypothesis based on the parameters \n \nHypothesis testing is particularly important as it is an integral part of the learning algorithms.  \nGenerally, the data size is small. So, one may have to know whether the hypothesis will work for  \nadditional samples and how accurate it is. No matter how effective the statistical tests are, two  \nkinds of errors are involved, that are Type I and Type II. \n \nType I error is the incorrect rejection of a true null hypothesis and is called false positive.   \nType II error is the incomplete failure of rejecting a false hypothesisand is called false negative. \nDuring these calculations, one must include the size of the data sample. Degree of freedom  ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":54}}}],["37c4e406-16cc-4372-bba8-ee2580c4834c",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n55 \nindicates the number of independent pieces of information used for the test. It is indicated as n. \nThe mean or variance can be used to indicate the degree of freedom. \n \nHypothesis Testing \nLet us define two important errors called sample error and true (or actual error). Let us assume  \nthat D is the unknown distribution, Target function is f(x): x ≥ {0, 1}, x is the instance, h(x) is the   \nhypothesis, and sample set is S that derives the samples on instances drawn from X. Then,   \nthe actual error is denoted as: \n \n \nIn other words, true error is the probability that the hypothesis will mis classify an instance  \nthat is drawn at random. The point is that population is very large and hence it is not possible to  \ndetermine true error and can only be estimated. So, another error is called sample error or \nestimator. \nSample error is with respect to sample S. It is the probability for instances drawn from X,   \nthat is, the fractions of S that are misclassified. The sample error is given as follows: \n \n \n \np-value \nStatistical tests can be performed to either accept or reject the null hypothesis. This is done by  \nthe value called p-value or probability value. It indicates the probability of hypothesis being true.  \nThe p-value is used to interpret or quantify the test. For example, a statistical test result may give   \na value of 0.03. Then, one can compare it with the level 0.05. As 0.03 < 0.05, the result is assumed \nto be significant. This means that the variables tested are not independent. Here, 0.05 is called \nsignificant level. In general, significant level is called a and p-value is compared with a. If p-value ≤ \na, then the hypothesis H1 is rejected and if p-value >a, then the hypothesis H0 is rejected. \n \nConfidence Intervals \nThe acceptance or rejection of the hypothesis can also be done using confidence interval.   \nThe confidence interval is computed as: \nConfidence interval = 1 – significant level                                                          (2.44) \n \nConfidence level is the range of values that indicates the location of true mean. Confidence  \nintervals indicate the confidence of the result. If the confidence level is 90%, then it infers that there \nis 90% of chance that the true mean lies in this range and remaining 10% indicates that true mean \nin not present. For finding this, one requires mean and standard deviation. Then, x can be given as  \n Here, s is the standard deviation, N is the number of samples, and z is the value  \nassociated with 90% and is called % of confidence. This is also called as margin of error.  \nSample error is the unbiased estimate of true error. If no information is provided, then both  \nerrors are the same. It is, however, often safe to suggest a margin of confidence associated with the  \nhypothesis. The hypothesis with 95% confidence about the sample error can be given as follows: \n \n \nThis 1.96 indicates the 95% confidence of the error. The number 1.96 can be replaced by  \nany number that is associated with different levels of confidence.  \nThe procedure to estimate the difference between two hypothesis, say h1 and h2, is as follows:  \n1.A parameter d can be chosen to estimate the error of two hypothesis: \n2.d ≡ errorD(h1) - errorD(h2)(2.46) ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":55}}}],["bc4af467-e9db-4fa8-b3d9-67a841330f34",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n56 \nHere, there are two hypothesis h1 and h2 tested on two sample sets s1 and s2. Similarly,  \nn1 and n2 are randomly drawn number of samples. \n3.The estimator ^d can be estimated as the difference as: \n \n4.The confidence intervals can be used for the estimator also as follows: \n \nSometimes, it is desirable to find interval L and U such that N% of the probability falls in this  \n \n2.9.1 Comparing Learning Methods \nSome of the methods for comparing the learning programs are given below: \nZ-test \nZ-test assumes normal distribution of data whose population variation is known. The sample size  \nis assumed to be large. The focus is to test the population mean. The z-statistic is given as: \n \nt-test and Paired t-test \nt-test is a hypothesis test and checks if the difference between two samples’ mean is real or by  \nchance. Here, data is continuous and randomly selected. There will only be small number of  \nsamples and variance between groups is real. The t-test statistics follows t-distribution under null  \nhypothesis and is used when the number of samples <30.  So, the procedure is: \n•Select a group  \n•Compute average \n•Compare it with theoretical value and compute t-statistic: \n \nHere, t is t-statistic, m is the mean of the group, m is the theoretical value or population mean,   \ns is the standard deviation, and n is the group size or sample size. \n \nIndependent Two Sample t-test t-statistic for two groups A and B is computed as follows: \n \nHere, mean(A) and mean(B) are for two different samples. N1 and N2 are sample sizes of  \ntwo groups A and B. s^2 is the variance of the two samples and the degree of freedom is given as   ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":56}}}],["9cce33b4-ebe3-4751-8ff8-8bbe2a52b3ae",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n57 \nN1 + N2 - 2 . Then, t-statistic is compared with the t-critical value. \n \n \nPaired t-test It is used to evaluate the hypothesis before and after intervention. The fact is that  \nthese samples are not independent. For example, consider the case of an effect of medication for  \na diabetic patient. The sequence is that first the sugar is tested, then the medication is done, and  \nagain the sugar test is conducted to study the effect of medication. In short, in paired t-test, the \ndata is taken from the same subject twice. In an unpaired t-test, the samples are taken \nindependently. In this only one group is involved. The t-statistic is computed as: \n \n \nHere, t is t-statistic, m is the mean of the group, m is the theoretical value or population mean,   \ns is the standard deviation, and n is the group size or sample size. \n \nChi-Square Test \nChi-Square test is a non-parametric test. The goodness-of-fit test statistics follows a Chi-Square  \ndistribution under null hypothesis and measures the statistical significance between observed  \nfrequency and expressed frequency, and each observation is independent of each other and \nfollows normal distribution.  This comparison is used to calculate the value of the Chi-Square \nstatistic as:  \n \nHere, E is the expected frequency, O is the observed frequency and the degree of freedom is  \nC – 1, where, C is number of categories. The Chi-Square test allows us to detect the duplication of  \ndata and helps to remove the redundancy of values. \n Example 2.11:  Consider the following Table 2.4, where the machine learning course registration  \nis done by both boys and girls. There are 50 boys and 50 girls in the class and the registration of  \nthe course is given in the table. Apply Chi-Square test and find out whether any differences exist  \nbetween boys and girls for course registration. \n \nSolution: Let the null hypothesis be H0 when there is no difference between boys and girls and  \nH1 be the alternate hypothesis when there is a significant difference between boys and girls.   \nFor applying the Chi-Square test based on the observations, the expectation should be obtained  \nby multiplying the total boys X registered/Total and Total girls X not registered/Total as shown in  \nTable 2.5.  \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":57}}}],["03622561-d9dd-4061-8855-cc6d35d09c97",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n58 \n  \nfor degree of freedom = number of categories -1 = 2 - 1 = 1. The p value for this statistic is 0.0412. \nThis is less  than 0.05. Therefore, the result is significant. \n \n2.10 FEATURE ENGINEERING AND DIMENSIONALITY REDUCTION TECHNIQUES \n \nFeatures are attributes. Feature engineering is about determining the subset of features that form  \nan important part of the input that improves the performance of the model, be it classification or  \nany other model in machine learning.  \n \nFeature engineering deals with two problems – Feature Transformation and Feature Selection.  \nFeature transformation is extraction of features and creating new features that may be helpful in  \nincreasing performance. For example, the height and weight may give a new attribute called Body  \nMass Index (BMI). \n \nFeature subset selection is another important aspect of feature engineering that focuses on  \nselection of features to reduce the time but not at the cost of reliability. \nThe features can be removed based on two aspects: \n1.Feature relevancy – Some features contribute more for classification than other features.  \nFor example, a mole on the face can help in face detection than common features like  \nnose. In simple words, the features should be relevant.  \n2. Feature redundancy – Some features are redundant. For example, when a database table  \nhas a field called Date of birth, then age field is not relevant as age can be computed  \neasily from date of birth.  \nSo, the procedure is: \n1.Generate all possible subsets \n2.Evaluate the subsets and model performance \n3.Evaluate the results for optimal feature selection \n \nFilter-based selection uses statistical measures for assessing features. In this approach,  \nno learning algorithm is used. Correlation and information gain measures like mutual information  \nand entropy are all examples of this approach. \n \nWrapper-based methods use classifiers to identify the best features. These are selected  \nand evaluated by the learning algorithms. This procedure is computationally intensive but has   \nsuperior performance. \n \n2.10.1 Stepwise Forward Selection \nThis procedure starts with an empty set of attributes. Every time, an attribute is tested for \nstatistical significance for best quality and is added to the reduced set. This process is continued \ntill a good reduced set of attributes is obtained. \n \n2.10.2 Stepwise Backward Elimination \nThis procedure starts with a complete set of attributes. At every stage, the procedure removes the  \nworst attribute from the set, leading to the reduced set. \n \n2.10.3 Principal Component Analysis \nThe idea of the principal component analysis (PCA) or KL transform is to transform a given   \nset of measurements to a new set of features so that the features exhibit high information   \npacking properties. This leads to a reduced and compact set of features.  \nConsider a group of random vectors of the form: ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":58}}}],["007e1d0e-1afe-408a-adcb-37692517d480",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n59 \n \nThe mean vector of the set of random vectors is defined as: \n \nThe operator E refers to the expected value of the population. This is calculated theoretically  \nusing the probability density functions (PDF) of the elements xi and the joint probability density  \nfunctions between the elements xi and xj. From this, the covariance matrix can be calculated as: \n \n \nThe mapping of the vectors x to y using the transformation can now be described as: \n \nThis transform is also called as Karhunen-Loeve or Hoteling transform. The original vector x  \ncan now be reconstructed as follows: \n \n \nIf K largest eigen values are used, the recovered information would be: \n \n \nThe PCA algorithm is as follows: \n1.The target dataset x is obtained  \n2.The mean is subtracted from the dataset. Let the mean be m. Thus, the adjusted dataset is  \nX – m. The objective of this process is to transform the dataset with zero mean. \n3.The covariance of dataset x is obtained. Let it be C. \n4.Eigen values and eigen vectors of the covariance matrix are calculated. \n5.The eigen vector of the highest eigen value is the principal component of the dataset.   \nThe eigen values are arranged in a descending order. The feature vector is formed with these  \neigen vectors in its columns. \nFeature vector = {eigen vector1, eigen vector2, ... , eigen vectorn} \n6.Obtain the transpose of feature vector. Let it be A. \n7.PCA transform is y = A × (x – m), where x is the input dataset, m is the mean, and A is the  \ntranspose of the feature vector.  \nThe original data can be retrieved using the formula given below:  \n \nThe new data is a dimensionaly reduced matrix that represents the original data.  ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":59}}}],["58aaf291-ca29-40b2-8d15-9437a6112320",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n60 \nFigure 2.15. The scree plot indicates that only 6 out of 246 attributes are important.  \n \nFrom Figure 2.15, one can infer the relevance of the attributes. The scree plot indicates that   \nthe first attribute is more important than all other attributes. \n \n \n \n2.10.4 Linear Discriminant Analysis \nLinear Discriminant Analysis (LDA) is also a feature reduction technique like PCA. The focus of  \nLDA is to project higher dimension data to a line (lower dimension data). LDA is also used to  \nclassify the data. Let there be two classes, c1 and c2. Let m1 and m2 be the mean of the patterns of \ntwo  \nclasses. The mean of the class c1 and c2 can be computed as: \n \n \nThe aim of LDA is to optimize the function: \n \n \n \n \n2.10.5 Singular Value Decomposition \nSingular Value Decomposition (SVD) is another useful decomposition technique. Let A be the  \nmatrix, then the matrix A can be decomposed as: \n \n \nHere, A is the given matrix of dimension m × n, U is the orthogonal matrix whose dimension is  \nm × n, S is the diagonal matrix of dimension n × n, and V is the orthogonal matrix. The procedure  \nfor finding decomposition matrix is given as follows: \n1.For a given matrix, find AA^T ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":60}}}],["c5ee9f46-fd2e-47de-8b46-994e7f048fe9",{"pageContent":"Module 2            AI&ML,  21CS54, 5\nth\n Semester \n \n \n61 \n2.Find eigen values of AA^T \n3.Sort the eigen values in a descending order. Pack the eigen vectors as a matrix U.  \n4.Arrange the square root of the eigen values in diagonal. This matrix is diagonal matrix, S.  \n5.Find eigen values and eigen vectors for A^TA. Find the eigen value and pack the eigen vector  \nas a matrix called V. \nThus, A = USV^ T. Here, U and V are orthogonal matrices. The columns of U and V are left and  \nright singular values, respectively. SVD is useful in compression, as one can decide to retain only a  \ncertain component instead of the original matrix A as: \n \n \nBased on the choice of retention, the compression can be controlled. \n \n \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-2-AI-2021-scheme-5th-semester.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134246Z","ModDate":"D:20240119143712Z"},"metadata":null,"totalPages":61},"loc":{"pageNumber":61}}}],["e2ae2bda-8d06-4965-a987-3c724a7e455b",{"pageContent":" ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                         \n \n \n \n                                                                                            1 \n         \nCHAPTER 3 \nBASICS OF LEARNING THEORY \n3.1 INTRODUCTION TO LEARNING AND ITS TYPES \nLearning is a process by which one can acquire knowledge and construct new ideas or \nconcepts based on the experiences.  \nThe standard definition of learning proposed by Tom Mitchell is that a program can learn \nfrom E for the task T, and P improves with experience E.  \nThere are two kinds of problems – well-posed and ill-posed. Computers can solve only well-\nposed problems, as these have well-defined specifications and have the following \ncomponents inherent to it. \n1. Class of learning tasks (T)   2. A measure of performance (P) 3. A source of experience (E)  \nLet x- input, χ-input space, Y –is the output space. Which is the set of all possible outputs, \nthat is yes/no,  \nLet D –dataset for n inputs.Consider, target function be: χ-> Y , that maps input to output. \nObjective: To pick a function, g: χ-> Y to appropriate hypothesis f. \n \nFig: Learning Environment \nLearning model= Hypothesis set + Learning algorithm \n \nvtucode.in\nMODULE 3","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":1}}}],["086d02e6-ca02-4f86-a4c5-ed13ae9e8a7e",{"pageContent":" ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                         \n \n \n \n                                                                                            2 \nClassical and Adaptive ML systems.  \nClassic machines  examine  data  inputs  according  to  a  predetermined  set  of  rules,  finding \npatterns and relationships that can be used to generate predictions or choices. Support vector \nmachines, decision trees, and logistic regression are some of the most used classical machine-\nlearning techniques. \nA class of machine learning techniques called adaptive machines, commonly referred to as \nadaptive  or deep  learning,  is  created  to  automatically  learn  from  data  inputs  without  being \nexplicitly   programmed.   By   learning   hierarchical   representations   of   the   input,   these \nalgorithms are able to handle more complex and unstructured data, such as photos, videos, \nand natural language. \nAdaptive ML is the next generation of traditional ML – the new, the improved, the better. Even \nthough traditional ML witnessed significant progress. \n \nLearning Types \n \n3.2 INTRODUCTION TO COMPUTATION LEARNING THEORY \n \nThese questions are the basis of a field called ‘Computational Learning Theory’ or in short \n(COLT). \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":2}}}],["2373a7af-49b6-4c44-bbdf-14907e9c58fe",{"pageContent":" ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                         \n \n \n \n                                                                                            3 \n3.3 DESIGN OF A LEARNING SYSTEM \n \n3.4 INTRODUCTION TO CONCEPT LEARNING  \n \n \n3.4.1 Representation of a Hypothesis \n \n3.4.2 Hypothesis Space \nHypothesis space is the set of all possible hypotheses that approximates the target function f.  \nThe subset of hypothesis space that is consistent with all-observed training instances is called \nas Version Space.  \n \n3.4.3 Heuristic Space Search  \nHeuristic search is a search strategy that finds an optimized hypothesis/solution to a problem \nby iteratively improving the hypothesis/solution based on a given heuristic function or a cost \nmeasure.  \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":3}}}],["62d3b43d-98db-48a5-a1de-b1268d6fd200",{"pageContent":" ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                         \n \n \n \n                                                                                            4 \n3.4.4 Generalization and Specialization  \nSearching the Hypothesis Space \n \nThere are two ways of learning the hypothesis, consistent with all training instances from the \nlarge hypothesis space. \n \n1. Specialization – General to Specific learning \n2. Generalization – Specific to General learning  \nGeneralization – Specific  to  General  Learning This  learning  methodology  will  search \nthrough the hypothesis space for an approximate hypothesis by generalizing the most specific \nhypothesis.  \n \nSpecialization – General  to  Specific  Learning This  learning  methodology  will  search \nthrough the hypothesis space for an approximate hypothesis by specializing the most general \nhypothesis.  \n \n3.4.5 Hypothesis Space Search by Find-S Algorithm  \n \nLimitations of Find-S Algorithm  \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":4}}}],["fd96f5c6-488d-4326-96b0-7c9391ea6930",{"pageContent":" ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                         \n \n \n \n                                                                                            5 \n \n3.4.6 Version Spaces  \n \nList-Then-Eliminate Algorithm  \n \nCandidate Elimination Algorithm  \n \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":5}}}],["a73cc616-5f39-4bfb-97d7-c44c729acccd",{"pageContent":" ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                         \n \n \n \n                                                                                            6 \nThe diagrammatic representation of deriving the version space is shown below: \n \n \nDeriving the Version Space  \n \n \n \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":6}}}],["23b93b6d-43e8-4d24-a3cd-50e4d20b7df5",{"pageContent":" ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                                   \n \n                                                                                                                1 \nMODULE 3 \nCHAPTER 4 \nSIMILARITY-BASED LEARNING \n  4.1 Similarity or Instance-based Learning  \n \n4.1.1 Difference between Instance-and Model-based Learning  \n \nSome examples of Instance-based Learning algorithms are:  \na) KNN \nb) Variants of KNN \nc) Locally weighted regression \nd) Learning vector quantization \ne) Self-organizing maps \nf) RBF networks \nNearest-Neighbor Learning  \n A powerful classification algorithm used in pattern recognition. \n K nearest neighbors stores all available cases and classifies new cases based on a \nsimilarity measure (e.g distance function) \n One of the top data mining algorithms used today. \n A non-parametric lazy learning algorithm (An Instance based Learning method). \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":7}}}],["afad52dd-702c-41e6-9ea5-a32108311c18",{"pageContent":" ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                                   \n \n                                                                                                                2 \n Used for both classification and regression problems. \n  \n  \n \n \n \n \nHere,  2  classes  of  objects  called  C\n1 \nand C\n2\n. When given a test instance T, \nthe  category  of  this  test  instance  is \ndetermined by looking at the class of \nk=3   nearest   neighbors.   Thus,   the \nclass   of   this   test   instance   T   is \npredicted as C\n2.\n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":8}}}],["3fb8b122-e887-477b-b96c-c283f9d9ef0b",{"pageContent":" ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                                   \n \n                                                                                                                3 \nAlgorithm 4.1: k-NN  \n \n4.3 Weighted k-Nearest-Neighbor Algorithm  \nThe weighted KNN  is an extension of k-NN.It chooses the neighbors by using the weighted \ndistance. In weighted kNN, the nearest k points are given a weight using a function called as \nthe kernel function. The intuition behind weighted kNN, is to give more weight to the points \nwhich    are    nearby    and    less    weight    to    the    points    which    are    farther    away.\n \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":9}}}],["4dc4f9d9-00ba-4fee-8c3a-6c31351684ee",{"pageContent":" ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                                   \n \n                                                                                                                4 \n4.4 Nearest Centroid Classifier  \nThe  Nearest  Centroids  algorithm  assumes  that  the  centroids  in  the  input  feature  space  are \ndifferent  for  each  target  label.  The  training  data  is  split  into  groups  by  class  label,  then  the \ncentroid for each group of data is calculated. Each centroid is simply the mean value of each \nof the input variables, so it is also called as Mean Difference classifier. If there are two classes, \nthen two centroids or points are calculated; three classes give three centroids, and so on. \n \n4.5 Locally Weighted Regression (LWR) \n \n     \nWhere, г is called the bandwidth parameter and controls the rate at which w\ni\n reduces to zero \nwith distance from x\ni.\n \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":10}}}],["eedfb519-ccf0-4e6c-bf69-ae19e7c187f2",{"pageContent":"ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                                     \n \n                                                                                            1 \nMODULE 3 \nCHAPTER 5 \nREGRESSION ANALYSIS \n5.1 Introduction to Regression \nRegression analysis is a fundamental concept that consists of a set of machine learning methods \nthat predict a continuous outcome variable (y) based on the value of one or multiple predictor \nvariables (x).  \nOR  \nRegression  analysis  is  a  statistical  method  to  model  the  relationship  between  a  dependent \n(target) and independent (predictor) variables with one or more independent variables. \nRegression is a supervised learning technique which helps in finding the correlation between \nvariables. \n It is mainly used for prediction, forecasting, time series modelling, and determining the causal-\neffect relationship between variables. \nRegression  shows  a  line  or  curve  that  passes  through  all  the  datapoints  on  target-predictor \ngraph in such a way that the vertical distance between the datapoints and the regression line \nis minimum.\" The distance between datapoints and line tells whether a model has captured a \nstrong relationship or not. \n• Function of regression analysis is given by:  \nY=f(x) \nHere, y is called dependent variable and x is called independent variable. \nApplications of Regression Analysis      \n Sales of a goods or services \n Value of bonds in portfolio management \n Premium on insurance componies \n Yield of crop in agriculture \n Prices of real estate \n5.2 INTRODUCTION TO LINEARITY, CORRELATION AND CAUSATION \nA correlation is the statistical summary of the relationship between two sets of variables. It is \na core part of data exploratory analysis, and is a critical aspect of numerous advanced machine \nlearning techniques.  \nCorrelation between two variables can be found using a scatter plot  \nThere are different types of correlation: \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":11}}}],["b5f22f89-b604-45b9-8cd1-f202d0f1d6d4",{"pageContent":"ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                                     \n \n                                                                                            2 \nPositive Correlation:  Two  variables  are  said  to  be  positively  correlated  when  their  values \nmove in the same direction. For example, in the image below, as the value for X increases, so \ndoes the value for Y at a constant rate. \nNegative  Correlation:  Finally, variables  X  and  Y  will  be  negatively  correlated  when  their \nvalues  change  in  opposite  directions,  so  here  as  the  value  for  X  increases,  the  value  for Y \ndecreases at a constant rate. \nNeutral  Correlation:  No  relationship  in  the  change  of  variables  X  and  Y.  In this  case,  the \nvalues  are  completely  random  and  do  not  show  any  sign  of  correlation,  as  shown  in  the \nfollowing image: \n \nCausation      \nCausation is about relationship between two variables as x causes y. This is called x implies b. \nRegression is different from causation. Causation indicates that one event is the result of the \noccurrence of the other event; i.e. there is a causal relationship between the two events. \nLinear and Non-Linear Relationships   \nThe  relationship  between  input  features  (variables)  and  the  output  (target)  variable  is \nfundamental. These concepts have significant implications for the choice of algorithms, model \ncomplexity, and predictive performance. \nLinear relationship creates a straight line when plotted on a graph, a Non-Linear relationship \ndoes not create a straight line but instead creates a curve. \nExample:  \nLinear-the relationship between the hours spent studying and the grades obtained in a class.   \nNon-Linear-  \nLinearity: \nLinear  Relationship: A  linear  relationship  between  variables  means  that  a  change  in  one \nvariable is associated with a proportional change in another variable. Mathematically, it can be \nrepresented as y = a * x + b, where y is the output, x is the input, and a and b are constants. \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":12}}}],["f44a59d6-3356-4568-bd04-e1d6ca6fecea",{"pageContent":"ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                                     \n \n                                                                                            3 \nLinear Models: Goal is to find the best-fitting line (plane in higher dimensions) to the data \npoints. Linear models are interpretable and work well when the relationship between variables \nis close to being linear. \nLimitations:  Linear  models  may  perform  poorly  when  the  relationship  between  variables  is \nnon-linear. In such cases, they may underfit the data, meaning they are too simple to capture \nthe underlying patterns. \nNon-Linearity: \nNon-Linear Relationship: A non-linear relationship implies that the change in one variable is \nnot proportional to the  change in another variable. Non-linear relationships can take various \nforms, such as quadratic, exponential, logarithmic, or arbitrary shapes. \nNon-Linear  Models:  Machine  learning  models  like  decision  trees,  random  forests,  support \nvector   machines   with   non-linear   kernels,   and   neural   networks   can   capture   non-linear \nrelationships. These models are more flexible and can fit complex data patterns. \nBenefits: Non-linear models can perform well when the underlying relationships in the data \nare complex or when interactions between variables are non-linear. They have the capacity to \ncapture intricate patterns. \n         \nTypes of Regression       \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":13}}}],["1bed3aae-8fff-49a3-aa0d-944eba6dac2e",{"pageContent":"ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                                     \n \n                                                                                            4 \nLinear Regression:  \nSingle Independent Variable:  Linear regression, also known as simple linear regression, is \nused  when  there  is  a  single  independent  variable  (predictor)  and  one  dependent  variable \n(target). \nEquation: The linear regression equation takes the form: Y = β0 + β1X + ε, where Y is the \ndependent  variable,  X  is  the  independent  variable,  β0  is  the  intercept,  β1  is  the  slope \n(coefficient), and ε is the error term. \nPurpose: Linear regression is used to establish a linear relationship between two variables and \nmake predictions based on this relationship. It's suitable for simple scenarios where there's only \none predictor. \nMultiple Regression: \nMultiple Independent Variables: Multiple regression, as the name suggests, is used when there \nare two or more independent variables (predictors) and one dependent variable (target). \nEquation: The multiple regression equation extends the concept to multiple predictors: Y = β0 \n+ β1X1 + β2X2 + ... + βnXn + ε, where Y is the dependent variable, X1, X2, ..., Xn are the \nindependent variables, β0 is the intercept, β1, β2, ..., βn are the coefficients, and ε is the error \nterm. \nPurpose:  Multiple  regression  allows  you  to  model  the  relationship  between  the  dependent \nvariable and multiple predictors simultaneously. It's used when there are multiple factors that \nmay influence the target variable, and you want to understand their combined effect and make \npredictions based on all these factors. \nPolynomial Regression: \nUse: Polynomial regression is an extension of multiple regression used when the relationship \nbetween the independent and dependent variables is non-linear. \nEquation: The polynomial regression equation allows for higher-order terms, such as quadratic \nor cubic terms: Y = β0 + β1X + β2X^2 + ... + βnX^n + ε. This allows the model to fit a curve \nrather than a straight line. \nLogistic Regression: \nUse: Logistic regression is used when the dependent variable is binary (0 or 1). It models the \nprobability of the dependent variable belonging to a particular class. \nEquation:   Logistic   regression   uses   the   logistic   function   (sigmoid   function)   to   model \nprobabilities:  P(Y=1)  =  1  /  (1  +  e^(-z)),  where  z  is  a  linear  combination  of  the  independent \nvariables: z = β0 + β1X1 + β2X2 + ... + βnXn. It transforms this probability into a binary \noutcome. \nLasso Regression (L1 Regularization): \nUse: Lasso regression is used for feature selection and regularization. It penalizes the absolute \nvalues of the coefficients, which encourages sparsity in the model. \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":14}}}],["ee42cad3-0144-4a27-a063-fd080b7ff9aa",{"pageContent":"ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                                     \n \n                                                                                            5 \nObjective Function: Lasso regression adds an L1 penalty to the linear regression loss function: \nLasso = RSS + λΣ|βi|, where RSS is the residual sum of squares, λ is the regularization strength, \nand |βi| represents the absolute values of the coefficients. \nRidge Regression (L2 Regularization): \nUse: Ridge regression is used for regularization to prevent overfitting in multiple regression. It \npenalizes the square of the coefficients. \nObjective Function: Ridge regression adds an L2 penalty to the linear regression loss function: \nRidge = RSS + λΣ(βi^2), where RSS is the residual sum of squares, λ is the regularization \nstrength, and (βi^2) represents the square of the coefficients. \n \nLimitations of Regression        \n \n5.3 INTRODUCTION TO LINEAR REGRESSION     \nLinear regression model can be created by fitting a line among the scattered   data points. The \nline is of the form: \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":15}}}],["d831906b-e432-4725-adb8-d2cbb5195780",{"pageContent":"ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                                     \n \n                                                                                            6 \n \nOrdinary Least Square Approach       \n The  ordinary  least  squares  (OLS)  algorithm  is a  method  for  estimating  the  parameters  of  a \nlinear regression model.  Aim: To find the values of the linear regression model's parameters \n(i.e., the coefficients) that minimize the sum of the squared residuals. \nIn mathematical terms, this can be written as:   Minimize ∑(yi – ŷi)^2 \nwhere yi is the actual value, ŷi is the predicted value.  \nA linear regression model used for determining the value of the response variable, ŷ, can be \nrepresented as the following equation.  \ny = b0 + b1x1 + b2x2 + ... + bnxn + e \n where:  y - is the dependent variable, b0 is the intercept, e is \nthe error term \n b1,  b2,  ...,  bn  are  the  coefficients  of  the  independent \nvariables x1, x2, ..., xn \nThe coefficients b1, b2, ..., bn can also be called the coefficients \nof determination.  The  goal  of  the  OLS  method  can  be  used  to \nestimate the unknown parameters (b1, b2, ..., bn) by minimizing \nthe sum of squared residuals (RSS). The sum of squared residuals \nis also termed the sum of squared error (SSE). \nThis method is also known as the least-squares method for regression or linear regression. \nMathematically the line of equations for points are:  \ny\n1\n=(a\n0\n+a\n1\nx\n1\n)+e\n1 \ny\n2\n=(a\n0\n+a\n1\nx\n2\n)+e\n2      \nand so on  \n....... \ny\nn\n=(a\n0\n+a\n1\nx\nn\n)+e\nn. \nIn general\n  \ne\ni\n=y\ni\n - (a\n0\n+a\n1\nx\n1) \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":16}}}],["28f734ae-5adb-44c7-a3e3-799aae54c972",{"pageContent":"ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                                     \n \n                                                                                            7 \n \n \nLinear Regression Example    \n   \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":17}}}],["11b94360-8492-4c07-93cf-b5198173dba7",{"pageContent":"ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                                     \n \n                                                                                            8 \n \n \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":18}}}],["00f21d8f-362f-4965-9245-3e33ad9f0349",{"pageContent":"ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                                     \n \n                                                                                            9 \nLinear Regression in Matrix Form  \n \n  \n  \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":19}}}],["b6c96308-acce-4650-bb0c-3fd6566f71e4",{"pageContent":"ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                                     \n \n                                                                                            10 \n \n5.4 VALIDATION OF REGRESSION METHODS        \nThe  regression  should  be  evaluated  using  some  metrics  for  checking  the  correctness.  The \nfollowing metrics are used to validate the results of regression.   \n \n \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":20}}}],["a92f3668-4123-4f84-869c-fb0d8487099c",{"pageContent":"ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING(21CS54)                                     \n \n                                                                                            11 \n \nCoefficient of Determination \nThe coefficient of determination (R² or r-squared) is a statistical measure in a regression model \nthat determines the proportion of variance in the dependent variable that can be explained by \nthe independent variable. \nThe sum of the squares of the differences between the y-value of the data pair and the average \nof y is called total variation. Thus, the following variation can be defined as, \nThe explained variation is given by, =∑( Ŷ\ni\n – mean(Y\ni)\n)\n2\n \nThe unexplained variation is given by, =∑( Y\ni   \n- Ŷ\ni \n)\n2\n \nThus, the total variation is equal to the explained variation and the unexplained variation. \nThe coefficient of determination r2 is the ratio of the explained and unexplained variations.  \n \n \n \n \n \n \n \nvtucode.in","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":21}}}],["ffe72fd8-2a71-4fea-a99f-2dbbd018fcc1",{"pageContent":"CHAPTER 5 \nREGRESSION ANALYSIS \n \n5. Consider the following dataset in Table 5.11 where the week and number of working hours per \nweek spent by a research scholar in a library are tabulated. Based on the dataset, predict the \nnumber of hours that will be spent by the research scholar in the 7\nth\n and 9\nth\n week. Apply Linear \nregression model. \n \nTable 5.11 \ni\nx\n \n(week) \n1 2 3 4 5 \ni\ny\n \n(Hours Spent) \n12 18 22 28 35 \n \nSolution \nThe computation table is shown below: \ni\nx\n \ni\ny\n \nii\nxx\n \nii\nxy\n \n1 12 1 12 \n2 18 4 36 \n3 22 9 66 \n4 28 16 112 \n5 35 25 175 \nSum = 15 \navg(\ni\nx\n)=15/5=3 \nSum = 115 \navg(\ni\ny\n)=115/5=23 \nAvg (\nii\nxx\n\n)=55/5=11 Avg(\nii\nxy\n\n)=401/5=80.2 \n \n \nThe regression Equations are \n \n \n \n1\n2\n80.2   3(23)\n80.2   69\n11.2\n5.6\n11   3\n11   9\n2\na\n−−\n=\n=\n=\n=\n−−\n \n0\n23   5.6   3    23   16.8    6.2a=  −   =  −   =\n \nTherefore, the regression equation is given as \n()()()\n()\n()\n1\n2\n2\ni\nxyx    y\na\nxx\n−\n=\n\n()\n01\naya    x=   −  ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":22}}}],["cb72fddb-99cb-463b-aaa8-64ef76413aec",{"pageContent":"5.6   6.2\nyx\n=   +   \n \nThe prediction for the 7\nth\n week hours spent by the research scholar will be \n5.6   6.2   7    49\ny\n=   +    =\n hours \nThe prediction for the 9\nth\n week hours spent by the research scholar will be  \n5.6   6.2   9    61.4    61\ny\n=   +    =    \n hours \n \n6. The height of boys and girls is given in the following Table5.12. \n     Table 5.12: Sample Data \n \nHeight of Boys 65 70 75 78 \nHeight of Girls 63 67 70 73 \n \nFit a suitable line of best fit for the above data. \nSolution \nThe computation table is shown below: \ni\nx\n \ni\ny\n \nii\nxx\n\n \nii\nxy\n\n \n65 63 4225 4095 \n70 67 4900 4690 \n75 70 5625 5250 \n78 73 6084 5694 \nSum = 288 \nMean(\ni\nx\n)=288/4=72 \nSum = 273 \nMean(\ni\ny\n)=273/4=68.25 \nAvg (\nii\nxx\n)=20834/4=5208.5 \nAvg(\nii\nxy\n)=19729/4=4932.25 \n \n \nThe regression Equations are \n \n \n \n(\n)\n(\n)\n(\n)\n(\n)\n(\n)\n1\n2\n2\ni\nxy\nx    y\na\nxx\n−\n=\n\n()\n01\naya    x=   −  ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":23}}}],["d4e8eef4-8aec-40eb-bb19-c52ddeef4eb9",{"pageContent":"1\n2\n4932.25   72(68.25)\n18.25\n0.7449\n5208.5   72\n24.5\na\n−\n=\n=\n=\n−\n \n0\n68.25   0.7449   72    68.25   53.6328   14.6172\na\n=\n−\n  =\n−\n=\n \nTherefore, the regression line of best fit is given as  \n0.7449   14.6172\nyx\n=\n+\n\n \n \n7. Using multiple regression, fit a line for the following dataset shown in Table 5.13. \nHere, Z is the equity, X is the net sales and Y is the asset. Z is the dependent variable \nand X and Y are independent variables. All the data is in million dollars.  \n \n                           Table 5.13: Sample Data \n \nZ X Y \n4 12 8 \n6 18 12 \n7 22 16 \n8 28 36 \n11 35 42 \n \nSolution \nThe matrix X and Y is given as follows: \n1   128\n1   18    12\n1   22    16\n1   28    36\n1   35    42\n4\n6\n7\n8\n11\nX\nY\n\n\n\n\n=\n\n\n\n\n\n\n\n\n=\n\n\n\n\n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":24}}}],["7e4bf9d9-b59f-4699-9701-3fb5efd9361b",{"pageContent":"The regression coefficients can be found as follows \n^\n1\n((\n)\n)\nTT\na\nX  X\nX   Y\n−\n=\n \n \nSubstituting the values one get, \n1\n^\n1   12\n8\n1   12\n8\n4\n1\n1\n1\n1\n1\n1   18    12\n1   18    12\n6\n12   18    22    28    35\n1   22    16\n1   22    16\n7\n8\n12    16    36    42\n1   28    36\n1   28    36\n8\n1   35    42\n1   35    42\n11\nT\na\n−\n\n\n    \n    \n\n\n    \n    \n\n\n\n    \n    \n\n\n\n    \n    \n=\n\n\n\n\n\n\n    \n    \n\n\n\n\n\n    \n    \n\n    \n    \n\n\n    \n    \n\n \n=\n1\n4\n5\n115\n114\n1\n1\n1\n1\n1\n6\n115    2961   3142\n12   18    22    28    35\n7\n114    3142    3524\n8\n12    16    36    42\n8\n11\n−\n\n\n\n   \n\n\n\n   \n\n\n\n\n   \n\n\n\n   \n\n\n   \n\n\n\n\n \n=\n0.4135\n0.39625\n0.0658\n−\n\n\n\n\n−\n\n \nTherefore, the regression line is given as \n12\n0.39625\n0.0658\n0.4135\ny\nx\nx\n=\n−−\n−\n \n*** ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\@vtucode.in-Module-3-AI-2021-scheme-5th-sem.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"pdf-lib (https://github.com/Hopding/pdf-lib)","Producer":"pdf-lib (https://github.com/Hopding/pdf-lib)","CreationDate":"D:20240119134547Z","ModDate":"D:20240119161622Z"},"metadata":null,"totalPages":25},"loc":{"pageNumber":25}}}],["841eb631-264b-404c-943f-bc8545b59c34",{"pageContent":" \n  \n \nComplete the following courses and submit the certificate  \n \n1. Python Libraries for Machine Learning \nhttps://www.mygreatlearning.com/academy/learn-for-free/courses/python-\nlibraries-for-machine-learning \n \n2. Data Visualization using Python \n \nhttps://www.mygreatlearning.com/academy/learn-for-free/courses/data-\nvisualization-using-python \n \n \n3. Introduction to Machine Learning \n \nhttps://www.mygreatlearning.com/academy/learn-for-free/courses/introduction-to-\nmachine-learning1 \n \n4. Support Vector Machines \n \nhttps://www.mygreatlearning.com/academy/learn-for-free/courses/support-vector-machines \n \n5. Unsupervised Machine Learning with K-means \n \nhttps://www.mygreatlearning.com/academy/learn-for-free/courses/unsupervised-machine-\nlearning-with-k-means \n \nAssignment - 1 \nSubject: \nArtificial Intelligence & Machine Learning Subject Code: 21CS54 \nMarks  \n10 \nDayananda Sagar Academy of Technology & Management \n(Autonomous Institute under VTU) \nAffiliated to VTU \nApproved by AICTE \nAccredited by NAAC with A+ Grade \n6 Programs Accredited by NBA \n(CSE, ISE, ECE, EEE, MECH, CV) ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\AIML_Assignment1[1].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Author":"RAVISHANKAR M","Creator":"Microsoft® Word 2019","Producer":"Microsoft® Word 2019","CreationDate":"D:20240123143604+05'30'","ModDate":"D:20240123143604+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word 2019","dc:creator":"RAVISHANKAR M","xmp:creatortool":"Microsoft® Word 2019","xmp:createdate":"2024-01-23T14:36:04+05:30","xmp:modifydate":"2024-01-23T14:36:04+05:30","xmpmm:documentid":"uuid:C2BCB242-FB2B-4863-9C61-0740423242BC","xmpmm:instanceid":"uuid:C2BCB242-FB2B-4863-9C61-0740423242BC"}},"totalPages":1},"loc":{"pageNumber":1}}}],["c7d7c37d-0431-4209-bff4-e318e716bc09",{"pageContent":"                  DAYANANDA SAGAR ACADEMY OF TECHNOLOGY AND MANAGEMENT \nUdayapura, Kanakapura Road, Opp. Art of Living, Bangalore – 560082 \n(Affliated to VTU, Belagavi, Approved by AICTE, New Delhi) \nAccredited by NBA and NAAC ( A+) \nDEPARTMENT OF COMPUTER SCIENCE & ENGINEERING \n2023-2024 \nDBMS LAB MANUAL \n(21CSL55) \n \n \n \nCompiled by: \n         Prof. Lakshmi M.R \n   Prof. Manasa Sandeep \nProf. Shylaja B. \n \n \n \n \n \n \nDr. Kavitha C Dr. M Ravishankar \nHOD, CSE, DSATM Principal, DSATM ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":1}}}],["d62c5492-fe98-4ac6-b679-dba8cf62a6a6",{"pageContent":"Page 2 \nDept. of CSE, DSATM, Bangalore-82 \n2023-24 \nDBMS Lab Manual 21CSL55 \n  \n \n \n \n21CSL55: DBMS LABORATORY WITH MINI PROJECT \nCourse objectives: This course will enable students to \n Foundation knowledge in database concepts, technology and practice to groom students into \nwell-informed database application developers. \n Strong practice in SQL programming through a variety of database problems. \n Develop database applications using front-end tools and back-end DBMS. \n \nDatabase: A Database is a collection of interrelated data and a Database Management Systemis a a \nsoftware  system  that  enables  users  to  define,  create  and  maintain  the  database  and  which  provides \ncontrolled access to the database \n \nSQL: It is structured query language, basically used to pass the query to retrieve andmanipulate the \ninformation  from  database.  Depending  upon  the  nature  of  query,  SQL  is divided  into  different \ncomponents: \n \n• DDL(Data Definition Language ) \n• DML(Data Manipulation Language ) \n• DCL(Data Control Language ) \n \nDDL: The   Data   Definition   Language   (DDL)   is   used   to   create   the   database   (i.e.   tables, \nkeys,relationships  etc),  maintain  the  structure  of  the  database  and  destroy  databases  and  database \nobjects. \n \nEg. Create, Drop, Alter, Describe, Truncate \n \n1. CREATE statements: It is used to create the table. \n \nSyntax: \nCREATE TABLE table_name(columnName1 datatype(size), columnName2 datatype(size), ......... ); \n \n2. DROP statements: To destroy an existing database, table, index, or view. If a table \nisdropped all records held within it are lost and cannot be recovered. \nSyntax: \nDROP TABLE table_name; \n \n3. ALTER statements: To modify an existing database object. \n \n• Adding new \ncolumns: \nSyntax: \n \nAlter table table_name Add(New_columnName1 datatype(size), New_columnName2 \ndatatype(size), ........ ) ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":2}}}],["bd9be4c4-9339-4de9-b2ac-123580cc3ccf",{"pageContent":"Page 3 \nDept. of CSE, DSATM, Bangalore-82 \n2023-24 \nDBMS Lab Manual 21CSL55 \n  \n \n \n \n• Dropping a columns from a \ntable : Syntax: \nAlter table table_name DROP column columnName: \n \n• Modifying Existing columns: \nSyntax: \nAlter table table_name Modify (columnName1 Newdatatype(Newsize)); \n \n4. Describe statements: To describe the structure (column and data types) of an \nexistingdatabase, table, index, or view. \nSyntax: \nDESC table_name; \n \n5. Truncate statements: To destroy the data in an existing database, table, index, or view.If a \ntable  is  truncated  all  records  held  within  it  are  lost  and  cannot  be  recovered  but  the  table \nstructure is maintained. \nSyntax : \nTRUNCATE TABLE table_name; \n \nData Manipulation Language (DML): \n• A Data Manipulation Language enables programmers and users of the database to retrieve insert, \ndelete and update data in a database. e.g. INSERT, UPDATE, DELETE, SELECT. \n \nINSERT: INSERT statement adds one or more records to any single table in a relationaldatabase. \nSyntax: \n \nINSERT INTO tablename VALUES (expr1,expr2. ...... ); \n \nUPDATE: UPDATE statement that changes the data of one or more records in a table. Eitherall the \nrows can be updated, or a subset may be chosen using a condition. \n \nSyntax: \nUPDATE table_name SET column_name = value [, column_name = value .... ] [WHERE \ncondition] \n \nDELETE: DELETE statement removes one or more records from a table. A subset may bedefined \nfor deletion using a condition, otherwise all records are removed. \n \nSyntax: \nDELETE FROM tablename WHERE condition: \nSELECT: SELECT statement returns a result set of records from one or more tables. \nThe select statement has optional clauses: \n• WHERE specifies which rows to retrieve ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":3}}}],["f404e24e-5728-439c-ac9b-6f935274bcd6",{"pageContent":"Page 4 \nDept. of CSE, DSATM, Bangalore-82 \n2023-24 \nDBMS Lab Manual 21CSL55 \n  \n \n \n \n• GROUP BY groups rows sharing a property so that an aggregate function can be \napplied to each group having group. \n• HAVING selects among the groups defined by the GROUP BY clause. \n \n• ORDER BY specifies an order in which to return the rows. \n \nSyntax: \n \nSELECT<attribute list> FROM<table list> \nWHERE<condition> Where \n \n• Attribute list is a list of attribute name whose values to be retrieved by the query. \n \n• Table list is a list of table name required to process query. \n \n• Condition is a Boolean expression that identifies the tuples to be retrieved by query. \nData Constraints are the business Rules which are enforced on the data being stored in a tableare \ncalled Constraints. \n \nTypes of Data Constraints \n \n1. I/O Constraint This type of constraint determines the speed at which data can be inserted \nor extracted from an Oracle table. I/O Constraints is divided into two different types \n● The Primary Key Constraint \n● The Foreign Key Constraint \n \n2. Business rule Constraint This type of constraint is applied to data prior the data being \nInserted into table columns. \n \n● Column level \n● Table level \n \n \nThe PRIMARY KEY defined at column level \nSyntax: \nCREATETABLEtablename \n(Columnname1DATATYPE \nCONSTRAINT <constraintname1> \nPRIMARY KEY, Columnname2 \nDATATYPE, columnname3 \nDATATYPE, .... ); ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":4}}}],["b387a6b2-0423-4b8f-85e4-4489f564b809",{"pageContent":"Page 5 \nDept. of CSE, DSATM, Bangalore-82 \n2023-24 \nDBMS Lab Manual 21CSL55 \n  \n \n \n \nThe PRIMARY KEY defined at table level \nSyntax: \nCREATE TABLE tablename (Columnname1 DATATYPE, columnname2 DATATYPE, \ncolumnname3 DATATYPE, PRIMARY KEY (columnname1, columnname2)); \nThe FOREIGN KEY defined at column level \nSyntax \nCREATE TABLE tablename (Columnname1 \ntablename[(columnname)]   [ON DELETE CASCADE], \ncolumnname3 DATATYPE , .... ); \n \n \nDATATYPE columnname2 REFERENCES DATATYPE , \n \nThe  table  in  which  FOREIGN  KEY  is  defined  is  called  FOREIGN  TABLE  or  DETAIL  TABLE. \nThe  table  in  which  PRIMARY  KEY  is  defined  and  referenced  by  FOREIGN  KEY  is  called \nPRIMARY TABLE or MASTER TABLE. \n \nON DELETE CASCADE is set then DELETE operation in master table will trigger the \nDELETE operation for corresponding records in the detail table. \n \nThe FOREIGN KEY defined at table level \nSyntax: \nCREATE   TABLE   table   name   (Columnname1   DATATYPE,   columnname2   DATATYPE, \ncolumnname3  DATATYPE,  PRIMARY  KEY (columnname1,  columnname2),  FOREIGN  KEY \n(columnname2) REFERENCES tablename2; \n \nA CONSTRAINT can be given User Defined Name, the syntax is: \nCONSTRAINT < constraint name><constraint definition> \n \nThe CHECK Constraint defined at column level \nSyntax: \n \nCREATE TABLE tablename (Columnname1 DATATYPE CHECK (logical expression), \ncolumnname2 DATATYPE, columnname3 DATATYPE, .. ); ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":5}}}],["c49fb5c2-0447-4b87-a6e7-4ad89b8c4a0c",{"pageContent":"Page 6 \nDept. of CSE, DSATM, Bangalore-82 \n2023-24 \nDBMS Lab Manual 21CSL55 \n  \n \n \n \n \nThe CHECK Constraint defined at table level \nSyntax: \n \nCREATE TABLE table name (Columnname1 DATATYPE, columnname2 DATATYPE, \ncolumnname3 DATATYPE, CHECK (logical expression1), CHECK (logical expression2)); \n \nThe UNIQUE Constraint defined at the column level \nSyntax: \n \nCREATE TABLE tablename (Columnname1 DATATYPE UNIQUE, columnname2 DATATYPE \nUNIQUE, columnname3 DATATYPE ...); \n \nThe UNIQUE Constraint defined at the the table level \nSyntax: \nCREATE TABLE tablename (Columnname1 DATATYPE, columnname2 DATATYPE, \ncolumnname3 DATATYPE, UNIQUE(columnname1)); \n \nNOT NULL constraint defined at column level : \nSyntax: \nCREATE TABLE tablename (Columnname1 DATATYPE NOT NULL, columnname2 \nDATATYPE NOT NULL, columnname3 DATATYPE,...); \n \n \nNote: \nThe NOT NULL constraint can only be applied at column level. \n \nER- Diagram: It   is   an   Entity –Relationship   diagram   which   is   used   to   represent   the \nrelationshipbetween   different   entities.   An   entity   is   an   object   in   the   real   world   which   is \ndistinguishable  from  other  objects.  The  overall  logical  structure  of  a  database  can  be  expressed \ngraphically by an ER diagram, which is built up from following components. \n \n Rectangles: represent entity sets. \n Ellipses: represent attributes. \n Diamonds: represent relationships among entity sets. \n Lines: link attribute to entity sets and entity sets to relationships. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":6}}}],["271546d9-2bf8-43cd-b5c9-16fd380a799f",{"pageContent":"Page 7 \nDept. of CSE, DSATM, Bangalore-82 \n2023-24 \nDBMS Lab Manual 21CSL55 \n  \n \n \n \nMapping Cardinalities: It expresses the number of entities to which another entity can beassociated \nvia  a  relationship  set.  For  a  binary  relationship  set  R  between  entity  sets  A  and  B.  The  Mapping \nCardinalities must be one of the following. \n One to one \n One to many \n Many to one \n Many to many","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":7}}}],["346b0c68-39cb-4586-a215-bd788376b4bc",{"pageContent":"DBMS Lab Manual 18CSL58 \nPage 8 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n\n\nLAB EXPERIMENTS \n \nPART A: SQL PROGRAMMING \n \n1. Consider the following schema for a Library Database: \nBOOK(Book_id, Title, Publisher_Name, Pub_Year) \nBOOK_AUTHORS(Book_id, Author_Name) \nPUBLISHER(Name, Address, Phone) \nBOOK_COPIES(Book_id, Programme_id, No-of_Copies) \nBOOK_LENDING(Book_id, Programme_id, Card_No, Date_Out, Due_Date) \nLIBRARY_PROGRAMME(Programme_id, Programme_Name, Address) \n \n Write SQL queries to \n 1. Retrieve details of all books in the library – id, title, name of publisher, authors, number of copies \nin each Programme, etc. \n 2. Get the particulars of borrowers who have borrowed more than 3 books, but from Jan 2017 to Jun \n2017. \n 3. Delete a book in BOOK table. Update the contents of other tables to reflect this data manipulation \noperation. \n 4. Partition the BOOK table based on year of publication. Demonstrate its working with a simple query. \n 5. Create a view of all books and its number of copies that are currently available in the Library. \n \nSolution: \nEntity-Relationship Diagram \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":8}}}],["f9f2e9e4-ea23-487c-b531-3c53cbc4d70b",{"pageContent":"DBMS Lab Manual 18CSL58 \nPage 9 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nSchema Diagram \n \nStep 1: Create Database \ncreate database Library; \nuse Library; \nStep 2: Create Tables \n \nCREATE TABLE PUBLISHER( \nNAME VARCHAR(18) PRIMARY KEY, \nADDRESS VARCHAR(10), \nPHONE VARCHAR(10)); \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":9}}}],["cddf2ee3-7d5f-489f-a940-7e9b91691efd",{"pageContent":"DBMS Lab Manual 18CSL58 \nPage 10 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nCREATE TABLE BOOK( \nBOOK_ID INTEGER PRIMARY KEY, \nTITLE VARCHAR(20), \nPUBLISHER_NAME VARCHAR(20), \nPUB_YEAR INT(4), \nFOREIGN KEY(PUBLISHER_NAME) REFERENCES PUBLISHER(NAME) ON \nDELETE CASCADE \n); \n \nCREATE TABLE BOOK_AUTHORS( \nBOOK_ID INTEGER, \nAUTHOR_NAME VARCHAR(20), \nPRIMARY KEY(BOOK_ID), \nFOREIGN KEY(BOOK_ID) REFERENCES BOOK(BOOK_ID) ON DELETE CASCADE); \n \nCREATE TABLE LIBRARY_PROGRAMME( \nPROGRAMME_ID INTEGER PRIMARY KEY, \nPROGRAMME_NAME VARCHAR(18), \nADDRESS VARCHAR(15)); \n \nCREATE TABLE BOOK_COPIES( \nBOOK_ID INTEGER, \nPROGRAMME_ID INTEGER, \nNO_OF_COPIES INTEGER, \nFOREIGN KEY(BOOK_ID) REFERENCES BOOK(BOOK_ID) ON DELETE CASCADE, \nFOREIGN KEY(PROGRAMME_ID) REFERENCES LIBRARY_PROGRAMME(PROGRAMME_ID) ON \nDELETE CASCADE, \nPRIMARY KEY(BOOK_ID,PROGRAMME_ID)); \n \nCREATE TABLE BOOK_LENDING( \nBOOK_ID INTEGER, \nPROGRAMME_ID INTEGER, \nCARD_NO INTEGER, \nDATE_OUT DATE, \nDUE_DATE DATE, \nPRIMARY KEY(BOOK_ID,PROGRAMME_ID,CARD_NO), \nFOREIGN KEY(BOOK_ID) REFERENCES BOOK(BOOK_ID) ON DELETE CASCADE, ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":10}}}],["c6c471cd-3019-4ae1-882f-ca31a5bcab13",{"pageContent":"DBMS Lab Manual 18CSL58 \nPage 11 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nFOREIGN KEY(PROGRAMME_ID) REFERENCES LIBRARY_PROGRAMME(PROGRAMME_ID) ON \nDELETE CASCADE \n); \n \nStep 3: Insert Values into Tables \nINSERT INTO PUBLISHER VALUES('PEARSON','BANGALORE','9875462530'); \nINSERT INTO PUBLISHER VALUES('MCGRAW','NEWDELHI','7845691234'); \nINSERT INTO PUBLISHER VALUES('SAPNA','BANGALORE','7845963210'); \n \nINSERT INTO BOOK VALUES(1111,'SE','PEARSON',2005); \nINSERT INTO BOOK VALUES(2222,'DBMS','MCGRAW',2004); \nINSERT INTO BOOK VALUES(3333,'ANOTOMY','PEARSON',2010);  \nINSERT INTO BOOK VALUES(4444,'ENCYCLOPEDIA','SAPNA',2010); \n \nINSERT INTO BOOK_AUTHORS VALUES(1111,'SOMMERVILLE'); \nINSERT INTO BOOK_AUTHORS VALUES(2222,'NAVATHE'); \nINSERT INTO BOOK_AUTHORS VALUES(3333,'HENRY GRAY'); \nINSERT INTO BOOK_AUTHORS VALUES(4444,'THOMAS'); \n \nINSERT INTO LIBRARY_PROGRAMME VALUES(11,'CENTRAL TECHNICAL','MG \nROAD'); \nINSERT INTO LIBRARY_PROGRAMME VALUES(22,'MEDICAL','BH ROAD'); \nINSERT INTO LIBRARY_PROGRAMME VALUES(33,'CHILDREN','SS PURAM'); \nINSERT INTO LIBRARY_PROGRAMME VALUES(44,'SECRETARIAT','SIRAGATE'); \nINSERT INTO LIBRARY_PROGRAMME VALUES(55,'GENERAL','JAYANAGAR'); \n \nINSERT INTO BOOK_COPIES VALUES(1111,11,5); \nINSERT INTO BOOK_COPIES VALUES(3333,22,6); \nINSERT INTO BOOK_COPIES VALUES(4444,33,10); \nINSERT INTO BOOK_COPIES VALUES(2222,11,12); \nINSERT INTO BOOK_COPIES VALUES(4444,55,3); \n \nINSERT INTO BOOK_LENDING VALUES(2222,11,1,'2017-01-10','2017-08-20'); \nINSERT INTO BOOK_LENDING VALUES(3333,22,2,'2017-07-09','2017-08-12'); \nINSERT INTO BOOK_LENDING VALUES(4444,55,1,'2017-04-11','2017-08-09'); \nINSERT INTO BOOK_LENDING VALUES(2222,11,5,'2017-08-09','2017-08-19'); \nINSERT INTO BOOK_LENDING VALUES(4444,33,1,'2017-06-10','2017-08-15'); \nINSERT INTO BOOK_LENDING VALUES(1111,11,1,'2017-05-12','2017-06-10'); \nINSERT INTO BOOK_LENDING VALUES(3333,22,1,'2017-07-10','2017-07-15'); \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":11}}}],["dcbfe1c4-13c4-40fc-a072-e8fe2b0b597c",{"pageContent":"DBMS Lab Manual 18CSL58 \nPage 12 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nStep 4: Display table contents \nSELECT * FROM BOOK; \n \n \n \nSELECT * FROM BOOK; \n \n \n \nSELECT * FROM BOOK_AUTHORS; \n \n \nSELECT * FROM LIBRARY_PROGRAMME; \n \n \nSELECT * FROM BOOK_COPIES; \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":12}}}],["e7f67d37-d679-4329-bc4d-8e040bd5340c",{"pageContent":"DBMS Lab Manual 18CSL58 \nPage 13 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nSELECT * FROM BOOK_LENDING; \n \n \n \nStep 5: Execute Queries: \n \n/* 1) Retrieve details of all books in the library – id, title, name of \npublisher, authors, number of copies in each PROGRAMME, etc.*/ \n \nSELECT PROGRAMME_NAME, B.BOOK_ID,TITLE, \nPUBLISHER_NAME,AUTHOR_NAME, NO_OF_COPIES \nFROM BOOK B, BOOK_AUTHORS BA, BOOK_COPIES BC, \nLIBRARY_PROGRAMME LB WHERE B.BOOK_ID = BA.BOOK_ID AND \nBA.BOOK_ID = BC.BOOK_ID AND \nBC.PROGRAMME_ID = LB.PROGRAMME_ID; \nOutput: \n \n \n/* 2) Get the particulars of borrowers who have borrowed more than 3 \nbooks, but from Jan 2017 to Jun 2017. */ \nSELECT CARD_NO \nFROM BOOK_LENDING \nWHERE DATE_OUT BETWEEN '2017-01-01' AND '2017-06-30' \nGROUP BY CARD_NO \nHAVING COUNT(*) > 3; \n \nOutput: \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":13}}}],["4d3400a7-f170-4999-9ff2-201ad0448613",{"pageContent":"DBMS Lab Manual 18CSL58 \nPage 14 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \n/* 3) Delete a book in BOOK table. Update the contents of other tables to \nreflect this data manipulation operation. */ \nDELETE FROM BOOK \nWHERE BOOK_ID = '3333'; \n \nSELECT * FROM BOOK; \nOutput: \n \n \n \n/* 4) Partition the BOOK table based on year of publication. Demonstrate \nits working with a simple query. */ \nCREATE VIEW V_PUBLICATION AS \nSELECT PUB_YEAR \nFROM BOOK; \n \nSELECT * FROM V_PUBLICATION; \nOutput: \n \n \n \n/* 5) Create a view of all books and its number of copies that are \ncurrently available in the Library. */ \n \nCREATE VIEW BOOKS_AVAILABLE AS \nSELECT B.BOOK_ID, B.TITLE, C.NO_OF_COPIES \nFROM LIBRARY_PROGRAMME L, BOOK B, BOOK_COPIES C \nWHERE B.BOOK_ID = C.BOOK_ID AND L.PROGRAMME_ID=C.PROGRAMME_ID; \n \nSELECT * FROM BOOKS_AVAILABLE; \nOutput: \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":14}}}],["1018f4e9-bc77-4f1a-b600-1067ebe4eda2",{"pageContent":"DBMS Lab Manual 18CSL58 \nPage 15 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \n2. Consider the following schema for Order Database: \nSALESMAN (Salesman_id, Name, City, Commission) \nCUSTOMER (Customer_id, Cust_Name, City, Grade,Salesman_id) \nORDERS (Ord_No, Purchase_Amt, Ord_Date, Customer_id, Salesman_id)  \n \nWrite SQL queries to \n1. Count the customers with grades above Bangalore‟s average. \n2. Find the name and numbers of all salesmen who had more than one customer. \n3. List all salesmen and indicate those who have and don‟t have customers in their cities (Use \nUNION operation.) \n4. Create a view that finds the salesman who has the customer with the highest order of a day. \n5. Demonstrate the DELETE operation by removing salesman with id 1000. All his orders must \nalso be deleted. \n \nSolution: \n \nEntity-Relationship Diagram \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":15}}}],["0799e5af-587e-4ab0-9f94-aa19da3767f9",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 16 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nSchema Diagram \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nStep 1: Create Database \nCREATE DATABASE ORDERS11; \nUSE ORDERS11; \n \nStep 2: Create Tables \nCREATE TABLE SALESMAN ( \nSALESMAN_ID INT (4),  \nNAME VARCHAR (20),  \nCITY VARCHAR (20),  \nCOMMISSION VARCHAR (20),  \nPRIMARY KEY(SALESMAN_ID));  \n \nCREATE TABLE CUSTOMER ( \nCUSTOMER_ID INT (4),  \nCUST_NAME VARCHAR (20),  \nCITY VARCHAR (20),  \nGRADE INT (3),  \nSALESMAN_ID INT (4),  \nPRIMARY KEY (CUSTOMER_ID),  \nFOREIGN KEY(SALESMAN_ID) REFERENCES SALESMAN (SALESMAN_ID) ON DELETE SET \nNULL);  ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":16}}}],["c5002676-3560-4a46-b65f-5bfaed19be34",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 17 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nCREATE TABLE ORDERS ( \nORD_NO INT(5),  \nPURCHASE_AMT FLOAT(10, 2),  \nORD_DATE DATE,  \nCUSTOMER_ID INT (4),  \nSALESMAN_ID INT (4),  \nPRIMARY KEY (ORD_NO),  \nFOREIGN KEY (CUSTOMER_ID) REFERENCES CUSTOMER(CUSTOMER_ID) ON DELETE \nCASCADE,  \nFOREIGN KEY (SALESMAN_ID) REFERENCES SALESMAN (SALESMAN_ID) ON DELETE \nCASCADE);  \n \nStep 3: Insert Values into Tables \n \nINSERT INTO SALESMAN VALUES (1000, 'JOHN','BANGALORE','25 %');  \nINSERT INTO SALESMAN VALUES (2000, 'RAVI','BANGALORE','20 %');  \nINSERT INTO SALESMAN VALUES (3000, 'KUMAR','MYSORE','15 %');  \nINSERT INTO SALESMAN VALUES (4000, 'SMITH','DELHI','30 %');  \nINSERT INTO SALESMAN VALUES (5000, 'HARSHA','HYDRABAD','15%');  \n \nINSERT INTO CUSTOMER VALUES (10, 'PREETHI','BANGALORE', 100, 1000);  \nINSERT INTO CUSTOMER VALUES (11, 'VIVEK','MANGALORE', 300, 1000);  \nINSERT INTO CUSTOMER VALUES (12, 'BHASKAR','CHENNAI', 400, 2000);  \nINSERT INTO CUSTOMER VALUES (13, 'CHETHAN','BANGALORE', 200, 2000);  \nINSERT INTO CUSTOMER VALUES (14, 'MAMATHA','BANGALORE', 400, 3000);  \n \nINSERT INTO ORDERS VALUES (50, 5000, '2017-05-04', 10, 1000);  \nINSERT INTO ORDERS VALUES (55, 1000, '2017-05-04', 10, 1000);  \nINSERT INTO ORDERS VALUES (56, 300, '2017-05-04', 10, 2000);  \nINSERT INTO ORDERS VALUES (51, 450, '2017-01-20', 10, 2000);  \nINSERT INTO ORDERS VALUES (52, 1000, '2017-02-24', 13, 2000);  \nINSERT INTO ORDERS VALUES (53, 3500, '2017-04-13', 14, 3000);  \nINSERT INTO ORDERS VALUES (54, 550, '2017-03-09', 12, 2000);  \nINSERT INTO ORDERS VALUES (57, 450, '2017-03-09', 12, 2000);  \nINSERT INTO ORDERS VALUES (58, 350, '2017-03-09', 12, 2000);  \nINSERT INTO ORDERS VALUES (60, 150, '2017-03-09', 12, 1000);  ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":17}}}],["bc5b7ac2-145d-42ca-8e23-13e26eff672b",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 18 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nINSERT INTO ORDERS VALUES (61, 200, '2017-03-09', 12, 3000);  \n \nStep 4: Display table contents \nselect * from SALESMAN; \n \n \n \nselect * from CUSTOMER; \n \n \n \nselect * from ORDERS; \n \n \n \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":18}}}],["f3fa854d-12b8-4f3d-bc82-043e1becd696",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 19 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nStep 5: Execute Queries: \n \n-- 1. Count the customers with grades above Bangalore’s average. \nSELECT GRADE, COUNT(CUSTOMER_ID)  \nFROM CUSTOMER \nGROUP BY GRADE  \nHAVING GRADE >  (SELECT AVG(GRADE) FROM CUSTOMER WHERE CITY='BANGALORE');  \nOutput: \n \n \n-- 2. Find the name and numbers of all salesmen who had more than one customer. \nSELECT SALESMAN_ID, NAME  \nFROM SALESMAN A  \nWHERE 1 < (SELECT COUNT(*) FROM CUSTOMER WHERE SALESMAN_ID=A.SALESMAN_ID); \nOutput: \n \n \n/* 3. List all salesmen and indicate those who have and don’t have customers in their cities (Use \nUNION operation)  */ \nSELECT SALESMAN.SALESMAN_ID, NAME, CUST_NAME  \nFROM SALESMAN, CUSTOMER  \nWHERE SALESMAN.CITY = CUSTOMER.CITY  \nUNION  \nSELECT SALESMAN_ID, NAME, 'NO MATCH'  \nFROM SALESMAN  \nWHERE NOT CITY = ANY (SELECT CITY FROM CUSTOMER) ORDER BY 2 DESC; \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":19}}}],["653f2fb2-3acd-4505-a794-7922f1ab2682",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 20 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nOutput: \n \n \n \n-- 4. Create a view that finds the salesman who has the customer with the highest order of a day. \n \nCREATE VIEW ELITESALESMAN AS  \nSELECT B.ORD_DATE, A.SALESMAN_ID, A.NAME  \nFROM SALESMAN A, ORDERS B  \nWHERE A.SALESMAN_ID = B.SALESMAN_ID AND B.PURCHASE_AMT=(SELECT \nMAX(PURCHASE_AMT) FROM ORDERS C WHERE C.ORD_DATE = B.ORD_DATE);  \n \nselect * from ELITESALESMAN; \nOutput: \n \n \n \n/* 5. Demonstrate the DELETE operation by removing salesman with id 1000. All his orders must also \nbe deleted. */ \n \nDELETE FROM SALESMAN WHERE SALESMAN_ID=1000; \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":20}}}],["b89eae30-2bf3-4d0f-a901-72b8a2177898",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 21 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nselect * from SALESMAN;  \n \nOutput: \n \n \n \n************** \n \n \n \n3. Consider the schema for MovieDatabase: \n \nACTOR (Act_id, Act_Name, Act_Gender) \nDIRECTOR (Dir_id, Dir_Name, Dir_Phone) \nMOVIES (Mov_id, Mov_Title, Mov_Year, Mov_Lang, Dir_id) \nMOVIE_CAST (Act_id, Mov_id, Role) \nRATING (Mov_id, Rev_Stars)  \n \nWrite SQL queries to \na. List the titles of all movies directed by „Hitchcock‟. \nb. Find the movie names where one or more actors acted in two or more movies. \nc. List all actors who acted in a movie before  2000 and also in a movie after  2015 \n(use JOIN operation). \nd. Find  the  title  of movies and  number  of  stars  for  each  movie  that  has  at  least  one  rating and \nfind the highest number of stars that movie received. Sort the result by movie title. \ne. Update rating of all movies directed by „Steven Spielberg‟ to 5. \n \n \n \n \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":21}}}],["d631e6f6-3cc1-4ca8-9a37-91cb721c7d1e",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 22 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nSolution: \nEntity-Relationship Diagram \n \n \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":22}}}],["1b3c0969-c1cc-4350-a358-a1cc6eabab50",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 23 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nStep 1: Create Database \n \nCREATE database movies; \nuse movies; \nStep 2: Create Tables \nCREATE TABLE ACTOR ( \nACT_ID int(3), \nACT_NAME VARCHAR(20), \nACT_GENDER CHAR(1), \nPRIMARY KEY (ACT_ID)); \n \nCREATE TABLE DIRECTOR ( \nDIR_ID int(3), \nDIR_NAME VARCHAR (20), \nDIR_PHONE bigint(10), \nPRIMARY KEY (DIR_ID)); \n \nCREATE TABLE MOVIES ( \nMOV_ID int(4), \nMOV_TITLE VARCHAR (25), \nMOV_YEAR int(4), \nMOV_LANG VARCHAR (12), \nDIR_ID int(3), \nPRIMARY KEY (MOV_ID), \nFOREIGN KEY (DIR_ID) REFERENCES DIRECTOR (DIR_ID)); \n \nCREATE TABLE MOVIE_CAST ( \nACT_ID int(3), \nMOV_ID int(4), \nROLE VARCHAR (10), \nPRIMARY KEY (ACT_ID, MOV_ID), ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":23}}}],["1391ce11-081a-4b54-864e-4eb100c9c4fa",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 24 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nFOREIGN KEY (ACT_ID) REFERENCES ACTOR (ACT_ID), \nFOREIGN KEY (MOV_ID) REFERENCES MOVIES (MOV_ID)); \n \nCREATE TABLE RATING ( \nMOV_ID int(4), \nREV_STARS VARCHAR (25), \nPRIMARY KEY (MOV_ID), \nFOREIGN KEY (MOV_ID) REFERENCES MOVIES (MOV_ID)); \n \nStep 3: Insert Values into Tables \nINSERT INTO ACTOR VALUES (301,'ANUSHKA','F'); \nINSERT INTO ACTOR VALUES (302,'PRABHAS','M'); \nINSERT INTO ACTOR VALUES (303,'James','M'); \nINSERT INTO ACTOR VALUES (304,'JERMY','M'); \nINSERT INTO ACTOR VALUES (305,'Punith','M'); \n \nINSERT INTO DIRECTOR VALUES (60,'RAJAMOULI', 8751611001); \nINSERT INTO DIRECTOR VALUES (61,'HITCHCOCK', 7766138911); \nINSERT INTO DIRECTOR VALUES (62,'FARAN', 9986776531); \nINSERT INTO DIRECTOR VALUES (63,'STEVEN SPIELBERG', 8989776530); \n \nINSERT INTO MOVIES VALUES (1001,'BAHUBALI-2', 2017, 'TELUGU', 60); \nINSERT INTO MOVIES VALUES (1002,'BAHUBALI-1', 2015, 'TELUGU', 60); \nINSERT INTO MOVIES VALUES (1003,'Vertigo', 1958, 'ENGLISH', 61); \nINSERT INTO MOVIES VALUES (1005,'The Birds', 1963, 'ENGLISH', 61); \nINSERT INTO MOVIES VALUES (1004,'WAR HORSE', 2011, 'ENGLISH', 63); \n \nINSERT INTO MOVIE_CAST VALUES (301, 1002, 'HEROINE'); ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":24}}}],["09bf870b-c5dc-4e24-8018-02d5662e0a0e",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 25 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nINSERT INTO MOVIE_CAST VALUES (301, 1001, 'HEROINE'); \nINSERT INTO MOVIE_CAST VALUES (303, 1003, 'HERO'); \nINSERT INTO MOVIE_CAST VALUES (303, 1002, 'GUEST'); \nINSERT INTO MOVIE_CAST VALUES (304, 1004, 'HERO'); \n \nINSERT INTO RATING VALUES (1001, 4); \nINSERT INTO RATING VALUES (1002, 2); \nINSERT INTO RATING VALUES (1003, 5); \nINSERT INTO RATING VALUES (1004, 4); \nINSERT INTO RATING VALUES (1005, 3); \n \nStep 4: Display table contents \nSELECT * FROM ACTOR; \n \n \n \nSELECT * FROM DIRECTOR; \n \n \nSELECT * FROM MOVIES; \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":25}}}],["be815c90-43e1-4144-a1ad-61d3ab96ec66",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 26 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nSELECT * FROM MOVIE_CAST; \n \n \nSELECT * FROM RATING; \n \n \nStep 5: Execute Queries: \n-- Queries: \n-- 1. List the titles of all movies directed by‘Hitchcock’. \nSELECT MOV_TITLE FROM MOVIES WHERE DIR_ID IN (SELECT DIR_ID \nFROM DIRECTOR WHERE DIR_NAME = 'HITCHCOCK'); \nOutput: \n \n/* 2. Find the movie names where one or more actors acted in two or \nmoremovies.*/ \nSELECT MOV_TITLE FROM MOVIES M, MOVIE_CAST MV \nWHERE M.MOV_ID=MV.MOV_ID AND ACT_ID IN (SELECT ACT_ID \nFROM MOVIE_CAST GROUP BY ACT_ID HAVING COUNT(ACT_ID)>1) \nGROUP BY MOV_TITLE HAVING COUNT(*)>1; \nOutput: \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":26}}}],["5f5dd6bf-9b8b-459c-9e9f-3e0c8eeaf4f3",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 27 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n/* 3. List all actors who acted in a movie before 2000 and also in a \nmovie after 2015 (use JOIN operation). */ \n-- Method 1 \nSELECT ACT_NAME, MOV_TITLE, MOV_YEAR FROM ACTOR A JOIN MOVIE_CAST C ON \nA.ACT_ID=C.ACT_ID JOIN MOVIES M ON C.MOV_ID=M.MOV_ID \nWHERE M.MOV_YEAR NOT BETWEEN 2000 AND 2015;  \n \n-- Method 2 \nSELECT A.ACT_NAME, A.ACT_NAME, C.MOV_TITLE, C.MOV_YEAR \nFROM ACTOR A, MOVIE_CAST B, MOVIES C WHERE A.ACT_ID=B.ACT_ID \nAND B.MOV_ID=C.MOV_ID AND C.MOV_YEAR NOT BETWEEN 2000 AND 2015; \nOutput: \n \n/* 4. Find the title of movies and number of stars for each movie that \nhas at least one rating and find the highest number of stars that movie \nreceived. Sort the result by movie title. */ \nSELECT MOV_TITLE, MAX(REV_STARS) FROM MOVIES INNER JOIN RATING USING \n(MOV_ID) GROUP BY MOV_TITLE HAVING MAX(REV_STARS)>0 ORDER BY MOV_TITLE; \nOutput: \n \n-- 5. Update rating of all movies directed by ‘Steven Spielberg’ to 5 \nUPDATE RATING SET REV_STARS=5 WHERE MOV_ID IN (SELECT MOV_ID FROM MOVIES \nWHERE DIR_ID IN (SELECT DIR_ID FROM DIRECTOR WHERE DIR_NAME = 'STEVEN \nSPIELBERG')); \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":27}}}],["36942869-27cc-4a5e-9ae6-eb0082cc036e",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 28 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nOutput: \nselect * from DIRECTOR; \n \n \n \nselect * from MOVIES; \n \n \nselect * from RATING; \n \n************* \n \n \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":28}}}],["604b7d08-64bb-4bb4-9efe-436ab3e50134",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 29 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \n4. Consider the schema for College Database: \n \nSTUDENT (USN, SName, Address, Phone, Gender) \nSEMSEC (SSID, Sem, Sec) \nCLASS (USN, SSID) \nSUBJECT (Subcode, Title, Sem, Credits) \nIAMARKS (USN, Subcode, SSID, Test1, Test2, Test3, FinalIA)  \nWrite SQL queries to \na. List all the student details studying in fourth semester „C‟ section. \nb. Compute the total number of male and female students in each semester and in each \nsection. \nc. Create a view of Test1 marks of student USN „1BI15CS101‟ in all subjects. \nd. Calculate the FinalIA (average of best two test marks) and update the \ncorresponding table for all students. \ne. Categorize students based on the following criterion: If \nFinalIA = 17 to 20 then CAT =„Outstanding‟ \nIf FinalIA = 12 to 16 then CAT = „Average‟ If \nFinalIA< 12 then CAT = „Weak‟ \nGive these details only for 8th semester A, B, and C section students. \nSolution: \n \nEntity - Relationship Diagram ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":29}}}],["e52f981e-63ab-4df6-a42a-b37795aa1ff4",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 30 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nSchema Diagram \n \n \n \nStep 1: Create Database \ncreate database collegedb; \nuse collegedb; \nStep 2: Create Tables \nCREATE TABLE STUDENT( \nUSN VARCHAR(10) PRIMARY KEY, \nSNAME VARCHAR(25), \nADDRESS VARCHAR(25), \nPHONE INTEGER, \nGENDER CHAR(1)); \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":30}}}],["5c7c183c-222b-43d1-879f-3bd91dac5c70",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 31 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nDESC STUDENT; \n----------------------------------- \nCREATE TABLE SEMSEC( \nSSID VARCHAR(5) PRIMARY KEY, \nSEM INTEGER, \nSEC CHAR(1)); \n \nDESC SEMSEC; \n \n----------------------------------- \nCREATE TABLE CLASS( \nUSN VARCHAR(10) PRIMARY KEY, \nSSID VARCHAR(5), \nFOREIGN KEY(USN) REFERENCES STUDENT(USN), \nFOREIGN KEY(SSID) REFERENCES SEMSEC(SSID)); \n \nDESC CLASS; \n------------------------------------ \nCREATE TABLE SUBJECT( \nSUBCODE VARCHAR(8) PRIMARY KEY, \nTITLE VARCHAR(20), \nSEM INTEGER, \nCREDITS INTEGER); \n \nDESC SUBJECT; \n-------------------------------------- \nCREATE TABLE IAMARKS( \nUSN VARCHAR(10), \nSUBCODE VARCHAR(8), \nSSID VARCHAR(5), \nTEST1 INTEGER, \nTEST2 INTEGER, \nTEST3 INTEGER, ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":31}}}],["481a314d-81cf-4fe3-8177-64b8d8201d5e",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 32 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nFINALIA INTEGER, \nPRIMARY KEY(SUBCODE,USN,SSID), \nFOREIGN KEY(USN) REFERENCES STUDENT(USN), \nFOREIGN KEY(SUBCODE) REFERENCES SUBJECT(SUBCODE), \nFOREIGN KEY(SSID) REFERENCES SEMSEC(SSID)); \n \nDESC IAMARKS; \nStep 3: Insert Values into Tables \nINSERT INTO STUDENT VALUES ('1DT13CS020','ANAND','BELAGAVI', \n1233423,'M'); \nINSERT INTO STUDENT VALUES \n('1DT13CS062','BABIITHA','BENGALURU',43123,'F'); \nINSERT INTO STUDENT VALUES ('1DT15CS101','CHETHAN','BENGALURU', \n534234,'M'); \nINSERT INTO STUDENT VALUES \n('1DT13CS066','DIVYA','MANGALURU',534432,'F'); \nINSERT INTO STUDENT VALUES ('1DT14CS010','EESHA','BENGALURU', \n345456,'F'); \nINSERT INTO STUDENT VALUES \n('1DT14CS032','GANESH','BENGALURU',574532,'M'); \nINSERT INTO STUDENT VALUES ('1DT14CS025','HARISH','BENGALURU', \n235464,'M'); \nINSERT INTO STUDENT VALUES ('1DT15CS011','ISHA','TUMKUR', \n764343,'F'); \nINSERT INTO STUDENT VALUES ('1DT15CS029','JOEY','DAVANGERE', \n235653,'M'); \nINSERT INTO STUDENT VALUES ('1DT15CS045','KAVYA','BELLARY', \n865434,'F'); \nINSERT INTO STUDENT VALUES \n('1DT15CS091','MALINI','MANGALURU',235464,'F'); \nINSERT INTO STUDENT VALUES ('1DT16CS045','NEEL','KALBURGI', \n856453,'M'); ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":32}}}],["66ef53ea-ea78-499f-8b76-ed495a9c879e",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 33 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nINSERT INTO STUDENT VALUES ('1DT16CS088','PARTHA','SHIMOGA', \n234546,'M'); \nINSERT INTO STUDENT VALUES ('1DT16CS122','REEMA','CHIKAMAGALUR', \n853333,'F'); \n------------------------------------ \nINSERT INTO SEMSEC VALUES ('CSE8A', 8,'A'); \nINSERT INTO SEMSEC VALUES ('CSE8B', 8,'B'); \nINSERT INTO SEMSEC VALUES ('CSE8C', 8,'C'); \nINSERT INTO SEMSEC VALUES ('CSE7A', 7,'A'); \nINSERT INTO SEMSEC VALUES ('CSE7B', 7,'B'); \nINSERT INTO SEMSEC VALUES ('CSE7C', 7,'C'); \nINSERT INTO SEMSEC VALUES ('CSE6A', 6,'A'); \nINSERT INTO SEMSEC VALUES ('CSE6B', 6,'B'); \nINSERT INTO SEMSEC VALUES ('CSE6C', 6,'C'); \nINSERT INTO SEMSEC VALUES ('CSE5A', 5,'A'); \nINSERT INTO SEMSEC VALUES ('CSE5B', 5,'B'); \nINSERT INTO SEMSEC VALUES ('CSE5C', 5,'C'); \nINSERT INTO SEMSEC VALUES ('CSE4A', 4,'A'); \nINSERT INTO SEMSEC VALUES ('CSE4B', 4,'B'); \nINSERT INTO SEMSEC VALUES ('CSE4C', 4,'C'); \nINSERT INTO SEMSEC VALUES ('CSE3A', 3,'A'); \nINSERT INTO SEMSEC VALUES ('CSE3B', 3,'B'); \nINSERT INTO SEMSEC VALUES ('CSE3C', 3,'C'); \nINSERT INTO SEMSEC VALUES ('CSE2A', 2,'A'); \nINSERT INTO SEMSEC VALUES ('CSE2B', 2,'B'); \nINSERT INTO SEMSEC VALUES ('CSE2C', 2,'C'); \nINSERT INTO SEMSEC VALUES ('CSE1A', 1,'A'); \nINSERT INTO SEMSEC VALUES ('CSE1B', 1,'B'); \nINSERT INTO SEMSEC VALUES ('CSE1C', 1,'C'); \n--------------------------------------- \nINSERT INTO CLASS VALUES ('1DT13CS020','CSE8A'); \nINSERT INTO CLASS VALUES ('1DT13CS062','CSE8A'); \nINSERT INTO CLASS VALUES ('1DT13CS066','CSE8B'); ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":33}}}],["12a89b0a-0ee4-45fc-aab5-d3d8c1cdec03",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 34 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nINSERT INTO CLASS VALUES ('1DT15CS101','CSE8C'); \nINSERT INTO CLASS VALUES ('1DT14CS010','CSE7A'); \nINSERT INTO CLASS VALUES ('1DT14CS025','CSE7A'); \nINSERT INTO CLASS VALUES ('1DT14CS032','CSE7A'); \nINSERT INTO CLASS VALUES ('1DT15CS011','CSE4A'); \nINSERT INTO CLASS VALUES ('1DT15CS029','CSE4A'); \nINSERT INTO CLASS VALUES ('1DT15CS045','CSE4B'); \nINSERT INTO CLASS VALUES ('1DT15CS091','CSE4C'); \nINSERT INTO CLASS VALUES ('1DT16CS045','CSE3A'); \nINSERT INTO CLASS VALUES ('1DT16CS088','CSE3B'); \nINSERT INTO CLASS VALUES ('1DT16CS122','CSE3C'); \n------------------------------------- \nINSERT INTO SUBJECT VALUES ('10CS81','ACA', 8, 4); \nINSERT INTO SUBJECT VALUES ('10CS82','SSM', 8, 4); \nINSERT INTO SUBJECT VALUES ('10CS83','NM', 8, 4); \nINSERT INTO SUBJECT VALUES ('10CS84','CC', 8, 4); \nINSERT INTO SUBJECT VALUES ('10CS85','PW', 8, 4); \nINSERT INTO SUBJECT VALUES ('10CS71','OOAD', 7, 4); \nINSERT INTO SUBJECT VALUES ('10CS72','ECS', 7, 4); \nINSERT INTO SUBJECT VALUES ('10CS73','PTW', 7, 4); \nINSERT INTO SUBJECT VALUES ('10CS74','DWDM', 7, 4); \nINSERT INTO SUBJECT VALUES ('10CS75','JAVA', 7, 4); \nINSERT INTO SUBJECT VALUES ('10CS76','SAN', 7, 4); \nINSERT INTO SUBJECT VALUES ('15CS51','ME', 5, 4); \nINSERT INTO SUBJECT VALUES ('15CS52','CN', 5, 4); \nINSERT INTO SUBJECT VALUES ('15CS53','DBMS', 5, 4); \nINSERT INTO SUBJECT VALUES ('15CS54','ATC', 5, 4); \nINSERT INTO SUBJECT VALUES ('15CS55','JAVA', 5, 3); \nINSERT INTO SUBJECT VALUES ('15CS56','AI', 5, 3); \nINSERT INTO SUBJECT VALUES ('15CS41','M4', 4, 4); \nINSERT INTO SUBJECT VALUES ('15CS42','SE', 4, 4); \nINSERT INTO SUBJECT VALUES ('15CS43','DAA', 4, 4); \nINSERT INTO SUBJECT VALUES ('15CS44','MPMC', 4, 4); ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":34}}}],["f8def497-84c3-412a-8300-cf9f04d4a4d9",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 35 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nINSERT INTO SUBJECT VALUES ('15CS45','OOC', 4, 3); \nINSERT INTO SUBJECT VALUES ('15CS46','DC', 4, 3); \nINSERT INTO SUBJECT VALUES ('15CS31','M3', 3, 4); \nINSERT INTO SUBJECT VALUES ('15CS32','ADE', 3, 4); \nINSERT INTO SUBJECT VALUES ('15CS33','DSA', 3, 4); \nINSERT INTO SUBJECT VALUES ('15CS34','CO', 3, 4); \nINSERT INTO SUBJECT VALUES ('15CS35','USP', 3, 3); \nINSERT INTO SUBJECT VALUES ('15CS36','DMS', 3, 3); \n---------------------------------------- \nINSERT INTO IAMARKS (USN, SUBCODE, SSID, TEST1, TEST2, TEST3) VALUES \n('1DT15CS101','10CS81','CSE8C', 15, 16, 18); \nINSERT INTO IAMARKS (USN, SUBCODE, SSID, TEST1, TEST2, TEST3) VALUES \n('1DT15CS101','10CS82','CSE8C', 12, 19, 14); \nINSERT INTO IAMARKS (USN, SUBCODE, SSID, TEST1, TEST2, TEST3) VALUES \n('1DT15CS101','10CS83','CSE8C', 19, 15, 20); \nINSERT INTO IAMARKS (USN, SUBCODE, SSID, TEST1, TEST2, TEST3) VALUES \n('1DT15CS101','10CS84','CSE8C', 20, 16, 19); \nINSERT INTO IAMARKS (USN, SUBCODE, SSID, TEST1, TEST2, TEST3) VALUES \n('1DT15CS101','10CS85','CSE8C', 15, 15, 12); \n \nStep 4: Display table contents \nSELECT * FROM STUDENT; \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":35}}}],["e86ddf1f-73a2-4835-9b50-bd9a7ba70e0b",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 36 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nSELECT * FROM SEMSEC; \n \n \nSELECT * FROM CLASS; \n \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":36}}}],["ee15deb9-f0dc-491c-9996-c81ca7c31139",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 37 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nSELECT * FROM SUBJECT; \n \n \nSELECT * FROM IAMARKS; \n \n \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":37}}}],["e9e6a75f-9607-4282-a152-18257547c2e2",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 38 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nStep 5: Execute Queries: \n \n/* 1. List all the student details studying in fourth semester ‘C’ \nsection. */ \nSELECT S.*, SS.SEM, SS.SEC FROM STUDENT S, SEMSEC SS, CLASS C \nWHERE S.USN = C.USN AND SS.SSID = C.SSID AND SS.SEM = 4 AND \nSS.Sec='C'; \nOutput: \n \n \n \n/* 2. Compute the total number of male and female students in each \nsemester and in each section.*/ \nSELECT SS.SEM, SS.SEC, S.GENDER, COUNT(S.GENDER) AS COUNT \nFROM STUDENT S, SEMSEC SS, CLASS C \nWHERE S.USN = C.USN AND SS.SSID = C.SSID \nGROUP BY SS.SEM, SS.SEC, S.GENDER ORDER BY SEM; \nOutput: \n \n \n \n/* 3. Create a view of Test1 marks of student USN ‘1BI15CS101’ in \nall subjects.*/ \nCREATE VIEW STU_TEST1_MARKS_VIEW AS ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":38}}}],["2033d5d6-e8c1-4337-b389-6e2a4a2680dc",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 39 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nSELECT TEST1, SUBCODE FROM IAMARKS WHERE USN = '1DT13CS091'; \n \nselect * from STU_TEST1_MARKS_VIEW; \nOutput: \n \n \n \n/* 4. Calculate the FinalIA (average of best two test marks) and \nupdate the corresponding table for all students.*/ \n \nDELIMITER // \nCREATE PROCEDURE AVG_MARKS() \nBEGIN \nDECLARE C_A INTEGER; \nDECLARE C_B INTEGER; \nDECLARE C_C INTEGER; \nDECLARE C_SUM INTEGER; \nDECLARE C_AVG INTEGER; \nDECLARE C_USN VARCHAR(10); \nDECLARE C_SUBCODE VARCHAR(8); \nDECLARE C_SSID VARCHAR(5); \n \nDECLARE C_IAMARKS CURSOR FOR \nSELECT GREATEST(TEST1,TEST2) AS A, GREATEST(TEST1,TEST3) AS B, \nGREATEST(TEST3,TEST2) AS C, USN, SUBCODE, SSID \nFROM IAMARKS \nWHERE FINALIA IS NULL \nFOR UPDATE; \n \nOPEN C_IAMARKS; \nLOOP \n \nFETCH C_IAMARKS INTO C_A, C_B, C_C, C_USN, C_SUBCODE, C_SSID; \n \nIF (C_A != C_B) THEN \n SET C_SUM=C_A+C_B; \nELSE ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":39}}}],["47c92000-3cde-444c-a29e-b395de4af6a4",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 40 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n SET C_SUM=C_A+C_C; \nEND IF; \n \nSET C_AVG=C_SUM/2; \n \nUPDATE IAMARKS SET FINALIA = C_AVG  \nWHERE USN = C_USN AND SUBCODE = C_SUBCODE AND SSID = C_SSID; \n \nEND LOOP; \nCLOSE C_IAMARKS; \nEND; \n// \n \nCALL AVG_MARKS(); \n \nSELECT * FROM IAMARKS; \nOutput: \n \n \n \n \n/* 5. Categorize students based on the following criterion: \nIf FinalIA = 17 to 20 then CAT = ‘Outstanding’ \nIf FinalIA = 12 to 16 then CAT = ‘Average’ \nIf FinalIA< 12 then CAT = ‘Weak’ \nGive these details only for 8th semester A, B, and C section \nstudents. */ \nSELECT S.USN,S.SNAME,S.ADDRESS,S.PHONE,S.GENDER, IA.SUBCODE, \n(CASE \nWHEN IA.FINALIA BETWEEN 17 AND 20 THEN 'OUTSTANDING' \nWHEN IA.FINALIA BETWEEN 12 AND 16 THEN 'AVERAGE' \nELSE 'WEAK' \nEND) AS CAT \nFROM STUDENT S, SEMSEC SS, IAMARKS IA, SUBJECT SUB ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":40}}}],["00f46af9-1418-4227-8332-88438f68f280",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 41 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nWHERE S.USN = IA.USN AND \nSS.SSID = IA.SSID AND \nSUB.SUBCODE = IA.SUBCODE AND \nSUB.SEM = 8; \nOutput: \n \n \n************* \n \n5. Consider the schema for Company Database: \n \nEMPLOYEE (SSN, Name, Address, Sex, Salary, SuperSSN, DNo) \nDEPARTMENT (DNo, DName, MgrSSN, MgrStartDate) \nDLOCATION (DNo,DLoc) \nPROJECT (PNo, PName, PLocation, DNo) \nWORKS_ON (SSN, PNo, Hours) \n \nWrite SQL queries to \na. Make a list of all project numbers for projects that involve an employee whose last name \nis „Scott‟, either as a worker or as a manager of the department that controls the project. \nb. Show the resulting salaries if every employee working on the „IoT‟ project is given a 10 \npercent raise. \nc. Find the sum of the salaries of all employees of the „Accounts‟ department, as well as the \nmaximum salary, the minimum salary, and the average salary in this department \nd. Retrieve  the  name  of  each  employee  who  works  on  all  the  projects  controlled  by \ndepartment  number  5  (use  NOT  EXISTS  operator).  For  each  department  that  has  more \nthan  five  employees,  retrieve  the  department  number  and  the  number  of  its  employees \nwho are making more than Rs.6,00,000. \n \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":41}}}],["1f24ae55-741e-42b2-a5b1-4279309563e3",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 42 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nEntity-Relationship Diagram \n \n \n \n \n \n \n Schema Diagram \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":42}}}],["537ffa1a-3b39-47ca-a4e9-d0b4cf40a04c",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 43 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nStep 1: Create Database \nCREATE DATABASE COMPANY; \nUSE COMPANY; \n \nStep 2: Create Tables \nCREATE TABLE DEPARTMENT \n(DNO VARCHAR(20) PRIMARY KEY, \nDNAME VARCHAR(20), \nMGR_SSN VARCHAR(20), \nMGR_START_DATE DATE); \n \nDESC DEPARTMENT; \n-- -------------------------------- \nCREATE TABLE EMPLOYEE \n(SSN VARCHAR(20) PRIMARY KEY, \nNAME VARCHAR(20), \nADDRESS VARCHAR(20), \nSEX CHAR(1), \nSALARY INTEGER, \nSUPERSSN VARCHAR(20), \nDNO VARCHAR(20), \nFOREIGN KEY (SUPERSSN) REFERENCES EMPLOYEE (SSN), \nFOREIGN KEY (DNO) REFERENCES DEPARTMENT (DNO)); \n \nDESC EMPLOYEE; \n-- -------------------------------- \n-- ADD FOREIGN KEY Constraint to DEPARTMENT table \n \nALTER TABLE DEPARTMENT \nADD FOREIGN KEY (MGR_SSN) REFERENCES EMPLOYEE(SSN); \n-- -------------------------------- ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":43}}}],["f86596fd-fbd9-42a2-b7a0-883f64c6ef57",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 44 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nCREATE TABLE DLOCATION \n(DLOC VARCHAR(20), \nDNO VARCHAR(20), \nFOREIGN KEY (DNO) REFERENCES DEPARTMENT(DNO), \nPRIMARY KEY (DNO, DLOC)); \n \nDESC DLOCATION; \n-- -------------------------------- \nCREATE TABLE PROJECT \n(PNO INTEGER PRIMARY KEY, \nPNAME VARCHAR(20), \nPLOCATION VARCHAR(20), \nDNO VARCHAR(20), \nFOREIGN KEY (DNO) REFERENCES DEPARTMENT(DNO)); \n \nDESC PROJECT; \n-- -------------------------------- \nCREATE TABLE WORKS_ON \n(HOURS INTEGER, \nSSN VARCHAR(20), \nPNO INTEGER, \nFOREIGN KEY (SSN) REFERENCES EMPLOYEE(SSN), \nFOREIGN KEY (PNO) REFERENCES PROJECT(PNO), \nPRIMARY KEY (SSN, PNO)); \n \nDESC WORKS_ON; \n-- -------------------------------- \nStep 3: Insert Values into Tables \nINSERT INTO EMPLOYEE (SSN, NAME, ADDRESS, SEX, SALARY) VALUES \n ('ABC01','BEN SCOTT','BANGALORE','M', 450000); \nINSERT INTO EMPLOYEE (SSN, NAME, ADDRESS, SEX, SALARY) VALUES \n ('ABC02','HARRY SMITH','BANGALORE','M', 500000); ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":44}}}],["0228ab15-b393-495e-a08a-342a0fb8db02",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 45 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nINSERT INTO EMPLOYEE (SSN, NAME, ADDRESS, SEX, SALARY) VALUES \n ('ABC03','LEAN BAKER','BANGALORE','M', 700000); \nINSERT INTO EMPLOYEE (SSN, NAME, ADDRESS, SEX, SALARY) VALUES \n ('ABC04','MARTIN SCOTT','MYSORE','M', 500000); \nINSERT INTO EMPLOYEE (SSN, NAME, ADDRESS, SEX, SALARY) VALUES \n ('ABC05','RAVAN HEGDE','MANGALORE','M', 650000); \nINSERT INTO EMPLOYEE (SSN, NAME, ADDRESS, SEX, SALARY) VALUES \n ('ABC06','GIRISH HOSUR','MYSORE','M', 450000); \nINSERT INTO EMPLOYEE (SSN, NAME, ADDRESS, SEX, SALARY) VALUES \n ('ABC07','NEELA SHARMA','BANGALORE','F', 800000); \nINSERT INTO EMPLOYEE (SSN, NAME, ADDRESS, SEX, SALARY) VALUES \n ('ABC08','ADYA KOLAR','MANGALORE','F', 350000); \nINSERT INTO EMPLOYEE (SSN, NAME, ADDRESS, SEX, SALARY) VALUES \n ('ABC09','PRASANNA KUMAR','MANGALORE','M', 300000); \nINSERT INTO EMPLOYEE (SSN, NAME, ADDRESS, SEX, SALARY) VALUES \n ('ABC10','VEENA KUMARI','MYSORE','M', 600000); \nINSERT INTO EMPLOYEE (SSN, NAME, ADDRESS, SEX, SALARY) VALUES \n ('ABC11','DEEPAK RAJ','BANGALORE','M', 500000); \n \n INSERT INTO DEPARTMENT VALUES ('1','ACCOUNTS','ABC09', '2016-01-03'); \nINSERT INTO DEPARTMENT VALUES ('2','IT','ABC11', '2017-02-04'); \nINSERT INTO DEPARTMENT VALUES ('3','HR','ABC01', '2016-04-05'); \nINSERT INTO DEPARTMENT VALUES ('4','HELPDESK', 'ABC10', '2017-06-03'); \nINSERT INTO DEPARTMENT VALUES ('5','SALES','ABC06', '2017-01-08'); \n---------------------------------- \n-- Updating EMPLOYEE records \n \nUPDATE EMPLOYEE SET  \nSUPERSSN=NULL, DNO='3' \nWHERE SSN='ABC01'; \n \nUPDATE EMPLOYEE SET ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":45}}}],["59ae28d3-7794-473d-81a1-397df354e0fe",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 46 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nSUPERSSN='ABC03', DNO='5' \nWHERE SSN='ABC02'; \n \nUPDATE EMPLOYEE SET \nSUPERSSN='ABC04', DNO='5' \nWHERE SSN='ABC03'; \n \nUPDATE EMPLOYEE SET \nSUPERSSN='ABC06', DNO='5' \nWHERE SSN='ABC04'; \n \nUPDATE EMPLOYEE SET \nDNO='5', SUPERSSN='ABC06' \nWHERE SSN='ABC05'; \n \nUPDATE EMPLOYEE SET \nDNO='5', SUPERSSN='ABC07' \nWHERE SSN='ABC06'; \n \nUPDATE EMPLOYEE SET \nDNO='5', SUPERSSN=NULL \nWHERE SSN='ABC07'; \n \nUPDATE EMPLOYEE SET \nDNO='1', SUPERSSN='ABC09' \nWHERE SSN='ABC08'; \n \nUPDATE EMPLOYEE SET \nDNO='1', SUPERSSN=NULL \nWHERE SSN='ABC09'; \n \nUPDATE EMPLOYEE SET ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":46}}}],["55db301d-bf7a-47b0-bffd-a5d844c03a3a",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 47 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nDNO='4', SUPERSSN=NULL \nWHERE SSN='ABC10'; \n \nUPDATE EMPLOYEE SET \nDNO='2', SUPERSSN=NULL \nWHERE SSN='ABC11'; \n \nSELECT * FROM EMPLOYEE; \n------------------------------- \n-- Inserting records into DLOCATION table \n \nINSERT INTO DLOCATION VALUES ('BENGALURU', '1'); \nINSERT INTO DLOCATION VALUES ('BENGALURU', '2'); \nINSERT INTO DLOCATION VALUES ('BENGALURU', '3'); \nINSERT INTO DLOCATION VALUES ('MYSORE', '4'); \nINSERT INTO DLOCATION VALUES ('MYSORE', '5'); \n \nSELECT * FROM DLOCATION; \n-------------------------------- \n-- Inserting records into PROJECT table \nINSERT INTO PROJECT VALUES (1000,'IOT','BENGALURU','5'); \nINSERT INTO PROJECT VALUES (1001,'CLOUD','BENGALURU','5'); \nINSERT INTO PROJECT VALUES (1002,'BIGDATA','BENGALURU','5'); \nINSERT INTO PROJECT VALUES (1003,'SENSORS','BENGALURU','3'); \nINSERT INTO PROJECT VALUES (1004,'BANK MANAGEMENT','BENGALURU','1'); \nINSERT INTO PROJECT VALUES (1005,'SALARY MANAGEMENT','BANGALORE','1'); \nINSERT INTO PROJECT VALUES (1006,'OPENSTACK','BENGALURU','4'); \nINSERT INTO PROJECT VALUES (1007,'SMART CITY','BENGALURU','2'); \n------------------------------ \nINSERT INTO WORKS_ON VALUES (4, 'ABC02', 1000); \nINSERT INTO WORKS_ON VALUES (6, 'ABC02', 1001); \nINSERT INTO WORKS_ON VALUES (8, 'ABC02', 1002); ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":47}}}],["b9e71c66-f5fa-4227-b2cd-84b1b31de064",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 48 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nINSERT INTO WORKS_ON VALUES (10,'ABC03', 1000); \nINSERT INTO WORKS_ON VALUES (3, 'ABC05', 1000); \nINSERT INTO WORKS_ON VALUES (4, 'ABC06', 1001); \nINSERT INTO WORKS_ON VALUES (5, 'ABC07', 1002); \nINSERT INTO WORKS_ON VALUES (6, 'ABC04', 1002); \nINSERT INTO WORKS_ON VALUES (7, 'ABC01', 1003); \nINSERT INTO WORKS_ON VALUES (5, 'ABC08', 1004); \nINSERT INTO WORKS_ON VALUES (6, 'ABC09', 1005); \nINSERT INTO WORKS_ON VALUES (4, 'ABC10', 1006); \nINSERT INTO WORKS_ON VALUES (10,'ABC11', 1007); \n \nStep 4: Display table contents \nSELECT * FROM EMPLOYEE; \n \n \nSELECT * FROM DEPARTMENT; \n \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":48}}}],["9471b72f-9945-4363-9b2e-119fc8758cae",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 49 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nSELECT * FROM DLOCATION; \n \n \nSELECT * FROM PROJECT; \n \n \nSELECT * FROM WORKS_ON; \n \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":49}}}],["08056deb-b8b0-4866-9aaa-3b71d28cde47",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 50 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nStep 5: Execute Queries: \n/* 1. Make a list of all project numbers for projects that involve an employee whose last name is \n‘Scott’, either as a worker or as a manager of the department that controls the project. */ \n \nSELECT DISTINCT P.PNO FROM PROJECT P, DEPARTMENT D, EMPLOYEE E \nWHERE E.DNO=D.DNO AND D.MGR_SSN=E.SSN AND E.NAME LIKE '%SCOTT' \nUNION \nSELECT DISTINCT P1.PNO FROM PROJECT P1, WORKS_ON W, EMPLOYEE E1 \nWHERE P1.PNO=W.PNO AND E1.SSN=W.SSN AND E1.NAME LIKE '%SCOTT'; \nOutput: \n \n/* 2. Show the resulting salaries if every employee working on the ‘IoT’ project is given a 10 \npercent raise. */ \n \nSELECT E.NAME, 1.1*E.SALARY AS INCR_SAL \nFROM EMPLOYEE E, WORKS_ON W, PROJECT P \nWHERE E.SSN=W.SSN AND W.PNO=P.PNO AND P.PNAME='IOT'; \nOutput: \n \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":50}}}],["7af5dfe1-32b1-4a1c-8d81-1cc82d32453e",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 51 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \n/* 3. Find the sum of the salaries of all employees of the ‘Accounts’ department, as well as the \nmaximum salary, the minimum salary, and the average salary in this department */ \n \nSELECT SUM(E.SALARY), MAX(E.SALARY), MIN(E.SALARY), AVG(E.SALARY) \nFROM EMPLOYEE E, DEPARTMENT D WHERE E.DNO=D.DNO \nAND D.DNAME='ACCOUNTS'; \nOutput: \n \n \n \n/* 4. Retrieve the name of each employee who works on all the projects controlled by \ndepartment number 5 (use NOT EXISTS operator). */ \nSELECT E.NAME FROM EMPLOYEE E \nWHERE NOT EXISTS(SELECT PNO FROM PROJECT WHERE DNO='5' AND PNO NOT IN \n(SELECT PNO FROM WORKS_ON WHERE E.SSN=SSN)); \nOutput: \n \n/* 5. For each department that has more than five employees, retrieve the department number \nand the number of its employees who are making more than Rs. 6,00,000. */ \n \nSELECT D.DNO, COUNT(*) FROM DEPARTMENT D, EMPLOYEE E \nWHERE D.DNO=E.DNO AND E.SALARY > 600000 AND D.DNO IN (SELECT E1.DNO \nFROM EMPLOYEE E1  GROUP BY E1.DNO HAVING COUNT(*)>5) \nGROUP BY D.DNO; \nOutput: \n \n********** \n \n \n ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":51}}}],["4c58cdf6-52fd-4e9a-a8cf-c60b2781b3de",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 52 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nViva Questions \n \n1. What is SQL? \nStructured Query Language \n2. What is database? \nA   database   is   a   logically   coherent   collection   of   data   with   some   inherent   meaning, \nrepresenting some aspect of real world and which is designed, built and populated with data \nfor a specific purpose. \n3. What is DBMS? \nIt is a collection of programs that enables user to create and maintain a database. In other \nwords  it  is  general-purpose  software  that  provides  the  users  with  the  processes  of  defining, \nconstructing and manipulating the database for various applications. \n4. What is a Database system? \nThe database and DBMS software together is called as Database system. \n5. Advantages of DBMS? \n Redundancy is controlled. \n Unauthorized access is restricted. \n Providing multiple user interfaces. \n Enforcing integrity constraints. \n Providing backup and recovery. \n6. Disadvantage in File Processing System? \n Data redundancy & inconsistency. \n Difficult in accessing data. \n Data isolation. \n Data integrity. \n Concurrent access is not possible. \n Security Problems. \n7. Describe the three levels of data abstraction? \nThere are three levels of abstraction: \n Physical level: The lowest level of abstraction describes how data are stored. \n Logical level: The next higher level of abstraction, describes what data are stored in \ndatabase and what relationship among those data. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":52}}}],["b79cd3e3-8404-4690-bcd7-a87a2292446c",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 53 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \n View level: The highest level of abstraction describes only part of entire database. \n8. Define the \"integrity rules\" \nThere are two Integrity rules. \n Entity Integrity: States that “Primary key cannot have NULL value” \n Referential Integrity: States that “Foreign Key can be either a NULL value \nor should be Primary Key value of other relation. \n9. What is extension and intension? \nExtension - It is the number of tuples present in a table at any instance. This is time \ndependent. \nIntension -It is a constant value that gives the name, structure of table and the constraints laid \non it. \n10. What is Data Independence? \nData independence means that “the application is independent of the storage structure and \naccess strategy of data”. In other words, The ability to modify the schema definition in one level \nshould not affect the schema definition in the next higher level. \nTwo types of Data Independence: \n Physical Data Independence: Modification in physical level should not affect the \nlogical level. \n Logical Data Independence: Modification in logical level should affect the view \nlevel. \nNOTE: Logical Data Independence is more difficult to achieve \n11. What is a view? How it is related to data independence? \nA view may be thought of as a virtual table, that is, a table that does not really exist in its \nown right but is instead derived from one or more underlying base table. In other words, there is \nno  stored  file  that  direct  represents  the  view  instead  a  definition  of  view  is  stored  in  data \ndictionary. \nGrowth  and  restructuring  of  base  tables  is  not  reflected  in  views.  Thus  the  view  can \ninsulate  users  from  the  effects  of  restructuring  and  growth  in  the  database.  Hence  accounts  for \nlogical data independence. \n12. What is Data Model? ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":53}}}],["89feabee-f7c0-4ecd-87a4-500cc84ab32b",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 54 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nA collection of conceptual tools for describing data, data relationships data semantics and \nconstraints. \n13. What is E-R model? \nThis data model is based on real world that consists of basic objects called entities and of \nrelationship among these objects. Entities are described in a database by a set of attributes. \n14. What is Object Oriented model? \nThis model is based on collection of objects. An object contains values stored in instance \nvariables  within  the  object.  An  object  also  contains  bodies  of  code  that  operate  on  the  object. \nThese bodies of code are called methods. Objects that contain same types of values and the same \nmethods are grouped together into classes. \n15. What is an Entity? \nIt is an 'object' in the real world with an independent existence. \n16. What is an Entity type? \nIt is a collection (set) of entities that have same attributes. \n17. What is an Entity set? \nIt is a collection of all entities of particular entity type in the database. \n18. What is an Extension of entity type? \nThe collections of entities of a particular entity type are grouped together  into an entity \nset. \n19. What is an attribute? \nIt is a particular property, which describes the entity. \n20. What is a Relation Schema and a Relation? \nA relation Schema denoted by R(A1, A2, ..., An) is made up of the relation name \nR and the list of attributes A\ni \nthat it contains. A relation is defined as a set of tuples. Let r \nbe the relation which contains set tuples (t1,t2,t3, ...,tn). Each tuple is an ordered list of n- \nvalues t=(v1,v2, ...,vn). \n21. What is degree of a Relation? \nIt is the number of attribute of its relation schema. \n22. What is Relationship? \nIt is an association among two or more entities. \n23. What is Relationship set? ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":54}}}],["3cc3c176-d67b-4b8c-9141-fee90c8be6d6",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 55 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n \nThe collection (or set) of similar relationships. \n24. What is Relationship type? \nRelationship type defines a set of associations or a relationship set among a given set of \nentity types. \n25. What is degree of Relationship type? \nIt is the number of entity type participating. \n26. What is DDL (Data Definition Language)? \nA data base schema is specified by a set of definitions expressed by a special language \ncalled DDL. \n27. What is VDL (View Definition Language)? \nIt specifies user views and their mappings to the conceptual schema. \n28. What is SDL (Storage Definition Language)? \nThis language is to specify the internal schema. This language may specify the mapping \nbetween two schemas. \n29. What is Data Storage – Definition Language? \nThe storage structures and access methods used by database systemare specified by \na set of definition in a special type of DDL called data storage- definition language. \n30. What is DML (Data Manipulation Language)? \nThis language that enable user to access or manipulate data as organized by \nappropriate data model. \n Procedural DML or Low level: DML requires a user to specify what data are needed \nand how to get those data. \n Non-Procedural DML or High level: DML requires a user to specify what data are \nneeded without specifying how to get those data. \n31. What is DML Compiler? \nIt translates DML statements in a query language into low-level instruction that \nthe query evaluation engine can understand. \n32. What is Relational Algebra? \nIt is a procedural query language. It consists of a set of operations that take one or \ntwo relations as input and produce a new relation. \n33. What is Relational Calculus? ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":55}}}],["6b7f737f-e1a2-461f-9c8a-5165c27ed1bc",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 56 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \nIt is an applied predicate calculus specifically tailored for relational databases proposed by E.F. \nCodd. E.g. of languages based on it are DSL, ALPHA,QUEL. \n34. What is normalization? \nIt is a process of analyzing the given relation schemas based on their Functional \nDependencies (FDs) and primary key to achieve the properties \n Minimizing redundancy \n Minimizing insertion, deletion and update anomalies. \n35. What is Functional Dependency? \nA Functional dependency is denoted by X Y between two sets of attributes X \nand Y that are subsets of R specifies a constraint on the possible tuple that can form a \nrelation state r of R. The constraint is for any two tuples t1 and t2 in r if t1[X] = t2[X] then \nthey have t1[Y] = t2[Y]. This means the value of X component of a tuple uniquely \ndetermines the value of component Y. \n36. When is a functional dependency F said to be minimal? \n Every dependency in F has a single attribute for its right hand side. \n We cannot replace any dependency X A in F with a dependency Y A where Y is a \n \nproper subset of X and still have a set of dependency that is equivalent to F. \n We cannot remove any dependency from F and still have set of dependency that is \nequivalent to F. \n37. What is Multivalued dependency? \nMultivalued  dependency  denoted  by  X  Y  specified  on  relation  schema  R,  where  X \nand  Y are  both  subsets  of  R,  specifies  the  following  constraint  on  any  relation  r  of  R:  if  two \ntuples  t1  and  t2  exist  in  r  such  that  t1[X]  =  t2[X]  then  t3  and  t4  should  also  exist  in  r  with  the \nfollowing properties \n t3[x] = t4[X] = t1[X] = t2[X] \n t3[Y] = t1[Y] and t4[Y] = t2[Y] \n t3[Z] = t2[Z] and t4[Z] = t1[Z] \nwhere [Z = (R-(X U Y)) ] \n38. What is Lossless join property? \nIt guarantees that the spurious tuple generation does not occur with respect to relation \nschemas after decomposition. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":56}}}],["a35f0444-f3dd-4895-9796-5892c344ea25",{"pageContent":"DBMS Lab Manual 21CSL55 \nPage 57 \nDept. of CSE, DSATM, Bangalore-82 2023-24 \n \n \n39. What is 1 NF (Normal Form)? \nThe domain of attribute must include only atomic (simple, indivisible) values. \n40. What is Fully Functional dependency? \nIt  is  based  on  concept  of  full  functional  dependency.  A  functional  dependency  X  Y  is \nfully  functional  dependency  if  removal  of  any  attribute  A  from X  means  that  the  dependency \ndoes not hold anymore. \n41. What is2NF? \nA relation schema R is in 2NF if it is in 1NF and every non-prime attribute A in R is fully \nfunctionally dependent on primary key. \n42. What is3NF? \nA  relation  schema  R  is  in  3NF  if  it is  in  2NF  and for  every  FD  X  A  either  of  the \nfollowing is true \n X is a Super-key of R. \n A is a prime attribute of R. \nIn other words, if every non prime attribute is non-transitively dependent on primary key. \n43. What is BCNF (Boyce-Codd Normal Form)? \nA relation schema R is in BCNF if it is in 3NF and satisfies additional constraints that for \nevery FD X A, X must be a candidate key. \n44. What is 4NF? \nA relation schema R is said to be in 4NF if for every Multivalued dependency X Y \nthat holds over R, one of following is true \n X is subset or equal to (or) XY =R. \n X is a super key. \n45. What is 5NF? \nA Relation schema R is said to be 5NF if for every join dependency {R1, R2, ...,Rn} that \nholds R, one the following is true \n Ri = R for some i. \n The join dependency is implied by the set of FD, over R in which the left side is key of R. \n46. What is Domain-Key Normal Form? \nA relation is said to be in DKNF if all constraints and dependencies that should hold on the \nconstraint can be enforced by simply enforcing the domain constraint  and key constraint on the \nrelation. ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\DBMS MANUAL-2023-24.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"DBMS Lab Manual-2017","Author":"Admin-CSE","Creator":"Microsoft® Word 2010","Producer":"Microsoft® Word 2010","CreationDate":"D:20240201154915+05'30'","ModDate":"D:20240201154915+05'30'"},"metadata":null,"totalPages":57},"loc":{"pageNumber":57}}}],["a203f961-d8e6-4352-bda6-8bcb457aaa04",{"pageContent":"1 \nDigital Image Processing                                                                                                          Module 1 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nModule 1 \nDIGITAL IMAGE PROCESSING \nPrepared By, \nSandesha Karanth P.K & Ragavendra Kattagal \nAssistant Professors, Dept. Of CSE, \nVCET, Puttur \n writetokaranth@gmail.com\n1\n, rkk4691@gmail.com\n2   \n    \n \n An imageis  defined  as  a  two  dimensional  function, f(x,y), where  x  and  y  are  spatial \n(plane) coordinates, and the amplitude of ‘f’ at any pair of coordinates (x,y) is called the intensity \nor gray level of the image at that point.  \n A digital  image is  a  2D  representation  of  a  scene  as a  finite  set  of  digital  values, \ncalledpicture elements or pixels or pels. \n \n The  field  of digital  image  processing refers  to  processing  digital  image  by  means  of  a \ndigital computer.  \nNOTE: A  digital  image  is  composed of  finite  number  of  elements  like  picture  elements,  image \nelements, pels, and pixels.  \n The digital image processing methods stems from 2 principal application areas: \n1. Improvement of pictorial information for human interpretation \n2. Processing  of  image  data  for  storage,  transmission  and  representation  for  autonomous \nmachine perception.  \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 1 [www.vtuloop.com] (1).pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Digital Image Processing                                                                                                          Module 1","Author":"Sandesh","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20180918114405+00'00'","ModDate":"D:20180918114405Z"},"metadata":null,"totalPages":14},"loc":{"pageNumber":1}}}],["0ef85e4e-f66e-481e-bd86-2c204f7ac060",{"pageContent":"2 \nDigital Image Processing                                                                                                          Module 1 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nFundamental Steps in Digital Image Processing **  \n \nFigure 1.1 Fundamental steps in digital image processing. \nImage acquisition: This is the first step in the digital image processing. An image is captured by \na  sensor  (such  as  digital  camera)  and  digitized.  The  image  that  is acquired  is completely \nunprocessed. This step involves preprocessing such as scaling.  \nImage  enhancement: It is  the  process  of  manipulating  an  image  in  order  to  make image  more \nsuitable than the original  for the specific application. The  image enhancement techniques are so \nverified, and use so many different image processing approaches. The idea behind enhancement \ntechniques  is to bring out detail that is  hidden, or simply to highlight certain  features of  interest \nin an image like changing brightness & contrast etc. \nImage restoration: It is an area that also deals with improving the appearance of an image but it \nis  objective  than  subjective,  in  the  sense  that  restoration  techniques  tend  to  be  based  on \nmathematical or probabilistic models of image degradation.  \nColor  image  processing: It  is  an  area  that  has  been  gaining  in  importance  because  of  the \nsignificant increase in the use of digital images over the internet. Color is used also for extracting \nfeatures  of  interest  in  an  image. This  may  include  color  modeling  and  processing  in  a  digital \ndomain etc.  \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 1 [www.vtuloop.com] (1).pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Digital Image Processing                                                                                                          Module 1","Author":"Sandesh","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20180918114405+00'00'","ModDate":"D:20180918114405Z"},"metadata":null,"totalPages":14},"loc":{"pageNumber":2}}}],["bd8781be-3cb4-4ce1-9cfb-12731f75d76e",{"pageContent":"3 \nDigital Image Processing                                                                                                          Module 1 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nWavelets: These  are  the  foundation  for  representing  images  in  various  degrees  of  resolution.  In \nparticular  used  for  image  data  compression  and  for  pyramidal  representation,  in  which  images \nare subdivided successively into smaller regions.  \nCompression: Deals with techniques for reducing the storage required to saving an image, or the \nbandwidth  required  to  transmit  it.  An  example  for  image  compression  standard is  jpg  file \nextension used in the JPEG(Joint Photographic Experts Group) image compression standard. \nMorphological processing: It deals with tools for extracting image components that are useful in \nthe representation and description of shape.  \nSegmentation: Segmentation procedures partition an image into its constituent’s parts or objects. \nIn  general,  autonomous  segmentation  is  one  of  the  most  difficult  task  in  digital  processing.  A \nrugged  segmentation  procedure  brings  the  process  a  long  way  towards  successful  solution  of \nimaging  problems  that require  objects to  be  identified  individually. On  the other  hand,  weak  or \nerratic segmentation algorithms always guarantee eventual failure.  \nRepresentation  and  description: It  follows  the  output  of  the  segmentation  stage,  which  is  raw \npixel data it’s needed to convert it to a form suitable for computer processing. The first decision \nthat must be made is whether the data should be represented as a boundary (i.e., the set of pixels \nseparating one image region from another) or as a complete region. \n The  boundary  representation  is  appropriate  when  the  focus  is  on  external  shape \ncharacteristics, such as corners and inflections. \n The regional representation is appropriate when the focus is on internal properties, such \nas texture or skeletal shape. \nDescription  also  called  feature  selection,  deals  with  extracting  attributes  that  result  in  some \nquantitative  information  of  interest  or  are  basic  for  differentiating  one  class  of  objects  from \nanother. \nRecognition: It  is  the process  that  assigns a  label  (e.g.,  ‘vehicle’) to  an  object  based  on  its \ndescriptors.  \n \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 1 [www.vtuloop.com] (1).pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Digital Image Processing                                                                                                          Module 1","Author":"Sandesh","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20180918114405+00'00'","ModDate":"D:20180918114405Z"},"metadata":null,"totalPages":14},"loc":{"pageNumber":3}}}],["59c6ef73-1cef-4925-a86a-f781fa41ba1c",{"pageContent":"4 \nDigital Image Processing                                                                                                          Module 1 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nComponents of an Image Processing System** \n Network \n \n \n \n \n \n \n \n \n \n \n \n \nProblem domain \nFigure 1.2 Components of a general – purpose image processing system. \nThe above figure shows the basic components comprising a typical general purpose system used \nfor  digital  image  processing.  With  reference  to sensing,  two  elements  are required  to  acquire \ndigital images: \n1. The  physical  device  that  is  sensitive  to  the  energy  radiated  by  the  object  we  wish  to \nimage.  \n2. Digitizer  is a device  for converting the output of the physical  sensing device  into digital \nform.  \nFor example in a digital camera, the sensors produce an electrical output proportional to light \nintensity.  \nImage Displays Computer \nImage sensors \nHardcopy \nSpecialized image \nprocessing \nhardware \nImage processing \nsoftware \nMass storage \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 1 [www.vtuloop.com] (1).pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Digital Image Processing                                                                                                          Module 1","Author":"Sandesh","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20180918114405+00'00'","ModDate":"D:20180918114405Z"},"metadata":null,"totalPages":14},"loc":{"pageNumber":4}}}],["b8bdfb0c-d667-4b12-afa2-0bffe062cf2e",{"pageContent":"5 \nDigital Image Processing                                                                                                          Module 1 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nSpecialized image processing hardware usually consists of the digitizer plus hardware that \nperforms  other  primitive  operations,  such  as  an  arithmetic  logic  unit(ALU),  that  performs  other \nprimitive  operations  in  parallel  on  entire  images.  This  type  of  hardware  is  called  a front  end \nsubsystem, and its most distinguished characteristic is speed, so this unit performs functions that \nrequire fast data throughputs that the typical main computer cannot handle.  \nThe Computer in an  image processing system  is a general purpose computer and can range \nfrom a PC to a supercomputer. In dedicated applications, sometimes custom computers are used \nto achieve a required level of performance.  \nSoftware for image processing consists of specialized modules that perform specific tasks. A \nwell designed package also  includes the capacity  for the user to write code that, as a minimum, \nutilizes the specialized modules.  \nMass  storage capacity  is  a  must  in image  processing  applications.  An  image  1024  X  1024 \npixels, in which the intensity of each pixel is an 8-bit quantity, requires one megabyte of storage \nspace if the image is not compressed. When dealing with thousands, or even millions, of images, \nproviding  adequate  storage  in  an  image  processing  applications  falls  into  three  principal \ncategories:  \n1. Short term storage for use during processing \n2. Online storage for relatively fast recall \n3. Archival storage, characterized by infrequent access.  \nStorage  is  measured  in  bytes,  Kbytes,  Mbytes,  Gbytes,  Tbytes.  One  method  of  providing \nshort  term  storage  is  computer  memory.  An-other  is  by  specialized  buffers,  that  store  one  or \nmore images and can be accessed rapidly, usually at video buffers, that store one or more images \nand   can   be   accessed rapidly,   usually   at   video   rates.  The   latter   method   allows   virtually \ninstantaneous  image  zoom,  as  well  as  scroll  (vertical  shifts)  and  pan  (horizontal  shifts).  Online \nstorage  generally  takes  the  form  of  magnetic  disks or  optical  image  storage.  The  key  factor \ncharacterizing the online storage is frequent access to the stored data. Magnetic tapes and optical \ndisks housed in ‘jukeboxes’ are the usual media for the archival applications.  \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 1 [www.vtuloop.com] (1).pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Digital Image Processing                                                                                                          Module 1","Author":"Sandesh","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20180918114405+00'00'","ModDate":"D:20180918114405Z"},"metadata":null,"totalPages":14},"loc":{"pageNumber":5}}}],["3e139bbd-6e19-472d-a714-e6c9b8d2db63",{"pageContent":"6 \nDigital Image Processing                                                                                                          Module 1 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nImage  displays in  use  today  are  mainly  color  TV  monitors.  Monitors  are  driven  by  the \noutputs of  image  and  graphic  display  cards  that  are  an  integral  part  of  the  computer  system. In \nsome cases it is necessary to have stereo displays, and these are implemented in the form of head \ngear containing two small displays embedded in goggles worn by the users.  \nHardcopy devices  for  recording  images  include  laser  printers,  film  cameras,  heat-sensitive \ndevices,  inject  units,  such  as  optical  and  CD  ROM  disks.  Film  provides  the  highest  possible \nresolution, but paper is the obvious medium of choice for written material.  \nNetworking is almost a default function in any computer system in use today. Because of the \nlarge  amount of  data  inherent  in  image  processing  applications,  the  key  consideration  in  image \ntransmission  is  bandwidth. Optical  fiber  and  other  broadband  technologies overcoming  the \nproblem of communicating with remote sites via internet.  \nSampling and Quantization  \n In signal processing sampling is the reduction of continues time-signal into discrete time-\nsignal. We denote images by two-dimensional  functions of the  form  f( x,  y ). An  image  may  be \ncontinues with respect to the x- and y- coordinates, and also in amplitude. To convert it to digital \nform,  we  have  sampled  the  function  in  both  coordinates  and  in  amplitude.  Digitizing  the \ncoordinate values is called sampling. Digitizing the amplitude values is called quantization. \n \nFigure 1.3 Continues image, A scan line from A to B in the continues image, Sampling and quantization, Digital Scan line  \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 1 [www.vtuloop.com] (1).pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Digital Image Processing                                                                                                          Module 1","Author":"Sandesh","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20180918114405+00'00'","ModDate":"D:20180918114405Z"},"metadata":null,"totalPages":14},"loc":{"pageNumber":6}}}],["1529519c-916a-442a-94ff-6c2492df0b9c",{"pageContent":"7 \nDigital Image Processing                                                                                                          Module 1 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n In fig. 1.3(a) shows a continuous image f that we want to convert to digital form. The one \ndimensional  function in  fig. 1.3(b)  is  a  plot  of  amplitude  values  of  the  continuous  image  along \nthe line segment AB in fig. 1.3(a). The random variations are due to image noise. To sample this \nfunction, we take equally  spaced  samples along the  line  AB, as  shown  in fig.1.3(c). The spatial \nlocation of each sample is indicated by a vertical tick mark in the bottom part of the figure. The \nsamples  are  shown  as  small  white  squares  superimposed  on  the  function.  The  set  of  these \ndiscrete  locations  gives  the  sampled  function. In  order  to  form  a  digital  function,  the  intensity \nvalues also must be converted into discrete quantities. The right side of the fig. 1.3(c) shows the \nintensity  scale divided  into eight discrete intervals, ranging  from black to white. The vertical tic \nmarks indicate the specific value assigned to each of the eight intensity intervals. The continuous \nintensity  levels are  quantized  by  assigning  one  of  the  eight  values  to  each  sample.  The  digital \nsamples resulting from both sampling and quantization are shown in fig 1.3(d).  \nRepresenting Digital Images \n Let f(s, t) represent a continuous image function of two continuous variables, s and t. We \nconvert this  function  into a digital  image by sampling and quantization. Suppose we sample the \ncontinuous  image  into  a  2-D  array,  f(x,y),  containing  M  rows  and  N  columns,  where  (x,y)  are \ndiscrete  coordinates. For  notational  clarity and  convenience,  we  use  integer  values  for  these \ndiscrete  coordinates:  x  =  0,1,2,3,...M-1  and  y  =  0,1,2,3,.....N-1. In  general,  the  value  of  the \nimage  at  any  coordinates  (x,y)  is  denoted  f(x,y),  where  x  and  y  are  integers.  The  section  of  the \nreal  plane  spanned by  the  coordinates  of  an  image  is  called  the spatial  domain, with  x  and  y \nbeing referred to as spatial variables or spatial coordinates.  The image displays allow us to view \nresults at a glance. Numerical arrays are used for processing and algorithm development.  \n In equation form, we write the representation of an M X N numerical array as \n \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 1 [www.vtuloop.com] (1).pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Digital Image Processing                                                                                                          Module 1","Author":"Sandesh","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20180918114405+00'00'","ModDate":"D:20180918114405Z"},"metadata":null,"totalPages":14},"loc":{"pageNumber":7}}}],["3d6b2faf-35f1-4918-8ccf-36069225b392",{"pageContent":"8 \nDigital Image Processing                                                                                                          Module 1 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n Both  the  sides  of  this  equation  are  equivalent  ways  of  expressing  a  digital  image \nquantitatively. The right side is a matrix of real numbers. Each element of this matrix is called an \nimage  element,  pictures  element,  pixels,  or  pel. This  digitization  process  requires  that  decisions \nbe made regarding the values for M, N, and for the number L of discrete intensity levels. Here M \nand N are positive integers. The number of intensity levels typically is an integer power of 2:  \nL= 2\nk \nThe number, b of bits required to store a digitized image is b = ‘M’ x ‘N’ x ‘k’ When M = N, this \nequation becomes b = N\n2\nk \nBasic Relationships between Pixels  \n A  pixel  p  at  coordinates  (  x,  y)  has  four  horizontal  and  vertical  neighbors  whose \ncoordinates are given by \n(x+1, y), (x-1, y), (x, y+1), (x, y-1) \nThis set of pixels is called the 4-neighbors of P, and is denoted by N 4(P). Each of them are at a \nunit distance from P. The four diagonal neighbors of p(x,y) are given by,  \n(x+1, y+1), (x+1, y-1), (x-1, y+1), (x-1, y-1) \nThis  set  is  denoted  by  N  D(P). Each  of  them  are  at  Euclidean  distance  of  1.414  from  P. The \npoints  ND(P)  and  N\n4\n(P)  are  together  known  as  8-neighbors  of  the  point  P,  denoted  by  N\n8\n(P). \nSome  of  the  points  in  the  N4,  ND  and  N8  may  fall  outside  image  when  P  lies  on the  border of \nimage. \n \n N 4 - 4-neighbors \n N D - diagonal neighbors \n N 8 - 8-neighbors (N 4 U N D ) \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 1 [www.vtuloop.com] (1).pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Digital Image Processing                                                                                                          Module 1","Author":"Sandesh","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20180918114405+00'00'","ModDate":"D:20180918114405Z"},"metadata":null,"totalPages":14},"loc":{"pageNumber":8}}}],["cd675625-8f2f-4a46-8920-08e999b3771a",{"pageContent":"9 \nDigital Image Processing                                                                                                          Module 1 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nNeighbors of a pixel  \na. 4-neighbors of a pixel p are its vertical and horizontal neighbors denoted by N4(p) \n      \nb. 8-neighbors of  a  pixel  p  are  its  vertical  horizontal  and  4  diagonal  neighbors  denoted \nby N8(p) is shown above.  \n \nAdjacency, Connectivity, regions, and Boundaries  \n \nAdjacency: Two  pixels  are  connected  if  they  are  neighbors  and  their  gray  levels  satisfy  some \nspecified criterion of similarity. For example, in a binary image two pixels are connected if they \nare 4-neighbors and have same value (0/1) then it is said to be satisfy adjacency. \nLet V be set of gray levels values used to define adjacency. \n4-adjacency:  Two pixels p and q with values from V are 4- adjacent if q is in the set N 4 (p).  \n8-adjacency:  Two pixels p and q with values from V are 8- adjacent if q is in the set N 8 (p). \nm-adjacency: Two pixels p and q with values from V are madjacent if,  \nA. q is in N 4(P).  \nB. q is in   N D(p) and the set N4(p) ∩  N4(q) is empty (has no pixels whose values are \nfrom V.  \nConnectivity: To determine whether the pixels are adjacent in some sense. Let V be the set of \ngray-level values used to define connectivity; then Two pixels p, q that have values from the set \nV(1,2) are: \na.  4-connected, if q is in the set N4(p) \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 1 [www.vtuloop.com] (1).pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Digital Image Processing                                                                                                          Module 1","Author":"Sandesh","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20180918114405+00'00'","ModDate":"D:20180918114405Z"},"metadata":null,"totalPages":14},"loc":{"pageNumber":9}}}],["201d6746-e327-465e-a3d2-51b8863ac750",{"pageContent":"10 \nDigital Image Processing                                                                                                          Module 1 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n \n \nb. 8-connected, if q is in the set N8(p)  \n \n \nc. m-connected, if q is in N4(p) or q is in ND(p) and the set N\n4\n (p) ∩ N\n4\n (q) is empty \n \nPaths & Path lengths: \nA path from pixel p with coordinates (x, y) to pixel q with coordinates (s, t) is a sequence \nof distinct pixels with coordinates:  \n(x 0, y 0), (x 1, y 1), (x2, y 2) ... (x n, y n), \nwhere (x 0, y 0)=(x, y) and (x n, y n)=(s, t); (x i, y i ) is adjacent to (xi-1, yi-1) (1 ≤ i ≤ n) and ‘n’ \nis the length of the path. We can define 4-, 8-, and m-paths based on type of adjacency used. \n \nConnected Components:  \nIf p and q are pixels of an  image subset S then p  is connected to q in S if there  is a path \nfrom p to q consisting entirely of pixels in S. For every pixel p in S, the set of pixels in S that are \nconnected  to  p  is  called  a  connected  component  of S, If  S  has  only  one  connected  component \nthen S is called Connected Set . \n \nRegions and Boundaries  \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 1 [www.vtuloop.com] (1).pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Digital Image Processing                                                                                                          Module 1","Author":"Sandesh","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20180918114405+00'00'","ModDate":"D:20180918114405Z"},"metadata":null,"totalPages":14},"loc":{"pageNumber":10}}}],["ed9ae9bc-bdb1-4874-8cb0-8516adc8def5",{"pageContent":"11 \nDigital Image Processing                                                                                                          Module 1 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nA  subset  R  of pixels  in  an  image  is  called  a  Region  of  the  image  if  R  is  a \nconnected  set.   The  boundary  of  the  region  R  is  the  set of  pixels  in  the  region  that  have  one or \nmore neighbors that are not in R. If R happens to be an entire image, then its boundary is defined \nas  the  set  of  pixels  in  the  first  and  last  rows  and  columns  of  the  image  and  image  has  no \nneighbors beyond its border. Normally, when we refer to a region, we are referring to a subset of \nan image, and any pixels in the boundary of the region that happen to coincide with the border of \nthe image are included implicitly as part of the region boundary. \nDistance Measure  \nGiven  pixels  p,  q  and  z  with  coordinates  (x,  y),  (s,  t),  (u,  v)  respectively,  the  distance \nfunction D has following properties: \na. D(p, q) ≥ 0 [ D(p, q) = 0, iff  p = q]  \nb. D(p, q) = D(q, p)  \nc. D(p, z) ≤ D(p, q) + D(q, z) \nThe following are the different Distance measures: \n Euclidean Distance : D\ne\n(p, q) = [(x-s)2 + (y-t) 2 ] \n City Block Distance: D\n4\n(p, q) = |x-s| + |y-t| \n \n    \n \n \n \n Chess Board Distance: D\n8\n(p, q) = max(|x-s|, |y-t|) \n  2   \n 2 1 2  \n2 1 0 1 2 \n 2 1 2  \n  2   \n2 2 2 2 2 \n2 1 1 1 2 \n2 1 0 1 2 \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 1 [www.vtuloop.com] (1).pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Digital Image Processing                                                                                                          Module 1","Author":"Sandesh","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20180918114405+00'00'","ModDate":"D:20180918114405Z"},"metadata":null,"totalPages":14},"loc":{"pageNumber":11}}}],["9f731652-4272-4470-a598-501a1f0b4a47",{"pageContent":"12 \nDigital Image Processing                                                                                                          Module 1 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n \n  \n \n \n \nIn  this  case,  the  pixels  with  D\n8 \ndistance  from  (x,  y)  less  than  or  equal  to  some  value  r  form  a \nsquare  centered at  (x,y).    For  example,  the  pixels  with  D\n8 \ndistance ≤ 2  from (x,  y)  form the \nfollowing contains of constant distance: The pxels with D\n8 \n= 1 are the 8- neighbors of (x, y). \nApplications of Image Processing:  \nThe  areas  of  application  of  digital  image  processing  are  so  varied  that  some form  of \norganization  is  desirable  in  attempting  to  capture  the  breadth  of  this field.  One  of  the  simplest \nways  to  develop  a  basic  understanding  of  the  extent  of image  processing  applications  is  to \ncategorize images according to their application. \n1. Medical imaging \n2. Robot vision \n3. Character recognition \n4. Remote Sensing. \nMedical Imaging:  \nGamma-Ray  Imaging: Major  uses  of  imaging  based  on  gamma  rays  include  nuclear  medicine \nand  astronomical observations.  In  nuclear  medicine,  the  approach is  to  inject  a  patient with  a \nradioactive isotope that emits gamma rays as it decays. Images are produced from the emissions \ncollected by gamma ray detectors. \nX-ray Imaging: X-rays are among the oldest sources of EM radiation used for imaging. The best \nknown  use  of  X-rays  is  medical  diagnostics,  but  they  also  are  used  extensively in  industry  and \nother areas, like astronomy. X-rays for medical and industrial imaging are generated using an X-\nray tube, which is a vacuum tube with a cathode and anode. The cathode is heated, causing free \nelectrons  to  be released.  These  electrons  flow  at  high  speed  to  the  positively  charged  anode.  \nWhen the electrons strike  a nucleus, energy  is released  in the  form of X-ray radiation. e energy \n(penetrating  power)  of  the  X-rays  is controlled  by  a  voltage applied  across  the  anode,  and  the \nnumber of X-rays is controlled by a current applied to the filament in the cathode. The intensity \n2 1 1 1 2 \n2 2 2 2 2 \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 1 [www.vtuloop.com] (1).pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Digital Image Processing                                                                                                          Module 1","Author":"Sandesh","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20180918114405+00'00'","ModDate":"D:20180918114405Z"},"metadata":null,"totalPages":14},"loc":{"pageNumber":12}}}],["90888c87-cdde-4fff-a165-60ddf0ac6cf3",{"pageContent":"13 \nDigital Image Processing                                                                                                          Module 1 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nof the X-rays is modified by absorption as they pass through the patient, and the resulting energy \nfalling  on  the  film  develops it,  much  in  the  same  way  that  light  develops  photographic  film.  In \ndigital radiography, digital images are obtained by one of two methods: \n (1) By digitizing X-ray films;  \n (2) by having the X-rays that pass through the patient fall directly onto devices (such as a \nphosphor screen) that convert X-rays to light.  \nRobot Vision:  \nApart from the many challenges that a robot face today, one of the biggest challenge still \nis to increase the vision of the robot. Make robot able to see things, identify them.  \n1. Hurdle detection: \nHurdle  detection  is  one  of  the  common  task  that  has  been  done  through  image \nprocessing, by  identifying different type of objects  in the  image and then calculating the \ndistance between robot and hurdles. \n2. Line follower robot: \nMost  of  the  robots  today  work  by  following  the  line  and  thus  are  called  line \nfollower robots. This helps a robot to move on its path and perform some tasks. This has \nalso been achieved through image processing. \nCharacter Recognition:  \n• Optical Character Recognition \n• Detecting License Plate \n• Banking- To process the cheques \n• Blind and visually impaired persons \n• Legal department \n• Retail Industry \nRemote Sensing:  \nIn the field of remote sensing, the area of the earth is scanned by a satellite or from a very \nhigh ground and then  it  is analyzed to obtain  information about it. One particular application of \ndigital image processing in the field of remote sensing is to detect infrastructure damages caused \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 1 [www.vtuloop.com] (1).pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Digital Image Processing                                                                                                          Module 1","Author":"Sandesh","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20180918114405+00'00'","ModDate":"D:20180918114405Z"},"metadata":null,"totalPages":14},"loc":{"pageNumber":13}}}],["ea304ef8-832d-4147-9e06-ef124437a82e",{"pageContent":"14 \nDigital Image Processing                                                                                                          Module 1 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nby  an  earthquake. Since  the  area  effected  by  the earthquake  is  sometimes  so  wide,  that  it  not \npossible to examine it with human eye in order to estimate damages. Even if it is , then it is very \nhectic and time consuming procedure. So a solution to this  is  found  in digital  image processing \nusing remote sensing. An image of the affected area is captured from the above ground and then \nit  is  analyzed  to  detect  the  various  types  of  damage  done  by  the  earthquake. The  key  steps \ninclude in the analysis are \n1. The extraction of edges \n2. Analysis and enhancement of various types of edges \n \n \n \n \n \n  \n \n \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 1 [www.vtuloop.com] (1).pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Digital Image Processing                                                                                                          Module 1","Author":"Sandesh","Creator":"Microsoft® Word 2016","Producer":"www.ilovepdf.com","CreationDate":"D:20180918114405+00'00'","ModDate":"D:20180918114405Z"},"metadata":null,"totalPages":14},"loc":{"pageNumber":14}}}],["3d05607b-f1ac-4527-b3ea-7359418cf6fa",{"pageContent":"1\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nModule 2\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN \nPrepared By,\nSandesha Karanth P.K & Ragavendra Katagall\nAssistant Professors, Dept. Of CSE,\nVCET, Puttur\nwritetokaranth@gmail.com  \n1\n,rkk4691@gmail.com  \n2\nImage enhancement approaches fall into two broad categories: spatial domainmethods\nand   frequency  domain   methods.The   term  spatial domainrefers   to   theimage   plane   itself,   and\napproaches in this category are based on direct manipulationof pixels in an image.  Frequency\ndomain processing techniques are basedon modifying the Fourier transform of an image.\nThe term  spatial domain refers to the aggregate ofpixels composing an image. Spatial\ndomain methods are procedures that operatedirectly on these pixels. Spatial domain processes\nwill be denoted by theexpression\ng (x, y) = T [f (x, y)]\nwhere f(x, y) is the input image, g(x, y) is the processed image, and T is anoperator on f,\ndefined over some neighborhood of (x, y). In addition,T can operateon a  set of input images,\nsuch as performing the pixel-by-pixel sum of Kimages for noise reduction. \nThe principal approach in defining a neighborhood about a point (x, y) is to use a square\nor rectangular subimage area centered at (x, y), as shown in below figure 1.\nFigure 1: 3*3neighborhoodabout a point (x, y) in an image.\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":1}}}],["d54a4299-0488-4621-b58b-ab8ef49411a0",{"pageContent":"2\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nThe center of the subimage is moved from pixel to pixel starting, say, at the topleft\ncorner.The operator T is applied at each location (x, y) to yield the output,g, at that location.The\nprocess utilizes only the pixels in the area of the image spanned by the neighborhood.Although\nother neighborhood shapes, such as approximations to a circle, sometimes are used, square and\nrectangular arrays areby far the most predominant because of their ease of implementation.\nThe simplest form of T is when the neighborhood is of size 1*1 (that is, asingle pixel). In\nthis case, g depends only on the value of f at (x, y), and T becomesa gray-level (also called an\nintensity  or  mapping)  transformation   functionof   the   forms   =   T(r)where,   for   simplicity   in\nnotation, r and s are variables denoting, respectively, the gray level of f(x, y) and g(x, y) at any\npoint (x, y).\nFor example, if T(r) has the form shown in Fig. 2(a), the effect of this transformation\nwould   be   to   produce   an   image   of   higher   contrast   than   the   original   by  darkening   the   levels\nbelowm and brightening the levels above  m in the original image. In this technique,known as\ncontrast stretching, the values of r below m are compressed by thetransformation function into a\nnarrow range of s, toward black.The opposite effecttakes place for values of r above m. In the\nlimiting case shown in Fig. 2(b),T(r) produces a two-level (binary) image.A mapping of this\nform is called a thresholding function.\nFigure 2a,b : Gray level transformation functions for contrast enhancement.\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":2}}}],["0ce1e508-538c-456a-9d7b-bd6faa8a464b",{"pageContent":"3\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nSome Basic Gray Level Transformations:\n1.Image Negatives:\nThe negative of an image with gray levels in the range [0,L-1]is obtained by using the\nnegative transformation shown in Fig. 3.3, which is given by the expression\ns = L - 1 – r\nFigure 3: Some basic gray-level transformation functions used for image enhancement.\nReversing   the   intensity  levels   of   an   image   produces   the   equivalentof   a   photographic\nnegative.   This   type   of   processing   is   particularly   suitedfor   enhancing   white   or   gray   detail\nembedded in dark regions of an image, especiallywhen the black areas are dominant in size.\n2.Log Transformations: \nThe general form of the log transformation\ns = c log (1 + r)\nwhere c is a constant, and it is assumed that r \n≥\n 0.\nThe shape of the log curve in Fig. 3 shows that this transformation maps a narrow range\nof low gray-levelvalues in the input image into a wider range of output levels. The opposite is\ntrue of higher values of input levels.We would use a transformation of this type toexpand the\nvalues of dark pixels in an image while compressing the higher-levelvalues.The opposite is true\nof the inverse log transformation.\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":3}}}],["1d113aac-e456-41a1-ab58-54950f648002",{"pageContent":"4\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\n3.Power-Law Transformations\nPower-law transformations have the basic form\ns = c r\nγ\nwhere c and \nγ\n are positive constants, Also can be represented as  \ns = c (r+ε)\nγ\nAn offset measurable when input is zero\nWe see in Fig. 4 that curves generated with values of g>1 have exactlythe opposite effect\nas those generated with values of g<1.Finally, wenote that from above equation reduces to the\nidentity transformation when c=g=1.\nFigure 4: Plots of the equation s = c r\nγ\n for various values of g (c=1 in all cases).\nPlots of s versus r for variousvalues of g are shown in Fig. 4. As in the case of the log\ntransformation,power-law   curves   with   fractional   values   of   g   map   a   narrow   range   of   dark\ninputvalues into a wider range of output values, with the opposite being true for higher values of\ninput levels.\nA variety of devices used for image capture, printing, and display respond accordingto a\npower law. By convention, the exponent in the power-law equationis referred to as gamma. The\nprocess   used   to   correct   this   power-law   response   phenomenon   is   called   gamma\ncorrection.Gamma correctionis straightforward. All we need to do is preprocess the inputimage\nbefore inputting it into the monitor by performing the transformation\ns = r\n1/2.5\n = r\n0.4\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":4}}}],["37ef6577-529d-4b63-b9e6-2f2fd38c8588",{"pageContent":"5\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nGamma correction is important if displaying an image accurately on a computer screen is\nof concern. Images that are not corrected properly can look eitherbleached out, or, what is more\nlikely, too dark. \nFor example, cathode ray tube (CRT) devices have an intensity-to-voltage response that\nis a power function, with exponents varying from approximately 1.8 to 2.5.With reference to the\ncurve for g=2.5 in Fig. 3.6, wesee that such display systems would tend to produce images that\nare darker than intended.\nContrast stretching\nOne   of   the   simplest   piecewise   linear   functions   is   a   contrast-stretching\ntransformation.Low-contrast images can result from poor  illumination, lack of dynamic range in\nthe imaging sensor, or even wrong setting of a lens aperture during image acquisition. The idea\nbehind contrast stretching is to increase the dynamic range of the gray levels in the image being\nprocessed.\nIf r1,s1 and r2,s2 control the shape of the transformation function and if r1=s1 and r2=s2\nthe transformation is a linear function that produces no changes in intensity levels !\nIf r1=r2 and s1=0 and s2 =L-1, the transformation becomes a thresholding function that\ncreates a binary image.\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":5}}}],["16e5a054-cec2-4156-b7fe-f4aadc490ec3",{"pageContent":"6\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nIn   general   r1≤r2   and   s1   ≤s2   is   assumed   so   that   the   function   is   single   valued   and\nmonotonically increasing.This preserves the order of intensity levels, thus preventing the\ncreation of intensity artifacts in the processed image.\nGray level slicing\nIt   is   highlighting   a   specific   range   of   intensities   in   an   image   often   is   of   interest.   Its\napplications   include   enhancing   features   such   as   masses   of   water   in   satellite   imagery   and\nenhancing flaws in X-ray images.\nThe intensity level slicing process can be implemented for these defects/noise etc.\nIt can be done in several ways\nEx: One is to display in one value (say, white), all the values in the range of interest and\nin another (say, black), all other intensities.\nBit-plane slicing\nInstead   of   highlighting   gray-level   ranges,   highlighting   the   contribution   made   tototal\nimage   appearance   by  specific   bits   might   be   desired.   Suppose   that   eachpixel   in   an   image   is\nrepresented by 8 bits. Imagine that the image is composedof eight 1-bit planes, ranging from bit-\nplane 0 for the least significant bit to bitplane7 for the most significant bit. In terms of 8-bit\nbytes, plane 0 contains allthe lowest order bits in the bytes comprising the pixels in the image\nand plane7 contains all the high-order bits.\nFigure 5: Bit-plane representation of an 8-bit image.\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":6}}}],["2d9fe3f9-e89b-4da6-b8c3-67ea7a4783f2",{"pageContent":"7\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nDecomposing   an  image   into  its   bit   planes  is   useful  for  analyzing   the\nrelative   importance   of   each   bit  in   the   image,   a   process   that   aids   in\ndetermining the adequacy of the number of bits used to quantize the image.\nIt is useful in image compression. \nThe reconstruction is done by using few planes only.\nIt is done by multiplying the pixels of the n\nth\n plane by a constant 2\nn-1\n.\nAll the generated planes are added together (few of 8 planes)\nIf we use bit plane 7 and 8, multiply bit plane 8 by 128 and plane 7 by\n64 and then added together.\nHistogram Processing\nThe histogram of a digital image with gray levels in the range [0, L-1] is\na discrete  function  h(r\nk\n)=n\nk\n, where  r\nk\n  is the  k\nth\n  gray  level and n\nk\n  is the\nnumber of pixels in the image having gray level r\nk\n. Histograms are the basis\nfor numerous spatial domain processing techniques.Histogram manipulation\ncan be used effectively for image enhancement. Histograms are simple to\ncalculate   in   software   and   also   lendthemselves   to   economic   hardware\nimplementations, thus making them a popular tool for real-time image processing.\nThe   horizontal   axis   of   each   histogram  plot   corresponds   to   gray  level   values,   r\nk\n.  The\nvertical axis corresponds to values of \nH(r\nk\n)=n\nk\n or p(r\nk\n)=n\nk\n/n  if the values are normalized.\nThus, as indicated previously, these histogram plots are simply plots of h(r\nk\n)=n\nk\n versus r\nk\nor p(r\nk\n)=n\nk\n/n versus r\nk\n. \nHistogram Equalization\nConsider for a moment continuous functions, and let the variable  r  represent the gray\nlevels of the image to be enhanced. In the initial part of our discussion we assume that r has been\nnormalized to the interval [0, 1], with r=0 representing black and r=1 representing white. Later,\nwe consider a discrete formulationand allow pixel values to be in the interval [0, L-1].For any r\nsatisfying the aforementioned conditions, we focus attention on transformations of the form\ns=T(r)      0 ≤ r ≤ 1      ......(1)\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":7}}}],["d393b8ef-1885-4423-bb37-d9af3defae04",{"pageContent":"8\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nthat produce a level s for every pixel value r in the original image. For reasons that will become\nobvious   shortly,   we   assume   that   the   transformation   function   T(r)   satisfies   the   following\nconditions:\na.T(r) is a monotonically increasing function in the interval 0 ≤  r ≤  L-1: \nT(r) be single valued is needed to guarantee that the inverse transformation will exist, and\nthe monotonicity condition preserves  the increasing order from black to white in the\noutput image.\nb.0 ≤  T(r) ≤  L-1     for 0 ≤  r ≤  L-1: \nIt guaranteesthat the output gray levels will be in the same range as the input levels.\nFigure6 gives an example of a transformation function that satisfies these twoconditions.\nFigure 6 A gray-level transformation functions that is both single valued and monotonically increasing.\nThe inverse transformation from s back to r is denoted\nr = T\n-1\n(s)        0 ≤ s ≤1    ......(2)\nThe gray levels in an image may be viewed as random variables in the interval[0, 1]. One\nof   the   most   fundamental   descriptors   of   a   random   variable   isits   probability   density   function\n(PDF). Let p\nr\n(r) and p\ns\n(s) denote the probability density functions of random variables r and s,\nrespectively, where the subscriptson p are used to denote that pr and p\ns\n are different functions. A\nbasic result from an elementary probability theory is that, if p\nr\n(r) and T(r) are known andT\n-1\n(s)\nsatisfies condition(a) specified, then the probability density function ps(s) of the transformed\nvariable s can be obtained using a rather simple formula:\n   .........(3)\nA transformation function of particular importance in image processinghas the form\n..........(4) \nwhere w is a dummy variable of integration. From Leibniz’s rule in calculus\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":8}}}],["ebbce199-8ea2-46e9-a671-5367d4be95ad",{"pageContent":"9\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\n..........(5)\nSubstituting this result for dr/ds into Eq. (3), and keeping in mind that allprobability values are\npositive, yields\n....(6)\nFor   discrete   values   we   deal   with   probabilities   and   summations   instead   ofprobability\ndensity functions and integrals. The probability of occurrence of gray level r\nk\n  in an image is\napproximated by\n......(7)\nThe discrete version of the transformationfunction\n.....(8)\nThe   transformation   (mapping)   given   in   Eq.(8)   is   called  histogram equalizationor\nhistogram linearization.\nThe inverse transformation from s back to r is denoted by\n.......(9)\nHistogram Matching\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":9}}}],["313a89e5-82ee-43f1-aa33-841729a57cc4",{"pageContent":"10\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nAs indicated in the preceding discussion, histogram equalization automaticallydetermines\na   transformation   function   that   seeks   to   produce   an   output   imagethat   has   a   uniform\nhistogram.When automatic enhancement is desired, this isa good approach because the results\nfrom   this   technique   are   predictable   and   themethod   is   simple   to   implement.   But   in   few\napplications,   its   required   to   extract   specified   histogram   then   the   methodused   to   generate   a\nprocessed  image   that  has  a   specified   histogram  is   called  histogram matching or  histogram\nspecification.\nLet us return for a moment to continuous gray levels r and z and let p\nr\n(r) and p\nz\n(z) denote\ntheir corresponding continues probability density functions. In this notation, r and z denotethe\ngray levels of the input and output (processed) images, respectively. We can estimate p\nr\n(r) from\nthe given input image, while p\nz\n(z) is the specified probabilitydensity function that we wish the\noutput image to have.\nLet s be a random variable with the property\n.......(10)\nWhere ‘w’(omega)is a dummy variable of integration.\nSuppose nextthat we define a random variable z with the property\n......(11)\nwheret  is   a   dummy   variable   of   integration.   It   then   follows   from   these   two   equations   that\nG(z)=T(r) and, therefore, that z must satisfy the condition\n.....(12)\nThe transformation T(r) can be obtained from Eq. (10) once p\nr\n(r) has been estimated from the\ninput image. Similarly, the transformation function G(z) can be obtained using Eq. (11) because\np\nz\n(z) is given.\nThe discrete formulation of Eq. (3.3-10) is given by Eq. (3.3-8), which we repeathere for\nconvenience:\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":10}}}],["d6cee719-2a86-42ac-91af-bfbee23100e1",{"pageContent":"11\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\n....(13)\nWhere n is the total number of pixels in the image, nj is the number of pixels with gray level r\nj\n ,\nand  L is the number of discrete gray levels. Similarly, the discrete formulation of Eq. (11) is\nobtained from the given histogram p\nz\n(z\ni\n),i=0,1, 2,p ,L-1, and has the form\n.....(14)\nFinally,the discrete version of Eq. (12) is given by\n......(15)\nor, from Eq. (13),\n.......(16)\nFigure 7(a) Graphical interpretation of mapping from r\nk\n to s\nk\n via T(r). (b) Mapping of z\nq\n to its corresponding value v\nq\n via\nG(z). (c) Inverse mapping from s\nk\n to its corresponding value of z\nk\n.\nThe procedure we have just developed for histogram matching may be summarized as follows:\n1. Obtain the histogram of the given image.\n2. Use Eq. (13) to pre-compute a mapped level s\nk\n for each level r\nk\n.\n3. Obtain the transformation function G from the given p\nz\n(z) using Eq. (14).\n4. Pre-compute z\nk\n for each value of s\nk\n using the iterative scheme defined in connection with Eq.\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":11}}}],["d6a7105d-3dac-4800-b99d-905f6db23946",{"pageContent":"12\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\n5.  For each pixel in the original image, if the value of that pixel is r\nk\n, map this value to its\ncorresponding level s\nk\n; then map level s\nk\n  into the final level z\nk\n. Use the pre-computed values\nfrom Steps (2) and (4) for these mappings.\nEnhancement Using Arithmetic/Logic Operations\nArithmetic/logic operations  involving images  are  performed on a  pixel-by-pixel basis\nbetween two or more images (this excludes the logic operation NOT, which is performed on a\nsingle   image).Logic   operations   similarly   operate   on   a   pixel-by-pixel   basis.We  need   onlybe\nconcerned with the ability to implement the AND, OR, and NOT logic operators because these\nthree   operators   are  functionally   complete.When   dealing   with   logic   operations   on   gray-scale\nimages, pixel valuesare processed as strings of binary numbers. For example, performing the\nNOToperation on a black, 8-bit pixel (a string of eight 0’s) produces a white pixel(a string of\neight 1’s). Intermediate values are processed the same way, changing all 1’s to 0’s and vice versa.\nThe four arithmetic operations, subtraction and addition (in that order) arethe most useful\nfor image enhancement. \nImage Subtraction:\nThe difference between two images f(x, y) and h(x, y), expressed as\ng(x, y) = f(x, y) - h(x, y),\nAnd it is obtained by computing the difference between all pairs of corresponding pixels from f\nand h. The key usefulness of subtraction is the enhancement of differences between images. \nOne of the most commercially successful and beneficial uses of image subtraction is in\nthe area of medical imaging called mask mode radiography. In thiscase h(x, y), the mask, is an\nX-ray image of a region of a patient’s body capturedby an intensified TV camera (instead of\ntraditional X-ray film) located oppositean X-ray source.The procedure consists of injecting a\ncontrast   medium     into   the   patient’s   blood   stream,   taking   a   series   of   images   of   the   same\nanatomical regionas h(x, y), and subtracting this mask  from the series of incoming imagesafter\ninjection of the contrast medium. The net effect of subtracting the maskfrom each sample in the\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":12}}}],["635b0e98-00b0-4d84-854f-f2893f3baaa3",{"pageContent":"13\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nincoming stream of TV images is that the areas that aredifferent between f(x, y) and h(x, y)\nappear in the output image as enhanceddetail. \nImage Averaging:\nConsider a noisy image g(x, y) formed by the addition of noise h(x, y) to an original\nimage f(x, y); that is, \ng(x, y) = f(x, y) + h(x, y\nwhere the assumption is that at every pair of coordinates (x, y) the noise is uncorrelatedand has\nzero average value.The objective of the following procedureis to reduce the noise content by\nadding a set of noisy images, {g\ni\n(x, y)}.\nIf the noise satisfies the constraints just stated, it can be shown that if an image is\nformed by averaging K different noisy images,\nAn important application of image averaging is in the field of astronomy,where imaging\nwith very low light levels is routine, causing sensor noise frequentlyto render single images\nvirtually useless for analysis.\nMultiplication and Division:\nWe   consider   division   of   two   imagessimply   as   multiplication   of   one   image   by   the\nreciprocal of the other.Aside fromthe obvious operation of multiplying an image by a constant to\nincrease   its   averagegray   level,   image   multiplication   finds   use   in   enhancement   primarily   as\namasking   operation   that   is   more   general   than   the   logical   masks   discussed   in   theprevious\nparagraph. In other words, multiplication of one image by another canbe used to implement gray-\nlevel, rather than binary, masks.\nBasics of Spatial Filtering:\nSome   neighborhood   operations   work   with   the   valuesof   the   image   pixels   in   the\nneighborhood  andthe corresponding values of asubimage that has the same dimensions as the\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":13}}}],["aa6df0fe-dacd-4122-83c8-cc97e27668b5",{"pageContent":"14\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nneighborhood.The subimage iscalled a  filter, mask,  kernel, template,  or  window, with the first\nthree terms beingthe most prevalent terminology.The values in a filter subimage are referred to\nas coefficients, rather than pixels.\nThe mechanics of spatial filtering are illustrated in Fig 8. The process consists simply of\nmoving the filter mask from point to point in an image. At eachpoint (x, y), the responseof the\nfilter at that point is calculated using a predefinedrelationship. For linear spatial,the response is\ngiven by a sum of products of the filter coefficients and thecorresponding image pixels in the\narea spanned by the filter mask.\nFigure 8The mechanics of spatial filtering. The magnified drawing shows a 3*3 mask and the image section directly under\nit; the image section is shown displaced out from under the mask for ease of readability.\nFor the 3*3mask shown in Fig. 3.32, the result (or response), R, of linear filtering with thefilter\nmask at a point (x, y) in the image is\nwhich  we see  is   the  sum of  products  of  the  mask  coefficients   with  the  correspondingpixels\ndirectly under the mask. Note in particular that the coefficient w(0, 0) coincides with image value\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":14}}}],["e8fbc90b-6338-4dcb-89cf-53a85318a2c1",{"pageContent":"15\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nf(x, y), indicating that the mask is centeredat (x, y) when the computation of the sum of products\ntakes   place.   For   a   maskof   size   m*n,   we   assume   that   m=2a+1   and   n=2b+1,   where   a   and   b\narenonnegative integers. All this says is that our focus in the following discussionwill be on\nmasks of odd sizes, with the smallest meaningful size being 3*3 (weexclude from our discussion\nthe trivial case of a 1*1 mask).\nIn general, linear filtering of an image f of size M*N with a filter mask ofsize m*n is\ngiven by the expression:\nwhere, from the previous paragraph, a=(m-1)/2 and b=(n-1)/2. Togenerate a complete filtered\nimage this equation must be applied for x=0, 1,2, p , M-1 and y=0, 1, 2, p , N-1.\nWhen interest lies on the response, R, of an m*n mask at any point (x, y),and not on the\nmechanics of implementing mask convolution, it is commonpractice to simplify the notation by\nusing the following expression:\nwhere the w’s are mask coefficients, the z’s are the values of the image graylevels corresponding\nto those coefficients, and mn is the total number of coefficients in the mask.\nSmoothing Spatial Filter\nSmoothing   filters   are   used   for   blurring   and   for   noise   reduction.   Blurring   is   usedin\npreprocessing   steps,   such   as   removal   of   small   details   from   an   image   prior   to(large)   object\nextraction, and bridging of small gaps in lines or curves. Noise reduction can be accomplished by\nblurring with a linear filter and also by nonlinear filtering.\nSmoothing Linear Filters:\nThe output (response) of a smoothing, linear spatial filter is simply the averageof the\npixels   contained   in   the   neighborhood   of   the   filter   mask.   These   filters   sometimes   are   called\naveraging filters.\nThe idea behind smoothing filters is straightforward. By replacing the value of every\npixel in an image by the average of the gray levels in the neighborhood defined by the filter\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":15}}}],["fb645eae-cdce-4564-86e6-1b529ffca3de",{"pageContent":"16\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nmask, this process results in an image with reduced“sharp” transitions in gray levels. Because\nrandom noise typically consists ofsharp transitions in gray levels, the most obvious application of\nsmoothing isnoise reduction. However, edges (which almost always are desirable features of\nan image) also are characterized by sharp transitions in gray levels, so averagingfilters have the\nundesirable side effect that they blur edges. \nA major use of averaging filters is in the reduction of “irrelevant” detail in animage. By\n“irrelevant” we mean pixel regions that are small with respect to thesize of the filter mask.The\nFigure  shows two 3*3 smoothing filters. Use of the first filter yields thestandard average of the\npixels under the mask.\nThis is the average of the gray levels of the pixels in the 3*3 neighborhood defined by the mask.\nNote that, instead of being 1_9, the coefficients of the filterare all 1’s. An m*n mask would have\na normalizing constant equal to 1_mn. A spatial averaging filter in which all coefficients are\nequal is sometimes calleda box filter.\nFigure 9 Two 3*3 smoothing (averaging) filter masks. The constant multiplier in front of each mask is equal to the sum of\nthe values of its coefficients, as is required to compute an average.\nThe second mask shown in Fig. 9 is a little more interesting. This mask yields a so-called\nweighted   average,   terminology   used   to   indicate   that   pixels   aremultiplied   by   different\ncoefficients, thus giving more importance (weight) tosome pixels at the expense of others. In the\nmask shown in Fig. 9(b) the pixel at the center of the mask is multiplied by a higher value than\nany other, thus giving this pixel more importance in the calculation of the average.The other\npixelsare inversely weighted as a function of their distance from the center of the mask.\nThe general implementation  for filtering an M*N image with a weighted averaging filter\nof size m*n (m and  n odd) is given by the expression\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":16}}}],["b61fcb2a-adb7-4f10-9d41-31e8b516f01d",{"pageContent":"17\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nFor x=0, 1, 2, p , M-1 and y=0, 1, 2, p , N-1.\nOrder-Statistics Filters\nOrder-statistics filters are nonlinear spatial filters whose response is based on ordering\n(ranking) the pixels contained in the image area encompassed by the filter, and then replacing the\nvalue of the center pixel with the value determined by the ranking result.\nThe best-known example in this category is the median filter, which, as its name implies,\nreplaces the value of a pixel by the median of the gray levels in the neighborhood of that pixel\n(the original value of the pixel is included in the computation of the median). Median filters are\nquite popular because, for certain types of random noise, they provide excellent noise-reduction\ncapabilities, with considerably less blurring than linear smoothing filters of similar size. Median\nfilters are particularly effective in the presence of impulse noise, also called salt-and-pepper\nnoise because of its appearance as white and black dots superimposed on an image. The median,\nj, of a set of values is such that half the values in the set are less than or equal to j, and half are\ngreater than or equal to j. In order to perform median filtering at a point in an image, we first sort\nthe values of the pixel in question and its neighbors, determine their median, and assign this\nvalue to that pixel. For example, in a 3*3 neighborhood the median is the 5th largest value, in a\n5*5 neighborhood the 13th largest value, and so on.When several valuesin a neighborhood are\nthe same, all equal values are grouped.\n For example, suppose that a 3*3 neighborhood has values (10, 20, 20, 20, 15, 20, 20, 25,\n100). These values are sorted as (10, 15, 20, 20, 20, 20, 20, 25, 100), which results in a median of\n20. Thus, the principal function of median filters is to force points with distinct gray levels to be\nmore like their neighbors. In fact, isolated clusters of pixels that are light or dark with respect to\ntheir neighbors, and whose area is less than n\n2\n/2 (one-half the filter area), are eliminated by an\nn*n   median   filter.   In   this   case   “eliminated”   means   forced   to   the   median   intensity   of   the\nneighbors. Larger clusters are affected considerably less. Although the median filter is by far the\nmost useful order-statistics filter in image processing, it is by no means the only one. The median\nrepresents the 50th percentile of a ranked set of numbers, but the reader will recall from basic\nstatistics   that   ranking   lends   itself   to   many  other   possibilities.   For   example,   using   the   100th\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":17}}}],["13a3080a-9429-490a-b4a7-3dc44e76f4f4",{"pageContent":"18\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\npercentile results in the so-called max filter, which is useful in finding the brightest points in an\nimage. The response of a 3*3 max filter is given by R=max (zk|k=1, 2,p , 9).The 0th percentile\nfilter is the min filter, used for the opposite purpose.\nSharpening Spatial Filters: \nThe principal objective of sharpening is to highlight fine detail in an image or to enhance\ndetail that has been blurred, either in error or as a natural effect of a particular method of image\nacquisition.\nImage  sharpening  vary and  include  applications  ranging  from  electronic  printing  and\nmedical   imaging   to   industrial   inspection   and   autonomous   guidance   in   military   systems.\nSharpening  filters that are based on first- and second-order derivatives. The derivatives\nof a digital function are defined in terms of differences. There are various ways to define these\ndifferences. However, we require that any definition we use for a first derivative (1) must be zero\nin flat segments (areas of constant gray-level values); (2) must be nonzero at the onset of a gray-\nlevel step or ramp; and (3) must be nonzero along ramps. Similarly, any definition of a second\nderivative (1) must be zero in flat areas; (2) must be nonzero at the onset and end of a gray-level\nstep or ramp; and (3) must be zero along ramps of constant slope.\nA basic definition of the first-order derivative of a one-dimensional function f(x)\nis the difference\nSimilarly, we define a second-order derivative as the difference\nIt   is   easily   verified   that   these   two   definitions   satisfy   the   conditions   stated\npreviouslyregarding derivatives of the first and second order. \nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":18}}}],["878a074e-f166-4602-9ca5-3e06702de519",{"pageContent":"19\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nFigure 10 Simplified profile (the points are joined by dashed lines to simplify\ninterpretation).\nFigure 10 shows a simplification of the profile, with just enough numbers to make it\npossible for us to analyze how the first- and second-order derivativesbehave as they encounter a\nnoise point, a line, and then the edge of anobject. In our simplified diagram the transition in the\nramp spans four pixels, thenoise point is a single pixel, the line is three pixels thick, and the\ntransition   intothe   gray-level   step   takes   place   between   adjacent   pixels.The   number   of   gray\nlevelswas simplified to only eight levels.\nLet us consider the properties of the first and second derivatives as we traversethe profile\nfrom left to right.\n1.The first-order derivative is nonzero along the entire ramp, \n2.The second-order derivative is nonzero only at the onset and end of the ramp. \nWe  conclude   that   first-order   derivatives   produce   “thick”   edges   and   second-order\nderivatives, much finer ones. \n3.We encounter the isolated noise point. Here, the response at and around the point is\nmuch stronger for the second- than for the first-order derivative. \n4.A second-order derivative is much more aggressive than a first-order derivative in\nenhancing sharp changes. Thus, we can expect a second-order derivative to enhance\nfine detail (including noise) much more than a first-order derivative.\n5. The thin line is a fine detail, and we see essentially the same difference between the\ntwo derivatives. If the maximum gray level of the line had been the same as the\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":19}}}],["9519d812-bd87-4222-b62c-9c3ae25250ca",{"pageContent":"20\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nisolated point, the response of the second derivative would have been stronger for the\nlatter. \n6.Finally, in this case, the response of the two derivatives is the same at the gray-level\nstep. We also note that the second derivative has a transition from positive back to\nnegative. \nComparison B/N first- and second-order derivatives response\n1.First-order derivatives generallyproduce thicker edges in an image.\n2.Second-order derivatives have astronger response to fine detail, such\nas thin lines and isolated points.\n3.Firstorderderivatives generally have a stronger response to a gray-level\nstep.\n4.Second-order derivatives produce a double response at step changes\nin gray level.\nUse of Second Derivatives for Enhancement–The Laplacian\nThe approach basically consists of defininga discrete formulation of the second-order\nderivative  and then  constructinga  filter  mask  based on  that  formulation.We are  interested  in\nisotropic  filters,whose   response   is   independent   of   the   direction   of   the   discontinuities   in   the\nimageto which the filter is applied. In other words, isotropic filters are rotation invariant,in the\nsense that rotating the image and then applying the filter gives thesame result as applying the\nfilter to the image first and then rotating the result.\nIt can be shown that the simplest isotropic derivative operator is the Laplacian, which, for\na function (image) f(x, y) of twovariables, is defined as\n......(1)\nBecause derivatives of any order are linear operations, the Laplacian is a linear operator.\nThe   definition   of   the   digital   second   derivative   given   in   that   section   is   one   of   the   most\nused.Taking intoaccount that we now have two variables, we use the following notation for\nthepartial second-order derivative in the x-direction:\n.....(2)\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":20}}}],["b69cc6a9-2056-4ea0-813c-e6e9e3b49609",{"pageContent":"21\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nand, similarly in the y-direction, as\n.....(3)\nThe digital implementation of the two-dimensional Laplacian in Eq. (1) isobtained by summing\nthese two components:\n.....(4)\nThis equation can be implemented using the mask shown in Fig. 3.39(a),\nFigure 11Filter mask used to implement the digital Laplacian, as defined in Eq. (4). (b) Mask used to implement an\nextension of this equation that includes the diagonal neighbors. (c) and (d) Two other implementations of the\nLaplacian.\nBecause the Laplacian is a derivative operator, its use highlights gray-leveldiscontinuities\nin an image and deemphasizes regions with slowly varying graylevels. This will tend to produce\nimages   that   have   grayish   edge   lines   and   otherdiscontinuities,   all   superimposed   on   a   dark,\nfeatureless   background.   Backgroundfeatures   can   be   “recovered”   while   still   preserving   the\nsharpening effect of the Laplacian operation simply by adding the original and Laplacian images.\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":21}}}],["ab4080f6-b427-4540-9cd9-c760509f9e09",{"pageContent":"22\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nAsnoted   in   the   previous   paragraph,   it   is   important   to   keep   in   mind   which   definition   of   the\nLaplacian is used. If the definition used has a negative center coefficient, then we subtract, rather\nthan add, the Laplacian image to obtain asharpened result.Thus, the basic way in which we use\nthe Laplacian for image enhancement is as follows:\n....(5)\nUnsharp masking and high-boost filtering\nA process used for many years in the publishing industry to sharpen imagesconsists of\nsubtracting a blurred version of an image from the image itself. This process, called  unsharp\nmasking, is expressed as\n....(7)\nwhere f\ns\n(x, y) denotes the sharpened image obtained by unsharp masking, andis a\nblurred version of f(x, y).The origin of unsharp masking is in dark room photography, where it\nconsists   of   clamping   together   a   blurred   negative   toa   corresponding   positive   film   and   then\ndeveloping this combination to producea sharper image.\nA slight further generalization of unsharp masking is called high-boostfiltering. A high-\nboost filtered image, fhb, is defined at any point (x, y) as\n.....(8)\nwhereA ≥ 1 and, as before, is a blurred version of f. This equation may be written as\n.....(9)\nBy using Eq. (7), we obtain\n.....(10)\nas   the   expression   for   computing   a   high-boost-filtered   image.   Equation   (10)   is   applicable   in\ngeneral and does not state explicitly howthe sharp image is obtained. If we elect to use the\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":22}}}],["728815be-0d56-437a-b617-0e2c75e0e104",{"pageContent":"23\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nLaplacian, then we know that  fs(x, y)  can be obtained using Eq. (5). In this  case, Eq. (10)\nbecomes\n...(11)\nUse of First Derivatives for Enhancement—The Gradient\nFirst   derivatives   in   image   processing   are   implemented   using   the   magnitude   ofthe\ngradient.   For  a   function   f(x,   y),   the   gradient   of  fat   coordinates   (x,  y)   is   definedas   the   two-\ndimensional column vector. \n...(12)\nThe magnitude of this vector is given by\n....(13)\nThe components of the gradient vector itself are linear operators, but the magnitudeof this\nvector obviously is not because of the squaring and square root operations. On the other hand,\nthe partial derivatives in Eq. (3.7-12) are not rotationinvariant (isotropic), but the magnitude of\nthe gradient vector is. Althoughit is not strictly correct, the magnitude of the gradient vector\noften isreferred to as the gradient.\nThe computational burden of implementing Eq. (13) over an entire imageis not trivial,\nand it is common practice to approximate the magnitude of the gradientby using absolute values\ninstead of squares and square roots:\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":23}}}],["7c5a141a-2522-4ff8-b769-ed66ad2161aa",{"pageContent":"24\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\n....(14)\nThis equation is simpler to compute and it still preserves relative changes in gray levels,\nbut the isotropic feature property is lost in general. However, as in the case of the Laplacian, the\nisotropic properties of the digital gradient defined in the following paragraph are preserved only\nfor a limited number of rotational increments that depend on the masks used to approximate the\nderivatives. As it turns out, the most popular masks used to approximate the gradient give the\nsame result only for vertical and horizontal edges and thus the isotropic properties of the gradient\nare preserved only for multiples of 90°. These results are independent of whether Eq. (13) or (14)\nis used, so nothing of significance is lost in using the simpler of the two equations. Two other\ndefinitions proposed by Roberts,  in the early development ofdigital image processing use cross\ndifferences:\n....(15)\nIf we elect to use Eq. (13), then we compute the gradient as\n......(16)\nIf we use absolute values, then substituting the quantities in Eq. (15)\ninto Eq. (14) gives us the following approximation to the gradient:\n.....(17)\nThese masks are referred to as the Roberts cross-gradient operators. Masks\nof even size are awkward to implement. The smallest filter mask in which we\nare interested is of size 3*3. An approximation using absolute values, still at\npoint z\n5\n , but using a 3*3 mask, is\n.......(18)\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":24}}}],["46705218-0dc9-4728-a654-360ab3bf40b2",{"pageContent":"25\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nFigure 12 A 3*3 region of an image (the z’s are gray-level values) and masks used to compute the gradient at point\nlabeled z5 . All masks coefficients sum to zero, as expected of a derivative operator.\nThe difference between the third and first rows of the 3*3 image region approximates the\nderivative in the x-direction, and the difference between the third and first columns approximates\nthe derivative in the y-direction. The masks shown in above, called the Sobel operators, can be\nused to implement Eq. (18) via the mechanics given in Eq. (1). The idea behind using a weight\nvalue of 2 is to achieve some smoothing by giving more importance to the center point. Note that\nthe coefficients in all the masks shown in Fig. 3.44 sum to 0, indicating that they would give a\nresponse of 0 in an area of constant gray level, as expected of a derivative operator.\nCombining Spatial Enhancement Methods\nFrequently, a given enhancement task will require application of several complementary\nenhancement techniques in order to achieve an acceptable result. In this section we illustrate by\nmeans of an example how to combine several of the approaches developed in this chapter to\naddress a difficult enhancement task.\nThe image shown in Fig. 13(a) is a nuclear whole body bone scan, used to detect diseases\nsuch as bone infection and tumors. Our objective is to enhance this image by sharpening it and\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":25}}}],["41885cb8-fcf5-4293-9323-9149edf69e22",{"pageContent":"26\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nby bringing out more of the skeletal detail. The narrow dynamic range of the gray levels and high\nnoise content make this image difficult to enhance. The strategy we will follow is to utilize the\nLaplacian to highlight fine detail, and the gradient to enhance prominent edges.\nFigure 13(b) shows the Laplacian of the original image. We can obtain a sharpened image\nat this pointsimply by adding Figs. 13(a) and (b), which are an implementation of the second line\nin Eq. (5) (we used a mask with a positive center coefficient). Just by looking at the noise level in\n(b), we would expect a rather noisy sharpened image if we added Figs. 13(a) and (b), a fact that\nis confirmed by the result shown in Fig. 13(c). One way that comes immediately to mind to\nreduce the  noise is  to use a median  filter. However, median filtering  is  a nonlinear process\ncapable of removing image features. This is unacceptable in medical image processing.\nFigure   13(d)   shows   the   Sobel   gradient   of   the   original   image,   computed   using   Eq.   (14).\nComponents Gx and Gy were obtained using the masks in Figs. 14(d) and (e), respectively. The\nfact that Figs. 13(d) and (e) are much brighter than Fig. 13(b) is again evidence that the gradient\nof   an   image   with   significant   edge   content   has   values   that   are   higher   in   general   than   in   a\nLaplacian image. The product of the Laplacian and smoothed-gradient image is shown in Fig.\n13(f). Note the dominance of the strong edges and the relative lack of visible noise, which is the\nkey objective behind masking the Laplacian with a smoothed gradient image. Adding the product\nimage to the original resulted in the sharpened image shown in Fig. 13(g).\nFigure 13: (a) Image of whole body bone scan. (b) Laplacian of (a). (c) Sharpened image obtained by adding (a) and\n(b). (d) Sobel of (a).\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":26}}}],["3940b15c-1c39-4192-8260-d4928c7314a3",{"pageContent":"27\nIMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                             \nModule 2\nFigure 13(Continued) (e) Sobel image smoothed with a 5*5 averaging filter. (f) Mask image formed by the product\nof (c) and (e). (g) Sharpened image obtained by the sum of (a) and (f). (h) Final result obtained by applying a power-\nlaw transformation to (g). Compare (g) and (h) with (a). (Original image courtesy of G.E. Medical Systems.)\nwritetokaranth@gmail.com1| rkk4691@gmail.com| VCET, Puttur\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 2 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.4","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE ENHANCEMENT IN THE SPATIAL DOMAIN                                                            Module 2","Author":"Sandesh","Creator":"Writer","Producer":"LibreOffice 4.2","CreationDate":"D:20180927091141+02'00'"},"metadata":null,"totalPages":27},"loc":{"pageNumber":27}}}],["38f97b24-3c61-4908-a316-5eb8ea8da4a5",{"pageContent":"1 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n \nModule 3 \nIMAGE ENHANCEMENT IN THE FREQUENCY \nDOMAIN  \nPrepared By, \nSandesha Karanth P.K & Raghavendra Katagall \nAssistant Professors, Dept. Of CSE, \nVCET, Puttur \n writetokaranth@gmail.com\n1\n, rkk4691@gmail.com\n2   \n   \nFourier series - Any function that periodically repeats itself can be expressed as the sum of sines \nand/or cosines of different frequencies, each multiplied by a different coefficient  \nFourier  transform - Even  functions  that  are  not  periodic  (but  whose  area  under  the  curve  is \nfinite)  can  be  expressed  as  the  integral  of  sines  and/or  cosines  multiplied  by  a  weighting \nfunction. \n The frequency  domain refers  to  the  plane  of  the  two  dimensional  discrete  Fourier \ntransform  of  an  image.  The  purpose  of  the  Fourier  transform  is  to  represent  a  signal  as  a  linear \ncombination of sinusoidal signals of various frequencies. \n \nFigure 1 The function at the bottom is the sum of the four functions above it. \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":1}}}],["76d06ba3-10eb-4afa-8e14-dcfdba1bbc80",{"pageContent":"2 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nPreliminary Concepts  \nComplex Number :                      ---- 3.1 \n         where R and I are real numbers, and j is an imaginary number equal to the square of -1.  \nConjugate of C:                        ---- 3.2 \nPolar Representation:                                           ---- 3.3  \n                                      Where                            is the magnitude  \n                                           is the angle between vector and the real axis.  \n Euler’s formula:                                   ----- 3.4 \n                                                          ---- 3.5 \n \nFourier Series \n A function f(t) of a continuous variable t that is periodic with period, T can be expressed \nas the sum of sines and co-sines multiplied by appropriate co-efficient.  \n   ----3.6 \nWhere     ----3.7 \nImpulses and Their Sifting Property \nImpulse: is a distribution or a generalised function. Sifting: to separate \nA unit impulse of a continuous variable t located at t=0, is defined as: \n---- 3.8a \njI\nR\nC\n+\n=\njI\nR\nC\n−\n=\n*\n)\nsin\n(cos\n|\n|\n\n\nj\nC\nC\n+\n=\n2\n2\n|\n|\nI\nR\nC\n+\n=\n\n\n\n\nsin\ncos\nj\ne\nj\n+\n=\nradianeEx\neCC\nj\nj\n1.1,31:=+\n=\n\n\n\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":2}}}],["f3d88898-e8f6-4ee9-b9d1-123a2b71dccb",{"pageContent":"3 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n And is constrained also to satisfy the identity   \n----3.8b \nAn impulse has the sifting property with respect to integration \n----3.9 \nWhere f(t) is continues at t=0, a condition typically satisfied in practice. A more general \nstatement of the sifting property involves an impulse located at an arbitrary point t\n0\n, denoted by \n휕(푡−푡0). In this case sifting properties becomes \n∫\n풇\n(\n풕\n)\n흏\n(\n풕−풕ퟎ\n)\n풅풕=풇(풕ퟎ)\n∞\n−∞\n ----3.10  \nLet x represent a discrete variable. The unit discrete impulse, 흏(x),  \n흏\n(\n풙\n)\n={ퟏ  풊풇 \n(\n풙=ퟎ\n)\n,ퟎ  풊풇(풙≠ퟎ)}-----3.11a \nThe impulse train is defined as the sum of infinitely many periodic impulses ∆T unit apart: \n푠∆푇\n(\n푡\n)\n=\n∑\n휕(푡−푛∆푇)\n∞\n푛=−∞\n-----3.14 \n \nThe Fourier Transform of Functions of One Continuous Variable  \nFourier transform of a continuous function f(t) of a continuous variable, t, is denoted by:  \n----3.15 \nFourier Transform may be written as, \n-----3.16 \nInverse Fourier transform can be written as, \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":3}}}],["925a2c48-45c2-4f51-aadc-686024d19cf2",{"pageContent":"4 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n-----3.17 \nUsing Eulers formula we can express eq 3.16 as \n---- 3.18 \nThe Fourier transform of the periodic impulse train s\n∆T\n(t), is  \n푆\n(\n휇\n)\n=\n푖\n∆푇\n∑\n휕(휇−\n푛\n∆푇\n)\n∞\n푛=−∞\n \nConvolution \nThe convolution of two functions, f(t) and h(t), of one continuous variable t is denoted by, \n----3.20 \n Where minus sign accounts for flipping, t is the displacement and 휏 is a dummy variable that is \nintegrated out.  \n \nSampling and the Fourier Transform of Sampled Functions \nSampling \n       Continues function have to be converted into a sequence of discrete  values before they  can \nbe processed in a computer. This is accomplished by sampling and quantization. With reference \nto  below  figure  consider  a  continues  function,  f(t),  that  we  wish  to  sample  at  uniform  intervals \n(∆T) of the independent variable t.  We assume  that the function extends from -∞ to  ∞ with \nrespect to t.  \n.....3.21 \nWhere 푓\ñ\n(t)  denotes  the  sampled  function. The  value  of  each  sample  is  given  by  strength  of  the \nweighted impulse, obtained by integration.  \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":4}}}],["15539018-5381-4b46-b46b-9d95b5dd8e3e",{"pageContent":"5 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n.........3.22 \n \nThe Fourier transform, of the sampled function f(t) is: \n.....3.23 \n \nThe Sampling Theorem \n A function f(t) whose Fourier transform is zero for values of frequencies outside a finite \ninterval(band)[-휇 푚푎푥,휇 푚푎푥] about the origin is called a band-limited function.  \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":5}}}],["09d74acc-55ca-4259-a924-a58b3c7c9e08",{"pageContent":"6 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n \n The  equation   \n1\n∆푇\n>2휇\nmax\n indicates  that  a  continues,  band  limited  function  can  be \nrecovered  completely  from  a  set  of  its  samples  if  the  samples  are  acquired  at  a  rate  exceeding \ntwice  the  highest  frequency  content  of  the  function.  This  result  is  known  as  the  sampling \ntheorem.  No  information  is  lost  if  a  continues,  band  limited  function  is  represented  by  samples \nacquired at a rate greater than twice the highest frequency content of the function. Conversely, it \ncan state that the maximum frequency that can be ‘captured’ by sampling a signal at a rate 1/∆T \nis 휇 \nmax \n= 1/2∆T.  \n   \nAliasing \n If  a  band  limited  function  is  sampled  at  a  rate  that  is  less  than  the  twice  its  highest \nfrequency  then  it  corresponds to  the  under-sampling. If  a  band  limited  function  is  sampled  at  a \nrate  that  is  equal  to  the  twice  its  highest  frequency  then  it  results  to  the  critical-sampling. If  a \nband limited function is sampled at a rate that is more than the twice its highest frequency then it \nresults to the over-sampling. \n The  effect  that  caused  by  under-sampling  a  function,  is  known  as  frequency  aliasing  or \nsimply  as  aliasing.  In  words,  aliasing  is  a  process  in  which  high  frequency  components  of  a \ncontinues  function  “masquerade”  as  lower  frequencies  in  the  sampled  function. Suppose,  we \nwant to limit the duration of a band-limited function f(t) to an interval, say [0, T]. We can do this \nby multiplying f(t) by the function, as shown below.  \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":6}}}],["cf84a54d-476e-4c3a-92c7-51807e2a8b6a",{"pageContent":"7 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nh(t) = {1    if 0≤ t ≤ T,    0   otherwise} \n \n If  the  transform  of  f(t)  is  the  band-limited,  convolving  it  with  H(휇),  which  involves \nsliding one function across the other, will yield a result with frequency components extending to \ninfinity.  Therefore,  no  function  of  finite  duration  can  be  band-limited.  Conversely,  a  function \nthat is band-limited must extend from -∞ to ∞.  \n In  practice,  the  effects  of  aliasing  can  be  reduced  by  smoothing  the  input  function  to \nattenuate  its  higher  frequencies.  This  process  is  called  anti-aliasing,  has  to  be  done  before  the \nfunction its sampled because aliasing is a sampling issue that cannot be “undone after the fact” \nusing computational technique. The below figure  shows the classic example of aliasing. A pure \nsign wave extending infinitely in both directions has a single frequency so, its band-limited and \nhaving  a  frequency  much  lower  than  the  frequency  of  the  continuous signal.  The period of  the \nsine  wave  is  2s,  so  the  zero  crossings  of  the  horizontal  axis  occur  every  second.  ∆T  is  the \nseparation between samples.  \n \nFunction reconstruction from sampled data   \n The  reconstruction  of  a  function  from  a  set  of  its  samples  reduces  in  practice  to \ninterpolating between the samples. Convolution is the central in developing this concept. Using \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":7}}}],["48c20087-dd8c-4e9f-849f-f9a8a40c1fcf",{"pageContent":"8 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nconvolution  theorem,  in  frequency  domain  we  can  obtain  the  equivalent result  spatial  domain. \nSo,   \n \n A spatial domain expression for f(t) is, \n \n \nThe Discrete Fourier Transform of One Variable \nObtaining  the  DFT  from  the  continuous  transform  of  a  sampled function, From  the \ndefinition of Fourier transform, we have, \n \nBy substituting Eq., we obtain, \n \nSuppose that we want to obtain M equally spaced samples of       퐹(휇)\ñ\n     Taken over the period  \n \nThis is accomplished by taking the samples at the following frequencies. \n \nSubstituting this result for 휇 into eq.(4.4-2) and letting F\nm\n denote the result yields  \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":8}}}],["e6bb445b-ba41-4f66-8780-eb61d20f488d",{"pageContent":"9 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n \nThe inverse Fourier transform is given by, \n \nEqns 4.4-4 and 4.4-5 become: \n \n \n \n \nRelationship between the Sampling and frequency intervals  \n If  f(x)  consists  of  M  samples  of  a  function  f(t)  taken ∆T  units  apart,  the  duration  of  the \nrecord comprising the set {f(x)}, x = 0,1,2,....,M-1, is \nT = M∆T .... \nThe corresponding spacing, ∆u, in the discrete frequency domain follows from eq. \n∆풖=\nퟏ\n풎∆푻\n=\nퟏ\n푻\n \nThe entire frequency range spanned by the M components of the DFT is  \nΩ=푴∆풖=\nퟏ\n∆푻\n \nExtension to Functions of Two variables \n2D impulse and its sifting properties: \nThe impulse, 휕\n(\n푡,푧\n)\n, of two continuous variables, t and z, is defined as  \n \nAnd \n \nAs in the 1-D case, the 2-D impulse exhibits the sifting property under integration. \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":9}}}],["443caad7-3095-4863-8f1d-e111daed4831",{"pageContent":"10 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n \nOr, more generally for an impulse located at coordinates (t\n0\n, z\n0\n) \n \nAs before, we see that the sifting property yields the value of the function f(t,z) at the location of \nthe impulse.  \n For discrete variables x and y, the 2-D discrete impulse is defined as \n \nAnd its sifting properties is  \n \nWhere f(x,y) is a function of discrete variables x and y. For an impulse located at coordinates (x\n0, \ny\n0\n) the sifting property is  \n \nAs  before,  the  sifting  property  of  a  discrete  impulse  yields  the  value  of  the  discrete  function \nf(x,y) at location of the impulse.  \n \nFigure: Two dimensional unit discrete impulse.  \n \nThe 2-D Continuous Fourier Transform Pair \n Let  f(t,z)  be  a  continuous  function  of  two  continuous  variables,  t  and  z.  The  two-\ndimensional, continuous Fourier transform pair is given by the expressions \n \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":10}}}],["bef6eeee-2440-434b-b76a-8e2dbb6de18c",{"pageContent":"11 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nAnd  \n \nWhere 휇 and v are the frequency variables. When referring to images, t and z are interpreted to \nbe continuous spatial variables. As in the 1-D case, the domain of the variables 휇 and v defines \nthe continuous frequency domain. \n \n \nFigure: a. 2-D function and b. Section of its spectrum \nTwo dimensional sampling and Two dimensional sampling theorem \n In a  manner  similar  to  the 1-D  case,  sampling  in  two  dimensions  can  be  modeled  using \nthe sampling function (2-D impulse train): \n \n Where ∆T and ∆Z are the separations between samples along the t- and  z- axis  of  the \ncontinuous function f(t, z).  \n \nFigure : 2D impulse train \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":11}}}],["f557ca85-1ad8-47aa-a19e-1a325b659ea6",{"pageContent":"12 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n Function f(t, z) is said to be band-limited if its Fourier transform is 0 outside a rectangle \nestablished by the intervals [-μ\nmax\n, μ \nmax\n] and [-V\nmax, \nV\nmax\n]; that is,\n \n \n The  two-dimensional  sampling  theorem  states  that  a  continuous,  band-limited  function \nf(t,z) can be recovered with no error from a set of its samples if the sampling intervals are  \n∆푇 <\n1\n2휇 푚푎푥\n \nAnd  \n∆푍 <\n1\n2푣 푚푎푥\n \nThe 2-D Discrete Fourier Transform and its inverse  \n The 2-D discret Fourier transform(DFT): \n \nWhere f(x,y) is a digital image of size M X N. and variable u and v in the ranges u = 0,1,2,....M-\n1 and v = 0,1,2,....N-1.  \n Given  the transform  F(u,v),  we  can  obtain  f(x,y)  by  using  the  inverse  discrete  Fourier \ntransform (IDFT): \n \nFor x = 0, 1,2,...M-1 and y=0, 1,2,3,...N-1.    \n \nProperties of 2D Fourier Transform  \nRelationships between Spatial and Frequency Intervals  \nF(t, z) sampled from f(x, y) using the separation between separation between samples as ∆T and \n∆Z.  Then,  the  separations  denote  the  corresponding  discrete,  frequency  domain variables are \ngiven by, \n \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":12}}}],["6072bfda-92f2-4829-baad-db7cf066c23a",{"pageContent":"13 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nNote:  The  separation  between  samples  in  the  frequency  domain  are  inversely  proportional  both \nto the spacing between spatial samples and the number of samples.  \n \nTranslation and Rotation \n        Multiplying f(x,y) by the exponential shifts the original of DFT to (u\n0\n, v\n0\n).  \n Multiplying F(u,v) by the exponential shifts the original of (x,y) to (x\n0\n, y\n0\n).  \n \n \nPeriodicity \n The  Fourier  transform  and  inverse  are  infinitely  periodic  on  the  u  and  v  directions.  (k1 \nand k2 are integers).   \n \n To show the origin of F(u,v) at the center we shift the data by M/2 and N/2 \n \nSymmetry  \n Any real or complex any complex function can be expressed as sum of odd and even part \n \nThis shows that even functions are symmetric and odd functions are anti-symmetric  \n \n The Fourier transform of a real function f(x,y) is conjugate symmetric \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":13}}}],["36a83146-4e0c-4a71-9691-a522d3f9c56a",{"pageContent":"14 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n \nThe Fourier transform of a imaginary function f(x,y) is conjugate anti-symmetric \n \nProof \n \nFrequency Domain Filtering \n Filtering techniques in frequency domain are based on modifying the Fourier transform to \nachieve  a  specific  objective  and  then  computing  the  inverse  DFT  to  get  us  back  to  the  image \ndomain. Steps involved in the process of filtering in the frequency domain are as follows.      \n1. Compute the Fourier Transform of the image \n2. Multiply the result by filter transfer function \n3. Take the inverse transform \n \nSummary of steps involved for filtering in the Frequency Domain \n1. Given an input f(x,y) of size M X N, obtain the padding parameters P and Q. Typically, \nwe select P = 2M and Q= 2N. \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":14}}}],["11f79481-57c1-406b-9ad5-64b46b17bb53",{"pageContent":"15 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n2. Form  a  padding  image,  f\np \n(x,  y),  of  size  P  X  Q  by  appending  the  necessary  number  of \nzeros to f(x, y).  \n3. Multiply f\np \n(x, y) by (-1)\nx+y \nto center its transform \n4. Compute the DFT, F(u, v), of the image from step 3. \n5. Generate  a  real,  symmetric  filter  function,  H(u,  v),  of  size  P  X  Q  with  center  at \ncoordinates  (P/2,  Q/2).  From  the  product  G(u,  v)  =  H(u,  v)  F(u,  V)  using  array \nmultiplication; that is, G(i, k) = H(i, k) F(i, k).  \n6. Obtain the processed image; \n \n7. Obtain  the  final  processed  result,  g(x,  y),  by  extracting  the  M  X  N  region  from  the  top, \nleft quadrant of g\np \n(x, y).   \n \nSmoothing Frequency Domain Filters \n Smoothing  is  achieved  in  the  frequency  domain  by  dropping  out  the  high  frequency \ncomponents. The basic model for filtering is: \n  G(u,v) = H(u,v)F(u,v) \nwhere F(u,v) is the Fourier transform of the image being filtered and H(u,v) is the filter transform \nfunction.  \nLow pass filters – only pass the low frequencies, drop the high ones.  \nIdeal Low Pass Filter \n Changing  the  distance  changes  the  behaviour  of  the  filter.  The  transfer  function  for  the \nideal low pass filter can be given as: \n \n \n \nwhere D\n0 \nis a positive constant and  D(u,v) is the distance between a point (u, v) in the frequency \ndomain and the centre of the frequency rectangle; that is, \n \n  \nWhere, as before, P and Q are the padded sizes.  \n\n\n\n\n\n=\n0\n0\n),( if  0\n),( if  1\n),(\nDvuD\nDvuD\nvuH\n2\n/\n1\n2\n2\n]\n)\n2\n/\n(\n)\n2\n/\n[(\n)\n,\n(\nN\nv\nM\nu\nv\nu\nD\n−\n+\n−\n=\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":15}}}],["fb0d67a1-93d7-4b8c-9df3-942350793e9a",{"pageContent":"16 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n The name ideal indicates that all frequencies on or inside a circle of radius D\n0 \nare passed \nwithout  attenuation,  where  as  all  frequencies  outside  the  circle  are  completely  attenuated.  The \nideal  lowpass  filter  is  rapidly  symmetric  about  the  origin,  which  means  that  the  filter  is \ncompletely defined by radial cross section by 360\n0 \nyields the filter in 2-D.  \n \nFigure : a. Perspective plot of an ideal lowpass-filter transfer function b. Filter defined as image c. Filter radial cross section  \n For an  ILPF cross section, the point of transition between H(u,v) = 1 and  H(u, v) = 0 is \ncalled the cutoff frequency.  \nButterworth Lowpass Filters \n The transfer function of a Butterworth low pass filter of order n with cut-off  frequency at \ndistance D\n0\n from the origin is defined as:  \n \n \n \nFigure : a. Perspective plot of an Butterworth lowpass-filter transfer function b. Filter defined as image c. Filter radial cross \nsections of order 1 through 4.   \n Unlike the ILPF, the BLPF transfer function does not have sharp discontinuity that gives \na clear cutoff between passed and filtered frequencies.   \nGaussian Lowpass Filters \nGaussian lowpass filters (GLPFs) of two dimensions is given by \n2/),(\n2\n),(\nvuD\nevuH\n−\n=\n  휎\n2 \nn\nD\nv\nu\nD\nv\nu\nH\n2\n0\n]\n/\n)\n,\n(\n[\n1\n1\n)\n,\n(\n+\n=\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":16}}}],["4dae509b-e207-4b07-a8b1-624053d154c0",{"pageContent":"17 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nWhere D(u,v) is the distance from the centre of the frequency rectangle. 휎 is a measure of \nspread about the centre  By letting 휎 = D\n0 \n, The transfer function of a Gaussian lowpass filter is \ndefined as:  \n \n \nFigure : a. Perspective plot of an Gaussian lowpass-filter transfer function b. Filter defined as image c. Filter radial cross \nsections for various values of D\n0 \nSharpening in the Frequency Domain Filters using highpass filter   \nEdges  and fine  detail  in  images  are  associated  with  high  frequency  components hence \nimage sharpening can achieved in the frequency  domain by highpass filtering, which  attenuates \nthe  low  frequency  components  without  disturbing  high  frequency  information  in  the  Fourier \ntransform.   \n \nHigh pass filters – only pass the high frequencies, drop the low ones \nHigh pass frequencies are precisely the reverse of low pass filters, so: \nH\nhp\n(u, v) = 1 – H\nlp\n(u, v) \nIdeal High Pass Filters \nThe ideal high pass filter is given by: \n \n \nWhere D\n0\n is the cut off frequency.  \n \n                             Figure : a. Perspective plot, image representation and cross section of a typical ideal highpass filter \n2\n0\n2\n2\n/\n)\n,\n(\n)\n,\n(\nD\nv\nu\nD\ne\nv\nu\nH\n−\n=\n\n\n\n\n\n=\n0\n0\n)\n,\n(\n \nif\n  \n1\n)\n,\n(\n \nif\n  \n0\n)\n,\n(\nD\nv\nu\nD\nD\nv\nu\nD\nv\nu\nH\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":17}}}],["c3f05619-6f18-4a76-9353-db67425a8aa9",{"pageContent":"18 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nButterworth High Pass Filters \nThe Butterworth high pass filter is given as: \n \n \nn is the order and D\n0\n is the cut off distance as before.  \n \nFigure : Butterworth high pass filter  \nGaussian High Pass Filters \nThe Gaussian high pass filter is given as: \n \nWhere D\n0\n is the cut off distance as before.  \n \nFigure : Gaussian Highpass Filters   \nThe Discrete Cosine Transform  \n The N X N cosine transform matrix C={c(k,n)}, also called the discrete cosine \ntransform(DCT), is defined as \n \nThe one dimensional DCT of a sequence {u(n), 0 ≤ K ≤N-1} is defined as  \nn\nv\nu\nD\nD\nv\nu\nH\n2\n0\n)]\n,\n(\n/\n[\n1\n1\n)\n,\n(\n+\n=\n2\n0\n2\n2\n/\n)\n,\n(\n1\n)\n,\n(\nD\nv\nu\nD\ne\nv\nu\nH\n−\n−\n=\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":18}}}],["075152d1-4757-4f20-a72a-674cc7886886",{"pageContent":"19 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n \nThe inverse transformation is given by \n \nProperties of DCT: \n1. The cosine transform is real and orthogonal, i.e  \nC=C\n* \n          C\n-1\n = C\nT \n2. The cosine transform is not the real part of the unitary DFT. \n3. The cosine transform is a fast transform. The cosine transform of a vector of N elements \ncan be calculated in O(N log2 N). \n4. The basis vector of the sine transform is the eigenvectors of the symmetric tridiagonal \ntoeplize matrix.  \n \n5. The  sine  transform  is  close  to  the  KL  transform  of  first  order  stationary  markov \nsequences,  when  the  correlation  parameter 휌 lies  in  the  interval  (-0.5,  0.5).  In  general  it \nhas very good to excellent energy compaction property for images.  \n6. The sine transform leads to a fast transform algorithm for mark 0v sequences, whose \nboundary values are given. This makes it useful in many image processing problems.  \n \nProbable university exam questions \n1. Explain the process of obtaining the Discrete Fourier transform from the continuous \ntransform of a sampled function. (Pg. No: 8) \n2. Derive the relationship between the sampling and frequency intervals (Pg. No: 9) \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":19}}}],["d0a3631f-f000-4dc7-998e-7a33f945740b",{"pageContent":"20 \nIMAHE ENHANCEMENT IN THE FREQUENCY DOMAIN                                                     Module 3                                                           \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n3. Explain the properties of the 2D Discrete Fourier transform (Pg. No: 12 & 13) \n4. Explain the following with relevant equations \na.  The 2D discrete Fourier transform and its inverse. (Pg. No: 12) \nb. The 2D continuous Fourier transform pair (Pg. No: 10) \n5. Explain Image smoothing and Image sharpening in frequency domain.(Pg.No: 15 & 16) \n6. Explain the steps for filtering in frequency domain in detail. (Pg. No: 14) \n7. Explain Discrete Cosine Transform. (Pg. No: 18 & 19) \n8. Explain 1-D impulses and their sifting property. (Pg. No: 2 & 3)  \n9. Sampling and the Fourier Transform of Sampled Functions (Pg. No: 4, 5 & 6) \n10. Explain aliasing (Pg. No: 6 & 7) \n11. Explain 2-D impulses and their sifting property. (Pg. No: 9 & 10) \n12. Sharpening in the Frequency Domain Filters using highpass filter  (Pg. No: 17 & 18) \n \n \n \n \n \n \n \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 3 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"Microsoft® Word for Office 365","Producer":"Microsoft® Word for Office 365","CreationDate":"D:20181102083847+00'00'","ModDate":"D:20181102083847+00'00'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® Word for Office 365","xmp:creatortool":"Microsoft® Word for Office 365","xmp:createdate":"2018-11-02T08:38:47+00:00","xmp:modifydate":"2018-11-02T08:38:47+00:00","xmpmm:documentid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1","xmpmm:instanceid":"uuid:2A59F63A-C62E-4255-8294-D5E3D6D1FDF1"}},"totalPages":20},"loc":{"pageNumber":20}}}],["522b47b3-640b-44b5-b5eb-757f0d26a181",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":1}}}],["37efa081-ec3f-4832-ae23-22c3092f789e",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":2}}}],["9364a9bd-6d59-46c2-a958-9730ab6860d1",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":3}}}],["0850e6be-ecab-4683-bf46-082930d1814a",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":4}}}],["cd450669-ab27-4677-ad58-5923adf97d4f",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":5}}}],["3889cd46-ffba-4b0b-a684-38e7177920a4",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":6}}}],["7ff7adcb-2dda-46f7-9834-8a702622a205",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":7}}}],["11c692d2-ee2f-4cee-b750-3271374dd66e",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":8}}}],["79754afd-af4f-4ec1-9296-5e6688d69bb1",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":9}}}],["e792cb4d-26ad-4665-80b7-6c98df35eb22",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":10}}}],["79185277-0335-4eff-ad7a-ad8ec62cf46d",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":11}}}],["3c14f053-27df-49e8-8a92-bdffa254e163",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":12}}}],["b99b9ead-877c-4508-a76f-03143d99dba1",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":13}}}],["5f2f134a-1183-4f6e-a394-cf7f5405f615",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":14}}}],["d15e9fe4-8960-4650-b299-94f269cfd7c4",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":15}}}],["2f21d0c4-a101-4826-acbf-3fc19e326c95",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":16}}}],["a69d4797-dc0a-4cc8-994d-55b03d25f27e",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":17}}}],["e77d6462-57d9-40c7-9d7f-194086aef383",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":18}}}],["31dd48aa-3412-4228-a65e-bd2deda621e6",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":19}}}],["25a6f1b3-f288-46b9-891a-5f0468912fe4",{"pageContent":"Scanned by CamScanner\nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module 4 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"New Doc 2018-11-04","Author":"CamScanner","Subject":"New Doc 2018-11-04","Keywords":"","Producer":"intsig.com pdf producer","ModDate":""},"metadata":null,"totalPages":20},"loc":{"pageNumber":20}}}],["36bb5cdc-19b3-4206-8a04-401aee8b05e2",{"pageContent":"1 \nIMAGE COMPRESSION                                                                                                                Module 5 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nModule 5 \nIMAGE COMPRESSION   \nPrepared By, \nSandesha Karanth P.K & Raghavendra Katagall \nAssistant Professors, Dept. Of CSE, \nVCET, Puttur \n writetokaranth@gmail.com\n1\n, rkk4691@gmail.com\n2   \n   \n Image compression is the art and science of reducing amount of data required to represent \nan  image. Image  compression  is  used  in  many  applications  like  televideo  conferencing,  remote \nsensing, document and medical imaging, and facsimile transmission (FAX).  \nFundamentals:  \n The  data  compression  refers  to  the  process  of  reducing  the  amount  of  data  required to \nrepresent  a  given  quantity  of  information.  Here  data  and  information  are  not  the  same,  data  are \nthe mean by which information is conveyed and various amounts of data can be used to represent \nthe same amount of information. The data can have irrelevant or repeated information are called \nredundant data.  \n  If    we  let  b  and  b’  denote    the number  of  bits  in  two  representations  of  the  same  \ninformation, the relative data redundancy R of the representation with b bits is  \n      R = 1 – 1/C  \nWhere C, commonly called the compression ratio, is defined as  \n      C = b/b’  \nThe principle types of data redundancy that can be identified as: \n1. Coding  redundancy:  A  code  is  a  system  of  symbols  used  to  represent  a  body  of \ninformation or set of events. Each piece of information or event is assigned a sequence of \ncode  symbols,  called  a  code  word.  The  number  of  symbols  in  each  code  word  is  its \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 5 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE COMPRESSION                                                                                                                Module 5","Author":"Sandesh","Creator":"","Producer":"https://www.convertapi.com","CreationDate":"D:20190102082430+02'00'","ModDate":"D:20190102082432+02'00'"},"metadata":{"_metadata":{"pdf:keywords":"","pdf:producer":"Neevia Document Converter Pro v6.9 (http://neevia.com)","xmp:modifydate":"2019-01-02T08:24:31+02:00","xmp:createdate":"2019-01-02T08:24:30+02:00","xmp:metadatadate":"2019-01-02T08:24:30+02:00","xmp:creatortool":"Microsoft Word v16","dc:format":"application/pdf","dc:description":"","dc:creator":"Sandesh","dc:title":"IMAGE COMPRESSION                                                                                                                Module 5","xmpmm:documentid":"uuid:E63D66EB-5161-79E5-9E42-1B84BBBFF02C","xmpmm:instanceid":"uuid:5ED754A9-D84B-1B4A-CE2D-4F072FC497B9"}},"totalPages":14},"loc":{"pageNumber":1}}}],["39cc35da-35f8-4217-8a8a-092625e31cc0",{"pageContent":"2 \nIMAGE COMPRESSION                                                                                                                Module 5 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nlength. The  8-bit  codes  that  are  used  to  represent  the  intensities  in  most  2-D  intensity \narrays contain more bits than are needed to represent the intensities.  \n2. Spatial  and  temporal  redundancy: Because  the  pixels  of  most  2-D  intensity  arrays  are \ncorrelated  specially,(i.e.  each  pixel  is  similar  to  or  dependent  on  neighboring  pixels \nInformation is unnecessarily replicated in the representations of the correlated pixels. In a \nvideo sequence, temporally correlated pixels also duplicate information \n3. Irrelevant information:  Most  2-D  intensity  arrays contain  information  that  is  ignored  by \nhuman visual system and/or extraneous to the intended use of the image.  It is redundant \nin the sense that it is not used.  \n \nCoding Redundancy \nLet us assume, that a discrete random variable rk in the interval [0,L-1] represent the gray \nlevel of an M x N  image and that each r\nk\n occurs with probabilities p\nr\n(r\nk\n): \nP\nr \n(r\nk\n) = n\nk \n/ MN      k=0,1,2,3...L-1. \nWhere  L  is  the  number  of  intensity  values,  and  n\nk\n is  the  number  of  times  that  the  k\nth\n intensity \nappears  in  the  image. If  the  number  of  bits  used  to  represent  each  value  of rk is l(rk),  then  the \naverage number of bits required to represent each pixel: \n \nThe total number bits required to code an MxN image: \n \n \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 5 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE COMPRESSION                                                                                                                Module 5","Author":"Sandesh","Creator":"","Producer":"https://www.convertapi.com","CreationDate":"D:20190102082430+02'00'","ModDate":"D:20190102082432+02'00'"},"metadata":{"_metadata":{"pdf:keywords":"","pdf:producer":"Neevia Document Converter Pro v6.9 (http://neevia.com)","xmp:modifydate":"2019-01-02T08:24:31+02:00","xmp:createdate":"2019-01-02T08:24:30+02:00","xmp:metadatadate":"2019-01-02T08:24:30+02:00","xmp:creatortool":"Microsoft Word v16","dc:format":"application/pdf","dc:description":"","dc:creator":"Sandesh","dc:title":"IMAGE COMPRESSION                                                                                                                Module 5","xmpmm:documentid":"uuid:E63D66EB-5161-79E5-9E42-1B84BBBFF02C","xmpmm:instanceid":"uuid:5ED754A9-D84B-1B4A-CE2D-4F072FC497B9"}},"totalPages":14},"loc":{"pageNumber":2}}}],["19f182a1-deef-441e-a23f-0f4398913586",{"pageContent":"3 \nIMAGE COMPRESSION                                                                                                                Module 5 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n \nInterpixel redundancy \nInterpixel redundancy is defined as failure to identify and utilize data relationships \nIf  a  pixel  value  can  be  reasonably  predicted  from  its  neighboring  (or  preceeding /  following) \npixels the image is said to contain interpixel redundancy. Interpixel redundancy depends on the \nresolution  of  the  image The  higher  the  (spatial)  resolution  of  an  image,  the  more  probable  it  is \nthat two  neighboring  pixels  will  depict  the  same  object. The  higher  the  frame  rate  in  a  video \nstream, the more probable it is that the corresponding pixel in the following frame will depict the \nsame object these types of predictions are made more difficult by the presence of noise \n \nImage Compression Model \n The  following  figure  shows  an  image  compression  system  is  composed  of  two  distinct \nfunctional  components:  an  encoder  and  decoder.  The  encoder  performs  compression    and \ndecoder  performs  the  complementary  operation  of  decompression.  Both  operations  can  be \nperformed in software.  \n Input  image is  fed  into  the  encoder,  which  creates  a  compressed  representation  of  the \ninput.  When  the  compressed  representation  is presented  to  its  complementary  decoder,  a \nreconstructed image is generated.  \n \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 5 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE COMPRESSION                                                                                                                Module 5","Author":"Sandesh","Creator":"","Producer":"https://www.convertapi.com","CreationDate":"D:20190102082430+02'00'","ModDate":"D:20190102082432+02'00'"},"metadata":{"_metadata":{"pdf:keywords":"","pdf:producer":"Neevia Document Converter Pro v6.9 (http://neevia.com)","xmp:modifydate":"2019-01-02T08:24:31+02:00","xmp:createdate":"2019-01-02T08:24:30+02:00","xmp:metadatadate":"2019-01-02T08:24:30+02:00","xmp:creatortool":"Microsoft Word v16","dc:format":"application/pdf","dc:description":"","dc:creator":"Sandesh","dc:title":"IMAGE COMPRESSION                                                                                                                Module 5","xmpmm:documentid":"uuid:E63D66EB-5161-79E5-9E42-1B84BBBFF02C","xmpmm:instanceid":"uuid:5ED754A9-D84B-1B4A-CE2D-4F072FC497B9"}},"totalPages":14},"loc":{"pageNumber":3}}}],["ae80cfc9-c039-4e41-9294-3da8e75cf8d8",{"pageContent":"4 \nIMAGE COMPRESSION                                                                                                                Module 5 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n \n \n Mapper - transforms  the  image  to  a  (non-visual)  format  designed  to  reduce interpixel \nredundancies.  The  operation  generally  is  reversible  and  may  or  may  not  reduce  directly \nthe amount of data required to represent the image. In video applications, the mapper uses \nprevious video frames to facilitate the removal of temporal redundancy.  \n Quantizer - reduces   psychovisual   redundancies   by   quantizing   data   deemed less \nimportant for visual interpretation (omitted for lossless compression) \n Symbol  encoder - codes  the  data  efficiently  (typically  using  some  form  of variable-\nlength  coding  scheme)  and  aims  to  reduce  coding  redundancies.  It  generates  a  fixed  or \nvariable length code to represent the quantizer output and maps the output in accordance \nwith  the  code.  In  many  cases,  a  variable –length  code  is  used.  The  shortest  code  words \nare  assigned  to  the  most  frequently occurring  quantizer  output  values- thus  minimizing \ncoding redundancy.   \n• Future application requirements may be unknown \n \nSome Basic Compression Methods  \nHuffman coding \nProvides  a  data  representation  with  the  smallest  possible  number  of  code symbols  per \nsource symbol (when coding the symbols of an information source individually) \nHuffman code construction is done in two steps \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 5 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE COMPRESSION                                                                                                                Module 5","Author":"Sandesh","Creator":"","Producer":"https://www.convertapi.com","CreationDate":"D:20190102082430+02'00'","ModDate":"D:20190102082432+02'00'"},"metadata":{"_metadata":{"pdf:keywords":"","pdf:producer":"Neevia Document Converter Pro v6.9 (http://neevia.com)","xmp:modifydate":"2019-01-02T08:24:31+02:00","xmp:createdate":"2019-01-02T08:24:30+02:00","xmp:metadatadate":"2019-01-02T08:24:30+02:00","xmp:creatortool":"Microsoft Word v16","dc:format":"application/pdf","dc:description":"","dc:creator":"Sandesh","dc:title":"IMAGE COMPRESSION                                                                                                                Module 5","xmpmm:documentid":"uuid:E63D66EB-5161-79E5-9E42-1B84BBBFF02C","xmpmm:instanceid":"uuid:5ED754A9-D84B-1B4A-CE2D-4F072FC497B9"}},"totalPages":14},"loc":{"pageNumber":4}}}],["d6af3470-48c2-44ac-a8b3-c6866389036b",{"pageContent":"5 \nIMAGE COMPRESSION                                                                                                                Module 5 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n1. Source  reductions: Create  a  series  of  source  reductions  by  ordering  the  probabilities \nof  the symbols  and  then  combine  the  symbols of  lowest  probability  to  form  new \nsymbols recursively. This step is sometimes referred to as “building a Huffman tree” \nand can be done statistically \n \nFigure: Huffman source reduction   \n2. Code assignment: When only two symbols remain, retrace the steps in 1) and assign a \ncode bit  to  the  symbols  in  each  step. Encoding  and  decoding  is  done  using  these \ncodes in a lookup table manner \n \n \nFigure: Huffman code assignment procedure \nThe average length of this code is:  L\navg\n = (0.4)(1) + (0.3)(3) + (0.1)(4) + (0.06)(5) + (0.04)(5)         \n=2.2bits/pixels  \nArithmetic coding \nProvides  a  data  representation  where  the  entire  symbol  sequence  is  encoded as  a  single \narithmetic code word (which is represented as an interval of real numbers between 0 and 1) \nArithmetic code construction is done in 3 steps \n1. Subdivide the half-open interval [0,1) based on the probabilities of the source symbols \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 5 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE COMPRESSION                                                                                                                Module 5","Author":"Sandesh","Creator":"","Producer":"https://www.convertapi.com","CreationDate":"D:20190102082430+02'00'","ModDate":"D:20190102082432+02'00'"},"metadata":{"_metadata":{"pdf:keywords":"","pdf:producer":"Neevia Document Converter Pro v6.9 (http://neevia.com)","xmp:modifydate":"2019-01-02T08:24:31+02:00","xmp:createdate":"2019-01-02T08:24:30+02:00","xmp:metadatadate":"2019-01-02T08:24:30+02:00","xmp:creatortool":"Microsoft Word v16","dc:format":"application/pdf","dc:description":"","dc:creator":"Sandesh","dc:title":"IMAGE COMPRESSION                                                                                                                Module 5","xmpmm:documentid":"uuid:E63D66EB-5161-79E5-9E42-1B84BBBFF02C","xmpmm:instanceid":"uuid:5ED754A9-D84B-1B4A-CE2D-4F072FC497B9"}},"totalPages":14},"loc":{"pageNumber":5}}}],["8d9f6bba-2b5d-4fa0-9c22-4033d540445d",{"pageContent":"6 \nIMAGE COMPRESSION                                                                                                                Module 5 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n2. For each source symbol recursively. Narrow the interval to the sub-interval designated by \nthe  encoded  symbol. Subdivide  the  new  interval  among  the  source  symbols  based  on \nprobability \n3. Append  an  end-of-message  indicator. Encoding  is  done  by  choosing  any  number  in  the \ninterval  to represent  the  data. Decoding  is  done  by  retracing  the  steps  in  the  code \nconstruction \n \nFigure : Arithmetic coding procedure. \n \nFigure : Arithmetic coding example.  \nLempel-Ziv-Welch (LZW) coding \nProvides  a  data  representation  where  fixed-length  code  words  are  assigned  to variable \nlength  sequences  of  source  symbols. LZW  reduces both  coding  redundancies  as  well  as \ninterpixel  redundancies  and requires  no  knowledge  of  the  source  symbol  probabilities. LZW \ncode  construction  is  done  by  constructing  a  dictionary  which  translates encountered  source \nsymbol  sequences  to  code  symbols. This dictionary  is  created  as  the  data  stream  is  being \nprocessed  and  can  be flushed  (reinitialized)  when  it  is  full  or  when  coding  ratios  decline. The \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 5 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE COMPRESSION                                                                                                                Module 5","Author":"Sandesh","Creator":"","Producer":"https://www.convertapi.com","CreationDate":"D:20190102082430+02'00'","ModDate":"D:20190102082432+02'00'"},"metadata":{"_metadata":{"pdf:keywords":"","pdf:producer":"Neevia Document Converter Pro v6.9 (http://neevia.com)","xmp:modifydate":"2019-01-02T08:24:31+02:00","xmp:createdate":"2019-01-02T08:24:30+02:00","xmp:metadatadate":"2019-01-02T08:24:30+02:00","xmp:creatortool":"Microsoft Word v16","dc:format":"application/pdf","dc:description":"","dc:creator":"Sandesh","dc:title":"IMAGE COMPRESSION                                                                                                                Module 5","xmpmm:documentid":"uuid:E63D66EB-5161-79E5-9E42-1B84BBBFF02C","xmpmm:instanceid":"uuid:5ED754A9-D84B-1B4A-CE2D-4F072FC497B9"}},"totalPages":14},"loc":{"pageNumber":6}}}],["71f894fb-fde5-4673-8f0a-0d68493dbce6",{"pageContent":"7 \nIMAGE COMPRESSION                                                                                                                Module 5 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nsize  of  the  dictionary  affects  compression  performance. Small  dictionaries  are  less  likely  to \ncontain  an  encountered  source  symbol. Large  dictionaries  results  in  larger  code  words  (lower \ncompression ratios) \n \n \n \n \nFigure : LZW coing example \nRun-length coding \nProvides  a  data  representation  where  sequences  of  symbol  values  of  the  same value  are \ncoded as “run-lengths” \n• 1D – the image is treated as a row-by-row array of pixels \n• 2D – blocks of pixels are viewed as source symbols \nInput data       222222222226666666666666699999999999999999 \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 5 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE COMPRESSION                                                                                                                Module 5","Author":"Sandesh","Creator":"","Producer":"https://www.convertapi.com","CreationDate":"D:20190102082430+02'00'","ModDate":"D:20190102082432+02'00'"},"metadata":{"_metadata":{"pdf:keywords":"","pdf:producer":"Neevia Document Converter Pro v6.9 (http://neevia.com)","xmp:modifydate":"2019-01-02T08:24:31+02:00","xmp:createdate":"2019-01-02T08:24:30+02:00","xmp:metadatadate":"2019-01-02T08:24:30+02:00","xmp:creatortool":"Microsoft Word v16","dc:format":"application/pdf","dc:description":"","dc:creator":"Sandesh","dc:title":"IMAGE COMPRESSION                                                                                                                Module 5","xmpmm:documentid":"uuid:E63D66EB-5161-79E5-9E42-1B84BBBFF02C","xmpmm:instanceid":"uuid:5ED754A9-D84B-1B4A-CE2D-4F072FC497B9"}},"totalPages":14},"loc":{"pageNumber":7}}}],["1c4b63d9-5486-4bf8-b750-d9d99289b960",{"pageContent":"8 \nIMAGE COMPRESSION                                                                                                                Module 5 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nCode               2,11 6,14 9,17 \n Here  compression  is  achieved  by  eliminating    a  simple  form  of  spatial  redundancy – \ngroups of identical intensities. When there are few runs of identical pixels, run length encoding \nresults  in  data  expansion.  The  BMP  file  format  uses  a  form  of  rum-length  encoding  In  which \nimage data is represented in two different modes :  \n1. Encoded  mode – A  two  byte  RLE  representation  is  used.  The  first  byte  specifies  the \nnumber of consecutive pixels that have the color index contained in the second byte. The \n8 bit color index selects the run’s intensity from a table of 256 possible intensities. \n2. Absolute mode – The first byte here is 0 and the second byte signals one of four possible \nconditions, as shown in below table.  \n \nFigure : BMP absolute coding mode options. In this mode, the first byte of the BMP pair is 0 \nTransform Coding \nIn  transform  coding  a  linear  transform  is  used  to  map  the  image  data  into  a  set of \ntransform  coefficients  (which  are  then  quantized  and  coded). For  reasons  of  computational \ncomplexity   the   image   is subdivided   into   smaller subimages   before   the   transformation \ncomputation. The goal of the transformation process is to decorrelate (minimize the variance) \nthe  pixels  of  the  subimages  as  much  as  possible. This  will  result  in  a  localization  of  the  image \ninformation in a minimal number of transform coefficients - the transformation coefficients with \nlittle data can then be more coarsely quantized or eliminated. The better information compaction, \nthe better reconstruction approximations.   \n The following figure shows a typical block transform coding system. The decoder \nimplements  the  inverse  sequence  of  steps  of  the  encoder,  which  performs  four  relatively \nstraightforward  operations:  subimage  decomposition,  transformation,  quantization,  and  coding. \nM x N input image is subdivided first into subimages of size n X n, which are then transformed \nto  generate  MN/n\n2\n subimage  transform  arrays,  each  of  size  n  X  n.  The  quatization  stage  then \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 5 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE COMPRESSION                                                                                                                Module 5","Author":"Sandesh","Creator":"","Producer":"https://www.convertapi.com","CreationDate":"D:20190102082430+02'00'","ModDate":"D:20190102082432+02'00'"},"metadata":{"_metadata":{"pdf:keywords":"","pdf:producer":"Neevia Document Converter Pro v6.9 (http://neevia.com)","xmp:modifydate":"2019-01-02T08:24:31+02:00","xmp:createdate":"2019-01-02T08:24:30+02:00","xmp:metadatadate":"2019-01-02T08:24:30+02:00","xmp:creatortool":"Microsoft Word v16","dc:format":"application/pdf","dc:description":"","dc:creator":"Sandesh","dc:title":"IMAGE COMPRESSION                                                                                                                Module 5","xmpmm:documentid":"uuid:E63D66EB-5161-79E5-9E42-1B84BBBFF02C","xmpmm:instanceid":"uuid:5ED754A9-D84B-1B4A-CE2D-4F072FC497B9"}},"totalPages":14},"loc":{"pageNumber":8}}}],["61b67918-a4aa-4ad9-9567-96a26f0f9f0a",{"pageContent":"9 \nIMAGE COMPRESSION                                                                                                                Module 5 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nselectively  eliminates  or  more  coarsely  quantizes  the  coefficients  that  carry  the  least  amount  of \ninformation  in  a  predefined  sense.  The  encoding  process  terminates  by  coding  the  quantized \ncoefficients. Transformation coding can be \n• Adaptive – each subimage is treated in an individual manner \n• Non-adaptive – all subimages are treated in the same way \n \nFigure : A block transform coding system i. encoder ii. Decoder. \nSubimage size selection \nBoth  transform  coding  reconstruction  error  and  computational  complexity  are functions \nof  the  subimage  size. Usually  a  (integer  power  of  two)  size  is chosen  that  will  reduce  the \ncorrelation.  The  following  figure  illustrates  the  graphically  the  impact  of  subimage  size  on \ntransform coding reconstruction error.  between adjacent subimages in the reconstructed image.  \n \nBit allocation \nThe  process  of  truncating,  quantizing  and  coding  the  coefficients  of  the transformed \nsubimage is  referred to as bit allocation. The reconstruction error in a decompressed image is  a \nfunction of \n• The number of coefficients discarded \n• The precision used to store the remaining coefficients \n• The relative importance of these coefficients \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 5 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE COMPRESSION                                                                                                                Module 5","Author":"Sandesh","Creator":"","Producer":"https://www.convertapi.com","CreationDate":"D:20190102082430+02'00'","ModDate":"D:20190102082432+02'00'"},"metadata":{"_metadata":{"pdf:keywords":"","pdf:producer":"Neevia Document Converter Pro v6.9 (http://neevia.com)","xmp:modifydate":"2019-01-02T08:24:31+02:00","xmp:createdate":"2019-01-02T08:24:30+02:00","xmp:metadatadate":"2019-01-02T08:24:30+02:00","xmp:creatortool":"Microsoft Word v16","dc:format":"application/pdf","dc:description":"","dc:creator":"Sandesh","dc:title":"IMAGE COMPRESSION                                                                                                                Module 5","xmpmm:documentid":"uuid:E63D66EB-5161-79E5-9E42-1B84BBBFF02C","xmpmm:instanceid":"uuid:5ED754A9-D84B-1B4A-CE2D-4F072FC497B9"}},"totalPages":14},"loc":{"pageNumber":9}}}],["edb64482-c11b-4796-9eeb-d9c8616db1df",{"pageContent":"10 \nIMAGE COMPRESSION                                                                                                                Module 5 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nMost transform coding systems select which coefficients to retain \n• On the basis of maximum variance – zonal coding \n• On the basis of maximum magnitude – threshold coding \nZonal coding -  transform coefficients are selected using a fix filter mask, which has been \nformed to fit the maximum variance of an average image. Knowing which \ntransform  coefficients  that  are  going  to  be  retained  makes  it possible  to \noptimize   the   transform   computation – only   the   selectedtransform \ncoefficients need to be computed.  \nThreshold coding -  coefficients are selected with respect to their magnitude. There are several \nways of implementing threshold coding \n• Global  thresholding – use  the  same  (global)  threshold  value  for all \nimages \n• Adaptive thresholding – the threshold value is based on the coefficients \n• Local  thresholding – the  threshold  value  is  based  on  the  location  of  the \ncoeff \n• N-largest – the N largest coefficients are retained (requires ordering) \nNote  that  some thresholding  coding  schemes  result  in  a  predefined reconstruction  error  rather \nthan a specified compression rate \n \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 5 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE COMPRESSION                                                                                                                Module 5","Author":"Sandesh","Creator":"","Producer":"https://www.convertapi.com","CreationDate":"D:20190102082430+02'00'","ModDate":"D:20190102082432+02'00'"},"metadata":{"_metadata":{"pdf:keywords":"","pdf:producer":"Neevia Document Converter Pro v6.9 (http://neevia.com)","xmp:modifydate":"2019-01-02T08:24:31+02:00","xmp:createdate":"2019-01-02T08:24:30+02:00","xmp:metadatadate":"2019-01-02T08:24:30+02:00","xmp:creatortool":"Microsoft Word v16","dc:format":"application/pdf","dc:description":"","dc:creator":"Sandesh","dc:title":"IMAGE COMPRESSION                                                                                                                Module 5","xmpmm:documentid":"uuid:E63D66EB-5161-79E5-9E42-1B84BBBFF02C","xmpmm:instanceid":"uuid:5ED754A9-D84B-1B4A-CE2D-4F072FC497B9"}},"totalPages":14},"loc":{"pageNumber":10}}}],["3fff40b0-653c-4419-bc54-baea3747799f",{"pageContent":"11 \nIMAGE COMPRESSION                                                                                                                Module 5 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nPredictive coding \nProvides a data representation where code words express source symbol deviations from \npredicted  values  (usually  values  of neighboring  pixels). Predictive  coding  efficiently  reduces \ninterpixel redundancies \n• 1D & 2D – pixels are predicted from neighboring pixels \n• 3D – pixels are predicted between frames as well \nWorks well for all images with a high degree of interpixel redundancies. Works in the presence \nof noise (just not as efficiently) \nInput data 222222222226666666666666699999999999999999 \nCode         200000000004000000000000030000000000000000 \nPredictive coding can be used in both lossless and lossy compression schemes \n \nLossless predictive coding \n The  following  figure  shows  the  basic  components  of  lossless  predictive  coding  system. \nThe  system  consist  of  an  encoder  and  decoder,  each  containing  an  identical  predictor.  As \nsuccessive samples of discrete time input signal, f(n), are introduced to the encoder, the predictor \ngenerates the anticipated value of each sample based on a specified number of past samples. The \noutput of the predictor is then rounded to the nearest integer, The prediction error  \n \n \n \nFigure : A lossless predictive coding model: i. encoder ii. Decoder.  \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 5 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE COMPRESSION                                                                                                                Module 5","Author":"Sandesh","Creator":"","Producer":"https://www.convertapi.com","CreationDate":"D:20190102082430+02'00'","ModDate":"D:20190102082432+02'00'"},"metadata":{"_metadata":{"pdf:keywords":"","pdf:producer":"Neevia Document Converter Pro v6.9 (http://neevia.com)","xmp:modifydate":"2019-01-02T08:24:31+02:00","xmp:createdate":"2019-01-02T08:24:30+02:00","xmp:metadatadate":"2019-01-02T08:24:30+02:00","xmp:creatortool":"Microsoft Word v16","dc:format":"application/pdf","dc:description":"","dc:creator":"Sandesh","dc:title":"IMAGE COMPRESSION                                                                                                                Module 5","xmpmm:documentid":"uuid:E63D66EB-5161-79E5-9E42-1B84BBBFF02C","xmpmm:instanceid":"uuid:5ED754A9-D84B-1B4A-CE2D-4F072FC497B9"}},"totalPages":14},"loc":{"pageNumber":11}}}],["55eec8da-1f5f-4706-a057-fbc2e923729c",{"pageContent":"12 \nIMAGE COMPRESSION                                                                                                                Module 5 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nThe  decoder  shown  in  second  part  of  the  figure  reconstruct  e(n)  from  the  received \nvariable-length  code  words  and  performs  the  inverse  operation  to  decompress  or  recreate  the \noriginal input sequence.  \n \n \nLossy predictive coding \n In this lossy predictive coding, we add quantizer to the lossless predictive coding model \nintroduced earlier and examine the trade –off between reconstruction accuracy and compression \nperformance within the context of spatial predictors.  \nAs it shown in following figure the quantizer, which replaces the nearest integer function \nof  the  error-free  encoder,  is  inserted  between  the  symbol  encoder  and  the  point  at  which  the \nprediction error  is  formed.  It  maps  the  prediction  error  into  a  limited  range  of  outputs, denoted \ne(n)  ,  which  establish  the  amount  of  compression  and  distortion  that  occurs.  For  a  lossy \nencoder’s predictor within the feedback loop,  \n \nThe second part of the figure shows the lossy decoder.    \n \nFigure : A lossy predictive coding model: i. encoder ii. Decoder \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 5 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE COMPRESSION                                                                                                                Module 5","Author":"Sandesh","Creator":"","Producer":"https://www.convertapi.com","CreationDate":"D:20190102082430+02'00'","ModDate":"D:20190102082432+02'00'"},"metadata":{"_metadata":{"pdf:keywords":"","pdf:producer":"Neevia Document Converter Pro v6.9 (http://neevia.com)","xmp:modifydate":"2019-01-02T08:24:31+02:00","xmp:createdate":"2019-01-02T08:24:30+02:00","xmp:metadatadate":"2019-01-02T08:24:30+02:00","xmp:creatortool":"Microsoft Word v16","dc:format":"application/pdf","dc:description":"","dc:creator":"Sandesh","dc:title":"IMAGE COMPRESSION                                                                                                                Module 5","xmpmm:documentid":"uuid:E63D66EB-5161-79E5-9E42-1B84BBBFF02C","xmpmm:instanceid":"uuid:5ED754A9-D84B-1B4A-CE2D-4F072FC497B9"}},"totalPages":14},"loc":{"pageNumber":12}}}],["188a0ced-aef7-4f23-bc11-748125d55985",{"pageContent":"13 \nIMAGE COMPRESSION                                                                                                                Module 5 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \nWavelet coding \nLike  transform  coding,  wavelet  coding  is  based  on  the  premise  that  using  a linear \ntransform (here a wavelet transform) will result in transform coefficients that can be stored more \nefficiently than the pixels themselves. Due to the facts that wavelets are computationally efficient \nand that the wavelet basis functions are limited in duration, subdivision of the original image is \nUnnecessary. Wavelet  coding  typically  produces  a  more  efficient  compression  than  DCTbased \nsystems \n• Objectively – the  mean  square  error  of  wavelet-based  reconstructions  are typically \nlower \n• Subjectively - the  blocking  artifacts  (characteristic  of  DCT-based  systems  at high \ncompression ratios) are not present in wavelet reconstructions \nThe choice of wavelet to use greatly affects the compression efficiency \n \nFigure : A wavelet coding system i. Encoder ii. Decoder \n \n \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 5 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE COMPRESSION                                                                                                                Module 5","Author":"Sandesh","Creator":"","Producer":"https://www.convertapi.com","CreationDate":"D:20190102082430+02'00'","ModDate":"D:20190102082432+02'00'"},"metadata":{"_metadata":{"pdf:keywords":"","pdf:producer":"Neevia Document Converter Pro v6.9 (http://neevia.com)","xmp:modifydate":"2019-01-02T08:24:31+02:00","xmp:createdate":"2019-01-02T08:24:30+02:00","xmp:metadatadate":"2019-01-02T08:24:30+02:00","xmp:creatortool":"Microsoft Word v16","dc:format":"application/pdf","dc:description":"","dc:creator":"Sandesh","dc:title":"IMAGE COMPRESSION                                                                                                                Module 5","xmpmm:documentid":"uuid:E63D66EB-5161-79E5-9E42-1B84BBBFF02C","xmpmm:instanceid":"uuid:5ED754A9-D84B-1B4A-CE2D-4F072FC497B9"}},"totalPages":14},"loc":{"pageNumber":13}}}],["08eb7db7-c1e3-4500-bf77-8481907ea0f9",{"pageContent":"14 \nIMAGE COMPRESSION                                                                                                                Module 5 \n \nwritetokaranth@gmail.com1| rkk4691@gmail.com\n \n                                                        | VCET, Puttur \n \n \n \nWWW.VTULOOP.COM","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\Module 5 [www.vtuloop.com].pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"IMAGE COMPRESSION                                                                                                                Module 5","Author":"Sandesh","Creator":"","Producer":"https://www.convertapi.com","CreationDate":"D:20190102082430+02'00'","ModDate":"D:20190102082432+02'00'"},"metadata":{"_metadata":{"pdf:keywords":"","pdf:producer":"Neevia Document Converter Pro v6.9 (http://neevia.com)","xmp:modifydate":"2019-01-02T08:24:31+02:00","xmp:createdate":"2019-01-02T08:24:30+02:00","xmp:metadatadate":"2019-01-02T08:24:30+02:00","xmp:creatortool":"Microsoft Word v16","dc:format":"application/pdf","dc:description":"","dc:creator":"Sandesh","dc:title":"IMAGE COMPRESSION                                                                                                                Module 5","xmpmm:documentid":"uuid:E63D66EB-5161-79E5-9E42-1B84BBBFF02C","xmpmm:instanceid":"uuid:5ED754A9-D84B-1B4A-CE2D-4F072FC497B9"}},"totalPages":14},"loc":{"pageNumber":14}}}],["e42b6d2c-4153-40a2-841e-e813d8481568",{"pageContent":"NETWORK LAYER\nMODULE3","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":1}}}],["9f115e71-364d-4415-a688-a333fc34e0dc",{"pageContent":"CHAPTER5\nTHENETWORKLAYER\nI.RoutingAlgorithm\nII.Network Layer Design Issues\nIII.CongestionControlAlgorithms\nIV.QOSControlAlgorithms","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":2}}}],["0e4a380c-5820-40b7-a14f-b8c4925b604a",{"pageContent":"Network layer design Issues:\nThe Network layer is concerned with getting packets from the \nsource all the way to destination.\nNetwork layer design Issues:\n1.Service provided to the transport layer \n2. the internal design of the network\n3.Implementation of Connectionless service\n4.Implementation of Connection oriented service","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":3}}}],["9d49cfa6-85b7-4b3f-ad1b-48c17806b5cf",{"pageContent":"Theenvironmentofthenetworklayer\nprotocols","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":4}}}],["42733418-0f95-4a37-a6d9-9fbf2e765cf4",{"pageContent":"Store-and-Forward Packet Switching","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":5}}}],["3965cdb1-cc74-41a0-bf0a-9237543bf048",{"pageContent":"Store-and-Forward Packet Switching\n•Intheabovediagram,wecanseethattheInternetServiceProvider\n(ISP)hassixrouters(AtoF)connectedbytransmissionlinesshownin\nbluelines.\n•Therearetwohosts,hostH1isconnectedtorouterA,whilehostH2\nisconnectedtorouterD.\n•SupposethatH1wantstosendadatapackettoH2.H1sendsthe\npackettorouterA.\n•ThepacketisstoredinrouterAuntilithasarrivedfully.RouterA\nverifiesthechecksumusingCRC(cyclicredundancycheck)code.If\nthereisaCRCerror,thepacketisdiscarded,otherwiseitis\ntransmittedtothenexthop,hererouterF.\n•ThesameprocessisfollowedbyrouterFwhichthentransmitsthe\npackettorouterD.FinallyrouterDdeliversthepackettohostH2.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":6}}}],["8412c355-330b-4cc6-938a-e50fe56d53fa",{"pageContent":"Store-and-Forward Packet Switching\n•Thenodewhichhasapackettosend,deliversittothe\nnearestnode,i.e.router.Thepacketisstoredintherouter\nuntilithasfullyarrivedanditschecksumisverifiedforerror\ndetection.\n•Once,thisisdone,thepacketistransmittedtothenext\nrouter.\n•Thesameprocessiscontinuedineachrouteruntilthe\npacketreachesitsdestination.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":7}}}],["0df4e780-0b3c-4638-894b-ea7990e2e01d",{"pageContent":"Services provided to the transport layer\n•LogicalAddressing−Networklayeraddsheadertoincoming\npacketwhichincludeslogicaladdresstoidentifysenderand\nreceiver.\n•Routing−ItisthemechanismprovidedbyNetworkLayerfor\nroutingthepacketstothefinaldestinationinthefastest\npossibleandefficientway.\n•Flowcontrol−Thislayerroutesthepackettoanotherway,If\ntoomanypacketsarepresentatthesametimepreventing\nbottlenecksandcongestion.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":8}}}],["f423d4f1-5374-4ce8-9a4d-82b7aaa8eaea",{"pageContent":"Services provided to the transport layer\n•BreaksLargePackets−Breakslargerpacketsintosmallpackets.\n•ConnectionOrientedservice−Itisanetworkcommunication\nmode,whereacommunicationsessionisestablishedbeforeany\nusefuldatacanbetransferredandwhereastreamofdatais\ndeliveredinthesameorderasitwassent.\n•ConnectionlessService−Itisadatatransmissionmethodusedin\npacketswitchingnetworksbywhicheachdataunitisindividually\naddressedandroutedbasedoninformationcarriedineachunit,\nratherthaninthesetupinformationofaprearranged,fixeddata\nchannelasinconnection-orientedcommunication.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":9}}}],["3e855d16-f959-4c32-8357-533525b05b4c",{"pageContent":"Services provided to the transport layer\n•Datagram−Adatagramisabasictransferunitassociated\nwithapacket-switchednetwork.Thedelivery,arrivaltime\nandorderofarrivalneednotbeguaranteedbythenetwork.\n•Avirtualcircuit−Itisameansoftransportingdataovera\npacketswitchedcomputernetworkinsuchawaythatit\nappearsasthoughthereisadedicatedphysicallayerlink\nbetweenthesourceanddestinationendsystemofthisdata.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":10}}}],["dcc55240-e8e2-4c00-afe7-06d2e0fb5748",{"pageContent":"Implementation of Connectionless \nService(Datagram Switching)\n•Ifconnectionlessserviceisoffered,packetsareinjectedintothe\nnetworkindividuallyandroutedindependentlyofeachother.\n•Noadvancesetupisneeded.Inthiscontext,thepacketsarefrequently\ncalleddatagrams(inanalogywithtelegrams)andthenetworkis\ncalledadatagramnetwork.\n•IP(InternetProtocol),whichisthebasisfortheentireInternet,isthe\ndominantexampleofaconnectionlessnetworkservice.Eachpacket\ncarriesadestinationIPaddressthatroutersusetoindividuallyforward\neachpacket.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":11}}}],["f358ed3d-92f4-4ed2-a04b-dfcef5bbee1c",{"pageContent":"Implementation of Connection oriented \nService","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":12}}}],["87c8ccf7-85c5-456b-bcc4-20056c2eb994",{"pageContent":"ImplementationofConnectionoriented\nService\n•Ifconnection-orientedserviceisused,apathfromthesourcerouter\nallthewaytothedestinationroutermustbeestablishedbeforeany\ndatapacketscanbesent.\n•ThisconnectioniscalledaVC(virtualcircuit),inanalogywiththe\nphysicalcircuitssetupbythetelephonesystem,andthenetworkis\ncalledavirtual-circuitnetwork.\n•Anexampleofaconnection-orientednetworkserviceisMPLS\n(MultiProtocolLabelSwitching).ItisusedwithinISPnetworksinthe\nInternet,withIPpacketswrappedinanMPLSheaderhavinga20-bit\nconnectionidentifierorlabel.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":13}}}],["6c21efbb-833e-436b-ac0c-e5879b12db38",{"pageContent":"Implementation of Connection-Oriented \nService(virtual circuit switching , label switching)","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":14}}}],["2ac3c98e-3ac3-4597-857d-ea8c8c16e0bf",{"pageContent":"Comparison of Virtual-Circuit and Datagram \nNetworks","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":15}}}],["8a7620d4-e145-46c8-9707-01b4f3aa60d6",{"pageContent":"ROUTING ALGORITHMS\nCharacteristics of Routing algorithms:\n•Correctness,simplicity,robustness,stability,fairnessand\nefficiency.\n•Theroutingalgorithmshouldbeabletocopewithchangesin\nthetopologyandtrafficwithoutrequiringalljobsinallhosts\ntobeaborted.\n•Stabilityisalsoanimportantgoalfortheroutingalgorithm.\n•Minimizingthemeanpacketdelayisanobviouscandidateto\nsendtrafficthroughthenetworkeffectively,butsois\nmaximizingtotalnetworkthroughput.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":16}}}],["9238941f-7c58-4500-9079-d0967813cd84",{"pageContent":"Types of Routing :\n•Routing algorithms can be grouped into two major classes: \n1.Nonadaptive \n2.Adaptive.\n•Nonadaptivealgorithmsdonotbasetheirroutingdecisionsonany\nmeasurementsorestimatesofthecurrenttopologyandtraffic.\n•Instead,thechoiceoftheroutetousetogetfromItoJ(forallIand\nJ)iscomputedinadvance,offline,anddownloadedtotherouters\nwhenthenetworkisbooted.Thisprocedureissometimescalled\nstaticrouting.\n•Becauseitdoesnotrespondtofailures,staticroutingismostlyuseful\nforsituationsinwhichtheroutingchoiceisclear","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":17}}}],["92422606-7ce4-48fb-8e22-102c4c380d90",{"pageContent":"Types of Routing :\n•Adaptivealgorithms,incontrast,changetheirrouting\ndecisionstoreflectchangesinthetopology,andsometimes\nchangesinthetrafficaswell.\n•Thesedynamicroutingalgorithmsdifferinwheretheyget\ntheirinformation(e.g.locally,fromadjacentrouters,orfrom\nallrouters).\n•whentheychangetheroutes(e.g.,whenthetopology\nchanges,oreveryΔTsecondsastheloadchanges),andwhat\nmetricisusedforoptimization(e.g.,distance,numberof\nhops,orestimatedtransittime)","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":18}}}],["72c5afde-22da-46ef-bec5-4fc968392411",{"pageContent":"The Optimality Principle-\nabout optimal routes without regard to network topology\nor traffic\n•This statement is known as the optimality principle (Bellman,1957)\n•It states that if router J is on the optimal path from router I to router K,\nthen the optimal path from J to K also falls along the same route.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":19}}}],["de3667d8-9c1a-4cfe-968d-f4491d2e12e8",{"pageContent":"The Optimality Principle-\nabout optimal routes without regard to network topology\nor traffic\n•we can see that the set of optimal routes from all sources to \na given destination form a tree rooted at the destination. \nSuch a tree is called a sink tree and is illustrated in Fig. 5-6(b)","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":20}}}],["ad09ec49-a3c1-4c92-ba34-131b942284b5",{"pageContent":"Shortest Path Algorithm\n•Theideaistobuildagraphofthenetwork,witheach\nnodeofthegraphrepresentingarouterandeachedge\nofthegraphrepresentingacommunicationline,or\nlink.Tochoosearoutebetweenagivenpairofrouters,\nthealgorithmjustfindstheshortestpathbetweenthem\nonthegraph.\n•Refertoalgorithmin5-8Dijkstra'sforshortestpath","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":21}}}],["8169f345-3c81-4dfb-9b05-bab95756f020",{"pageContent":"Shortest Path Algorithm","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":22}}}],["a5ec8bb2-6c78-4781-954d-adcd3487da2a",{"pageContent":"FLOODING\n•A simple local technique is flooding, in which every incoming packet \nis sent out on every outgoing line except the one it arrived on.\n•Floodingobviouslygeneratesvastnumbersofduplicatepackets,in\nfact,aninfinitenumberunlesssomemeasuresaretakentodampthe\nprocess.\n•Onesuchmeasureistohaveahopcountercontainedintheheaderof\neachpacketthatisdecrementedateachhop,withthepacketbeing\ndiscardedwhenthecounterreacheszero.\n•Ideally,thehopcountershouldbeinitializedtothelengthofthepath\nfromsourcetodestination.\n•Ifthesenderdoesnotknowhowlongthepathis,itcaninitializethe\ncountertotheworstcase,namely,thefulldiameterofthenetwork.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":23}}}],["eeb0874b-a8dd-462d-ab84-2a3d6341ab3d",{"pageContent":"FLOODING\n•Flooding is not practical for sending most packets\n•First,itensuresthatapacketisdeliveredtoeverynodeinthenetwork.\nThismaybewastefulifthereisasingledestinationthatneedsthe\npacket,butitiseffectiveforbroadcastinginformation\n•Second,floodingistremendouslyrobust,Eveniflargenumbersof\nroutersareblowntobits(e.g.,inamilitarynetworklocatedinawar\nzone),floodingwillfindapathifoneexists,togetapackettoits\ndestination.\n•Floodingalwayschoosestheshortestpathbecauseitchoosesevery\npossiblepathinparallel.Consequently,nootheralgorithmcan\nproduceashorterdelay","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":24}}}],["142f1505-dc7e-44b5-a519-79df0bf68e40",{"pageContent":"Distance Vector Routing(Bellman-Ford)\n•Adistancevectorroutingalgorithmoperatesby\nhavingeachroutermaintainatable(i.e.,avector)\ngivingthebestknowndistancetoeach\ndestinationandwhichlinktousetogetthere.\nThesetablesareupdatedbyexchanging\ninformationwiththeneighbors.\n•It was the original ARPANET routing algorithm and \nwas also used in the Internetunder the name RIP.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":25}}}],["b51dbad2-9773-4f38-9f57-56d27db1c697",{"pageContent":"Distance Vector Routing(Bellman-Ford)\n•In distance vector routing, each router maintains a \nrouting table indexed by,andcontaining one entry \nfor each router in the network. This entry has two \nparts:\n➢the preferred outgoing line to use for that \ndestination and\n➢an estimate of the distance to that destination.\nProblems solved in class:","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":26}}}],["02ab0336-0db3-45ae-b928-16dbf0f64cb4",{"pageContent":"Distance Vector Routing(Bellman-Ford)","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":27}}}],["51e886ad-19e2-4c62-92ff-8ffa740a6604",{"pageContent":"Distance Vector Routing(Bellman-Ford)","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":28}}}],["b61e7bba-2f24-44c4-a47f-d42dbc7e095a",{"pageContent":"Distance Vector Routing(Bellman-Ford)","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":29}}}],["ba6bbd5b-0053-406d-867f-372f67505e3c",{"pageContent":"Distance Vector Routing(Bellman-Ford)","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":30}}}],["e753355e-d8aa-426a-bced-1809ebb53191",{"pageContent":"Distance Vector Routing(Bellman-Ford)","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":31}}}],["364bfb96-2826-491d-accb-299818e4e01e",{"pageContent":"Distance Vector Routing(Bellman-Ford)\nNote: please check for the problem solved in class","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":32}}}],["8658c5ed-b972-4908-aa78-a4184c8dc3ae",{"pageContent":"Count to infinity problem in Distance Vector \nrouting \n•Thesettlingofroutestobestpathsacrossthenetworkiscalled\nconvergence.\n•Distancevectorroutingisusefulasasimpletechniquebywhich\nrouterscancollectivelycomputeshortestpaths,butithasaserious\ndrawbackinpractice:althoughitconvergestothecorrectanswer,it\nmaydososlowly.\n•Inparticular,itreactsrapidlytogoodnews,butleisurelytobadnews.\nConsiderarouterwhosebestroutetodestinationXislong.If,onthe\nnextexchange,neighborAsuddenlyreportsashortdelaytoX,the\nrouterjustswitchesovertousingthelinetoAtosendtraffictoX.In\nonevectorexchange,thegoodnewsisprocessed.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":33}}}],["e1e3c961-6ae1-4f02-8f85-8a270b5d2331",{"pageContent":"Count to infinity problem in Distance Vector \nrouting ","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":34}}}],["6cb6cf61-2a69-433d-a3c7-547d22ece507",{"pageContent":"Link State Routing\n•DistancevectorroutingwasusedintheARPANETuntil1979,whenit\nwasreplacedbylinkstaterouting.\n•Theprimaryproblemthatcauseditsdemisewasthatthealgorithm\noftentooktoolongtoconvergeafterthenetworktopologychanged\n(duetothecount-to-infinityproblem)\n•Variants of link state routing called IS-IS and OSPF are the routing \nalgorithms that are most widely used inside large networks and the \nInternet today","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":35}}}],["a1628cf3-5d74-4bc0-8d76-ae36360acaba",{"pageContent":"Link State Routing\n•Each router must do the following things to make it work\n•Discover its neighbors and learn their network addresses.\n•Set the distance or cost metric to each of its neighbors.\n•Construct a packet telling all it has just learned.\n•Send this packet to and receive packets from all other routers.\n•Compute the shortest path to every other router","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":36}}}],["cc4fa121-667f-4328-8cfd-e3bc5454e007",{"pageContent":"Link State Routing","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":37}}}],["869e6b6d-8eb2-439f-af9f-0017df2002ac",{"pageContent":"Link State Routing\n•When a router is booted, its first task is to learn who its neighbors \nare. It accomplishes this goal by sending a special HELLO packet on \neach point-to-point line. The router on the other end is expected to \nsend back a reply giving its name.\n•These names must be globally unique because when a distant router \nlater hears that three routers are all connected to F, it is essential that \nit can determine whether all three mean the same F.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":38}}}],["15d92394-ae02-44a0-9ecf-ecdbd70d5088",{"pageContent":"Link State Routing","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":39}}}],["04638432-bb0e-4a1d-b488-047fcbdafd83",{"pageContent":"Link State Routing\n•Themostdirectwaytodeterminethisdelayistosendoverthelinea\nspecialECHOpacketthattheothersideisrequiredtosendback\nimmediately.Bymeasuringtheround-triptimeanddividingitbytwo,\nthesendingroutercangetareasonableestimateofthedelay.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":40}}}],["49bfd084-1ede-405d-88cd-4a2a5c295ae8",{"pageContent":"Hierarchical Routing\n•Asnetworksgrowinsize,therouterroutingtablesgrow\nproportionally.Notonlyisroutermemoryconsumedbyever-\nincreasingtables,butmoreCPUtimeisneededtoscanthemandmore\nbandwidthisneededtosendstatusreportsaboutthem.\n•Atacertainpoint,thenetworkmaygrowtothepointwhereitisno\nlonger.feasibleforeveryroutertohaveanentryforeveryotherrouter,\nsotheroutingwillhavetobedonehierarchically,asitisinthe\ntelephonenetwork.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":41}}}],["9e97ad31-5b74-42b5-95ed-20c75e921ed0",{"pageContent":"Hierarchical Routing\n•Whenhierarchicalroutingisused,theroutersaredividedinto\nwhatwewillcallregions.Eachrouterknowsallthedetails\nabouthowtoroutepacketstodestinationswithinitsown\nregionbutknowsnothingabouttheinternalstructureofother\nregions.Whendifferentnetworksareinterconnected,itis\nnaturaltoregardeachoneasaseparateregiontofreethe\nroutersinonenetworkfromhavingtoknowthetopological\nstructureoftheotherones.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":42}}}],["750ad979-2984-4320-a17a-dd3e877d4410",{"pageContent":"Hierarchical Routing","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":43}}}],["3d8fea92-2cec-4ccc-879c-4fd774c3301d",{"pageContent":"Broadcast Routing\n•Insomeapplications,hostsneedtosendmessagestomanyor\nallotherhosts.Forexample,aservicedistributingweather\nreports,stockmarketupdates,orliveradioprogramsmight\nworkbestbysendingtoallmachinesandlettingthosethat\nareinterestedreadthedata.Sendingapackettoall\ndestinationssimultaneouslyiscalledbroadcasting","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":44}}}],["d26c5d7b-58c1-4872-8271-4c03a2613db9",{"pageContent":"Broadcast Routing\n•Animprovementismultidestinationrouting,inwhicheach\npacketcontainseitheralistofdestinationsorabitmap\nindicatingthedesireddestinations.Whenapacketarrivesata\nrouter,therouterchecksallthedestinationstodeterminethe\nsetofoutputlinesthatwillbeneeded.\n•Theroutergeneratesanewcopyofthepacketforeachoutput\nlinetobeusedandincludesineachpacketonlythose\ndestinationsthataretousetheline.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":45}}}],["ba7e0a6e-1461-47a0-a365-ca49a02dbb46",{"pageContent":"Broadcast Routing\n•Theideaforreversepathforwardingiselegantandremarkably\nsimpleonceithasbeenpointedout(DalalandMetcalfe,1978).When\nabroadcastpacketarrivesatarouter,theroutercheckstoseeifthe\npacketarrivedonthelinkthatisnormallyusedforsendingpackets\ntowardthesourceofthebroadcast.\n•Theprincipaladvantageofreversepathforwardingisthatitis\nefficientwhilebeingeasytoimplement.Itsendsthebroadcastpacket\novereachlinkonlyonceineachdirection,justasinflooding,yetit\nrequiresonlythatroutersknowhowtoreachalldestinations,without\nneedingtoremembersequencenumbers(oruseothermechanismsto\nstoptheflood)orlistalldestinationsinthepacket","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":46}}}],["aa05ebbb-2f15-4c95-9bfa-21997dd061f1",{"pageContent":"Broadcast Routing\n•Aspanningtreeisasubsetofthenetworkthatincludesalltherouters\nbutcontainsnoloops.Sinktreesarespanningtrees.Ifeachrouter\nknowswhichofitslinesbelongtothespanningtree,itcancopyan\nincomingbroadcastpacketontoallthespanningtreelinesexceptthe\noneitarrivedon.\nDraw Back:\n•Theonlyproblemisthateachroutermusthaveknowledgeofsome\nspanningtreeforthemethodtobeapplicable.Sometimesthis\ninformationisavailable(e.g.,withlinkstaterouting,allroutersknow\nthecompletetopology,sotheycancomputeaspanningtree)but\nsometimesitisnot(e.g.,withdistancevectorrouting).","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":47}}}],["72b121c6-8cf6-44a6-8658-15d13816c0bd",{"pageContent":"Multicast Routing\n•Someapplications,suchasamultiplayergameorlivevideoofa\nsportseventstreamedtomanyviewinglocations,sendpacketsto\nmultiplereceivers.Unlessthegroupisverysmall,sendingadistinct\npackettoeachreceiverisexpensive.Ontheotherhand,broadcastinga\npacketiswastefulifthegroupconsistsof,say,1000machinesona\nmillion-nodenetwork,sothatmostreceiversarenotinterestedinthe\nmessage(orworseyet,theyaredefinitelyinterestedbutarenot\nsupposedtoseeit).","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":48}}}],["a9cca161-c4fe-4250-b6a1-69067e636e04",{"pageContent":"Multicast Routing","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":49}}}],["01669102-66a5-4e59-94c4-3bbccc0a9814",{"pageContent":"Routing for Mobile Hosts\n•An alternative design uses core-based trees to compute a single \nspanning tree for the group (Ballardieet al., 1993). All of the routers \nagree on a root (called the core or rendezvous point) and build the \ntree by sending a packet from each member to the root.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":50}}}],["e56ac047-194d-4d9b-bb95-2bfca41c40cd",{"pageContent":"Anycast Routing\n•In anycast, a packet is delivered to the nearest member ofagroup \n(Partridge et al., 1993). Schemes that find these paths are called \nanycast routing.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":51}}}],["5f0e95a2-c550-4c36-8eb0-baa65b8623d3",{"pageContent":"Routing for Mobile Hosts","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":52}}}],["75a79f3c-4bf4-4929-85af-945eeb06617e",{"pageContent":"Routing for Mobile Hosts\n•Whentheencapsulatedpacketarrivesatthecareofaddress,\nthemobilehostunwrapsitandretrievesthepacketfromthe\nsender.Themobilehostthensendsitsreplypacketdirectlyto\nthesender(step4).Theoverallrouteiscalledtriangle\nroutingbecauseitmaybecircuitousiftheremotelocationis\nfarfromthehomelocation.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":53}}}],["85fb38b8-c67d-4d01-bd27-b1fcfa291a1a",{"pageContent":"Routing in Ad Hoc Networks\n•Wehavenowseenhowtodoroutingwhenthehostsare\nmobilebuttheroutersarefixed.Anevenmoreextremecase\nisoneinwhichtheroutersthemselvesaremobile\n•Inallthesecases,andothers,eachnodecommunicates\nwirelesslyandactsasbothahostandarouter.Networksof\nnodesthatjusthappentobeneareachotherarecalledadhoc\nnetworksorMANETs(MobileAdhocNETworks).","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":54}}}],["33183f5a-36ec-4c05-a664-40ca41467d2d",{"pageContent":"Routing in Ad Hoc Networks\n•Route Discovery:\n•In AODV, routes to a destination are discovered on demand, that is, \nonly when a somebody wants to send a packet to that destination\n•Note: Please go through page 385 and 390","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":55}}}],["79215c81-01cc-4e5f-b4b2-4082c9c1fe83",{"pageContent":"Routing in Ad Hoc Networks","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":56}}}],["a472ea37-6d3c-4212-9d7e-c160e5be670a",{"pageContent":"Routing in Ad Hoc Networks\n•SupposethataprocessatnodeAwantstosendapackettonodeI.The\nAODValgorithmmaintainsadistancevectortableateachnode,keyed\nbydestination,givinginformationaboutthatdestination,includingthe\nneighbortowhichtosendpacketstoreachthedestination.First,A\nlooksinitstableanddoesnotfindanentryforI.Itnowhasto\ndiscoveraroutetoI.Thispropertyofdiscoveringroutesonlywhen\ntheyareneedediswhatmakesthisalgorithm‘‘ondemand.’’\n•Note:Routerequestpacket\nRouteReplyPacket(gothroughtextbookforthispart)\nTimetolive","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":57}}}],["bc00d348-4234-42e8-8ae4-f894e892215b",{"pageContent":"CONGESTION CONTROL ALGORITHMS","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":58}}}],["eeeb1f31-f21c-4df9-ac2e-734eb394df43",{"pageContent":"CONGESTION CONTROL ALGORITHMS\nTerminologies  and definitions:\n•Too many packets present in (a part of) the network causes packet \ndelay and loss that degrades performance. This situation is called \ncongestion\n•Unless the network is well designed, it may experience a congestion \ncollapse  inwhich performance plummets as the offered load \nincreases beyond the capacity.\n•Goodput, which is the rate at which useful packets are delivered by \nthe network","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":59}}}],["ea808b91-3d94-43a5-800d-4b5e8900acb6",{"pageContent":"Approaches to Congestion Control","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":60}}}],["0baf7a3e-0037-496e-9f87-031b2258aa4d",{"pageContent":"Approaches to Congestion Control\n•The presence of congestion means that the load is (temporarily) \ngreater than the resources (in a part of the network) can handle.\n•Two solutions come to mind:\nincrease the resources or decrease the load.\n•As shown in Fig. 5-22, these solutions are usually applied on \ndifferent time scales to either prevent congestion or react to it \nonce it has occurred","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":61}}}],["3d90b37d-045c-4c7d-8a4a-9d4f1c93fb01",{"pageContent":"Approaches to Congestion Control\n•The most basic way to avoid congestion is to build a network that is \nwell matched to the traffic that it carries\n•Sometimes the resources can be added Dynamically when there is \nserious congestion, for example, turning on spare routers or enabling \nlines that are normally used only as backups (to make the system fault \ntolerant) or purchasing bandwidth on the open market.\n•More often, links and routers that are regularly heavily utilized are \nupgraded at the earliest opportunity. This is called provisioning and \nhappens on a time scale of months, driven by long-term traffic trends.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":62}}}],["1dd4103a-9701-4da3-b66d-e57765aa5c15",{"pageContent":"Approaches to Congestion Control\n•To make the most of the existing network capacity, routes can be tailored \nto traffic patterns that change during the day as network users wake and \nsleep in different time zones.This is called traffic-aware routing.\n•However, sometimes it is not possible to increase capacity. The only way \nthen to beat back the congestion is to decrease the load. In a virtual-\ncircuit network, new connections can be refused if they would cause the \nnetwork to become congested. This is called admission control.\nTwo difficulties with this approach are how to identify the onset of \ncongestion,andhow to inform the source that needs to slow down. To \ntackle the firstissue, routers can monitor the average load, queueing delay, \nor packet loss. In allcases, rising numbers indicate growing congestion.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":63}}}],["af72ef21-c8bf-4bfb-b1b1-1535c0b385f3",{"pageContent":"Approaches to Congestion Control\n•Finally,whenallelsefails,thenetworkisforcedtodiscardpackets\nthatitcannotdeliver.Thegeneralnameforthisisloadshedding.A\ngoodpolicyforchoosingwhichpacketstodiscardcanhelptoprevent\ncongestioncollapse\n•Traffic-AwareRouting:","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":64}}}],["991e2fa8-e9c2-478b-92d6-4b04fbef4010",{"pageContent":"Approaches to Congestion Control\n•AdmissionControl:Theideaissimple:donotsetupanewvirtual\ncircuitunlessthenetworkcancarrytheaddedtrafficwithout\nbecomingcongestedAcommonlyuseddescriptorthatcapturesthis\neffectistheleakybucketortokenbucket","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":65}}}],["2fb5ae2c-0cc8-4cc4-a488-c272f9c7231f",{"pageContent":"Approaches to Congestion Control\n•To maintain a good estimate of the queueing delay, d, a sample of the \ninstantaneous queue length, s, can be made periodically and d updated \naccording to","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":66}}}],["262bac4d-c49b-4803-b9d9-ce745e6c37f9",{"pageContent":"Approaches to Congestion Control\n•TrafficThrottling:Whencongestionisimminent,itmusttellthesenderstothrottle\nbacktheirtransmissionsandslowdown.Thisfeedbackisbusinessasusualrather\nthananexceptionalsituation.\nChokePacketsThemostdirectwaytonotifyasenderofcongestionistotell\nitdirectly.Inthisapproach,therouterselectsacongestedpacketandsendsachoke\npacketbacktothesourcehost,givingitthedestinationfoundinthepacket.\nTheoriginalpacketmaybetagged(aheaderbitisturnedon)sothatitwillnot\ngenerateanymorechokepacketsfartheralongthepathandthenforwardedintheusual\nway.\n•To avoid increasing load on the network during a time of congestion, the router may \nonly send choke packets at a low rate. When the source host gets the choke packet, it \nis required to reduce the traffic sent to the specified destination","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":67}}}],["f4c76cb9-38c0-4131-ae27-c62a050b104e",{"pageContent":"Approaches to Congestion Control\n•RED(RandomEarlyDetection):\n•Dealingwithcongestionwhenitfirststartsismoreeffectivethan\nlettingitgumuptheworksandthentryingtodealwithit.This\nobservationleadstoaninterestingtwistonloadshedding,whichisto\ndiscardpacketsbeforeallthebufferspaceisreallyexhausted.\n•REDroutersimproveperformancecomparedtoroutersthatdrop\npacketsonlywhentheirbuffersarefull,thoughtheymayrequire\ntuningtoworkwell","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":68}}}],["fce26de8-1097-4e21-bd4c-e49ad59fa320",{"pageContent":"QUALITY OF SERVICE\n•Four issues must be addressed to ensure quality of service:\n1. What applications need from the network.\n2. How to regulate the traffic that enters the network.\n3. How to reserve resources at routers to guarantee  \nperformance.\n4. Whether the network can safely accept more traffic.","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":69}}}],["67fbc966-de02-4cb8-9b1f-20521cce3022",{"pageContent":"QUALITY OF SERVICE","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":70}}}],["3fda0441-748a-4081-975f-a0ad1aa89db6",{"pageContent":"Key terminologies toachieveQoS\n•Traffic Shaping\n•SLA(servicelevelagreements)\n•Traffic policing\n•LeakyBucketsandtokenbuckets\n•PacketschedulingAlgorithms(FIFO,FCFS\nWeighted fairqueuing)","metadata":{"source":"C:\\Users\\vinay\\Desktop\\frontend-next\\public\\documents\\module_3_Network_layer_ppt_shalini.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"NETWORK LAYER","Author":"Shalini  S","Creator":"Microsoft® PowerPoint® 2019","Producer":"Microsoft® PowerPoint® 2019","CreationDate":"D:20240208132452+05'30'","ModDate":"D:20240208132452+05'30'"},"metadata":{"_metadata":{"pdf:producer":"Microsoft® PowerPoint® 2019","dc:title":"NETWORK LAYER","dc:creator":"Shalini  S","xmp:creatortool":"Microsoft® PowerPoint® 2019","xmp:createdate":"2024-02-08T13:24:52+05:30","xmp:modifydate":"2024-02-08T13:24:52+05:30","xmpmm:documentid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A","xmpmm:instanceid":"uuid:50C5BE31-F364-4F7D-9306-87098E1B620A"}},"totalPages":71},"loc":{"pageNumber":71}}}]],{"0":"ec8c4203-e463-42e8-a36f-8f6c772fef74","1":"b609af76-5653-44ba-90cd-4b1cbe20ecdc","2":"9299c1b6-371e-4cd1-8e48-314c4c2b80e2","3":"684161fe-0741-478a-8ef2-926775ad8660","4":"778578c5-b01d-4b15-9319-80334c3a4ce4","5":"e43e6d0c-acbd-4007-929a-f4e69225ce5c","6":"7de4bfff-8d53-4bbd-a51e-4f5513c14431","7":"c0062663-940c-4850-866e-9cb14363a352","8":"f75a8eeb-d2ed-403f-acf7-4b4a4760b31e","9":"e95c86b7-40e5-4206-8683-c8366c81d9cc","10":"f6c343e1-65ce-4d21-8e6a-d281011744f5","11":"b44c7b88-456c-4b61-b685-2ae11f99279a","12":"f40cce3e-9463-4bb1-88dd-c3320be60f3e","13":"cba9625d-9b37-48eb-a5d6-60c069eab3bf","14":"a85daac8-d0ce-4be8-97ca-28fc6d21154d","15":"4d0f4941-604b-416a-9135-0cc61c442003","16":"c703e731-f306-478e-963f-e5f6a1d66acf","17":"72146861-dc67-48a5-9939-96593b78158d","18":"9153e299-18e3-4b09-a3b9-43cf7b204eed","19":"e22269a5-f4bc-49f5-bebb-2ff2ba2f1a62","20":"e83a2260-1d0a-4c23-8dc9-b1fce62c8dbc","21":"e31d9697-a470-4464-af54-2bc554258208","22":"826f6ab2-6d71-4296-8957-85fa8c480cae","23":"16166afe-c982-4697-92ca-bfe1f547330c","24":"c92b1399-28f3-4dd0-99f2-0343bc224537","25":"fd168a47-95cf-4576-92df-dc01dad635e1","26":"c910db97-0d64-48e2-9049-895fe1f44431","27":"63336476-5a5c-43ea-bc5e-a2e923c16061","28":"d7ea6c6c-4755-4873-b93b-9d8c0f914574","29":"56759625-e6b7-4b09-8f7c-8ad161e360a9","30":"f9631412-4d80-4e93-9f7c-cd2cd8cd758b","31":"e9d5b1e9-7e0b-4064-8ed6-8ddfef2a6e7f","32":"ef9683e3-06a3-4e26-8ab9-70d438153113","33":"dca14c99-6214-4292-8798-54821aa8e1c9","34":"8e56dd17-5f99-401a-992c-840269435666","35":"9c584786-3f02-4203-bbf1-c0dcd2df8623","36":"c44bd214-f96b-4c1a-907b-3d7d57f6756b","37":"3d784843-c400-41ed-b578-76247fbd90ea","38":"2516daea-e295-42f0-a4fa-36db4c0dc39d","39":"826acdad-53dd-43a8-a677-43d7fa87e1df","40":"d9c3f483-2b98-4d16-9183-a4f4348c04d6","41":"921727dc-2360-4c53-bbe1-92addca03b3e","42":"a3423919-2b2d-4f1e-af70-2ac04bc2b03c","43":"1e3ef94d-4f54-4b9e-9c03-e828bc231bbb","44":"78fc5676-167c-4512-966e-64f9205a8b8c","45":"7ad85185-1b73-4ed8-8d85-fa4fd1895e09","46":"c616b255-e7d5-4383-b156-e03dc3a251ec","47":"760e99ab-ac75-4819-8bba-22d193f030fa","48":"02dfa018-2104-445d-9aac-fb7d4be80b45","49":"4b24c592-3196-4638-9b62-d264f5572eb1","50":"a23daf8f-c20a-422b-aaf9-420b021a7714","51":"65f83bc8-bdfd-4a19-967e-9fab4f51add7","52":"98861dc0-7148-4f58-981e-8c74ece837b0","53":"9e1c923f-86e9-43dd-9b42-9da2ca623326","54":"7506ef9a-4635-41bb-9cba-24a95f4f1a41","55":"3d9ec74b-bcae-4567-bee0-f5e74053dfed","56":"34cba5af-19a5-4b89-93bf-5cffcfa97f02","57":"e2bd1e9f-e46d-493b-85ad-30c45b920b73","58":"fef284c1-78cb-4dd6-967f-f94029b1c634","59":"c1e7ef81-2eb3-4bff-84f4-07a6d15aff0a","60":"5c0ac0dc-55a2-48d5-a225-99a623529783","61":"8590046a-96ab-4029-a947-787b07e8cbde","62":"e4193eaf-8327-419f-bce5-af39e74d1ad6","63":"a785eac5-e811-4eca-88c2-aa8956247946","64":"b871bfd1-0be0-48f0-9716-0b44d9a8c29a","65":"5eed714b-3abe-4212-aa91-9514a119518d","66":"dd2bbf3f-2f3c-4a53-bcd6-0f057d1719f5","67":"650cb5d2-d63e-4aac-b692-506459750886","68":"e4f388c2-8c9f-47a1-90a4-f440e095f544","69":"adbdbea1-13ee-4844-b1c0-2c14475bbb6e","70":"29c1a1a4-819b-4b1f-a2ee-76b88fa88b31","71":"4d6d74cd-9989-40f4-a76f-81c8aa4493c8","72":"42ebf312-7876-4ea2-9b59-577f535439e8","73":"b770c220-d42f-4918-8974-b45868f7eb7d","74":"cf648f01-eb07-41b4-8b16-9adef93522fc","75":"3bdd22f4-8464-47c8-bbb8-94cb9b448e01","76":"df1ddefc-872e-4bc8-ac74-ca0505844ac0","77":"5a82dcbc-e879-4b06-916d-a09b0331bc5b","78":"0a9b8bc8-e938-4957-a9cb-299caccf243c","79":"167273d4-2ed9-4a79-9a95-d85ff58567f9","80":"02e30c37-5281-49a7-bfa3-1c1029e22c50","81":"491bb2b7-8f7c-4761-8e38-677143f154f6","82":"1a735d76-33f9-4616-8e83-ce503093607e","83":"524158dd-7582-4310-912f-8a73bc40ea1b","84":"2f40734d-4bf5-4040-a4ec-5b56dd57f071","85":"ce160dd4-3b52-4c68-b280-8630456cc3dd","86":"65bc8eb9-e79c-4d40-8c4e-a287a9c46f85","87":"cc57067a-66c0-4892-a061-23c45e3d8885","88":"f9abc90a-a4cd-442c-a8ff-f94a9ee94508","89":"919733f8-e62f-49d4-aed2-69b821e74ac9","90":"6f09a373-2ca3-4630-bbef-f83eac459adb","91":"eab1f8b8-7489-47b0-8233-5c5d998bc633","92":"c6f832ae-713d-44eb-b58d-786942b10e86","93":"7cb4672b-7173-4a84-9c31-ddcddefec1b0","94":"27eaec16-3939-41e7-81a6-0a7f8ba6146b","95":"35e4538e-fa02-4162-8ef1-a87b4f8c19d2","96":"3e660b45-e0a8-44f6-8e49-ce58ef0d3d9c","97":"7f7e796f-4354-43ea-97cc-fb146133274e","98":"7169f5e4-11bf-479b-b452-0b67b6990f70","99":"acf53c61-4ac8-42d2-9df7-efdc60566caa","100":"24364b9a-6144-4430-8af8-85da5556250e","101":"5380a951-6b83-409e-87ba-52deeec0163c","102":"d163af36-2361-405c-8b5e-b98ddfdce537","103":"c3749e75-95e6-49e1-a1ee-11ea38444422","104":"75c5d784-e0ff-4bc4-8aff-f66538aa832e","105":"a2426c77-7173-43ab-8192-8a592131745c","106":"18c42fac-c17b-4442-bc2a-a9ee353ffc35","107":"c6cbf59c-eefc-4559-ae4c-4092e413ba61","108":"11cb1f5b-b642-4481-8a89-ee4e72504872","109":"b62e55d5-cafd-4d34-927c-211929e51801","110":"69e7a072-90e2-4576-89ef-952c85e61eab","111":"42e8caca-b55c-4962-b7f6-b5a3685a16e0","112":"09fadf68-ed7d-4e41-b00c-18833b3ba72e","113":"79b3bacf-a1d7-4205-b5e4-3b34013335c0","114":"3cfa90dd-ad6c-4af2-842b-09fbcf107ca3","115":"befe85eb-9a55-43ac-a041-ab3e2401d3dc","116":"4f200a6c-5c39-4eb7-a262-efb2ea819980","117":"b8f93337-e5a5-4913-bac3-b36b1c09c5cb","118":"712f68f2-d331-4519-8285-2bed7deebe85","119":"63b8beef-e36d-483e-bd2d-241ff3b4d987","120":"06146bf3-00bf-41a0-8a1b-b948c776ecc4","121":"80337401-f1ad-45e5-a46a-490d2920706a","122":"255b9f7d-e79e-4ee6-8386-2a0ccd7fdcde","123":"b4b943b2-ed32-4fdc-a486-ada55530fc2b","124":"8e8ee341-2e80-4a70-b28a-36f5841d2772","125":"6d8b2352-eaac-47a6-ae03-dbd3e7d34745","126":"960c4e20-1d96-4a68-b97b-801c24ef8772","127":"19fdedd2-2277-45d5-a03c-3c6e02116b3c","128":"a76e5db5-56f0-4d49-bd86-ac9f09ae9fa2","129":"2d68b9c8-770a-4f0e-85a1-4f219c2cae7c","130":"2698929b-76e9-42fc-982c-2864953b44b8","131":"fd4b193f-9428-4b48-8616-876ee4669f74","132":"ee49fafc-5a90-48e6-9d3d-63e90e7453a8","133":"262d33d4-7913-453d-9b2d-09dd95f5da69","134":"98d638a0-55ac-4160-ac1c-560cf9910b9f","135":"9cffa61c-497e-4814-85e9-7d0974952848","136":"d155a2e8-7b64-4b5c-b4dd-88a4aeed5bd6","137":"d4b36a83-9bc7-4f08-9989-ecc71db62726","138":"37c4e406-16cc-4372-bba8-ee2580c4834c","139":"bc4af467-e9db-4fa8-b3d9-67a841330f34","140":"9cce33b4-ebe3-4751-8ff8-8bbe2a52b3ae","141":"03622561-d9dd-4061-8855-cc6d35d09c97","142":"007e1d0e-1afe-408a-adcb-37692517d480","143":"58aaf291-ca29-40b2-8d15-9437a6112320","144":"c5ee9f46-fd2e-47de-8b46-994e7f048fe9","145":"e2ae2bda-8d06-4965-a987-3c724a7e455b","146":"086d02e6-ca02-4f86-a4c5-ed13ae9e8a7e","147":"2373a7af-49b6-4c44-bbdf-14907e9c58fe","148":"62d3b43d-98db-48a5-a1de-b1268d6fd200","149":"fd96f5c6-488d-4326-96b0-7c9391ea6930","150":"a73cc616-5f39-4bfb-97d7-c44c729acccd","151":"23b93b6d-43e8-4d24-a3cd-50e4d20b7df5","152":"afad52dd-702c-41e6-9ea5-a32108311c18","153":"3fb8b122-e887-477b-b96c-c283f9d9ef0b","154":"4dc4f9d9-00ba-4fee-8c3a-6c31351684ee","155":"eedfb519-ccf0-4e6c-bf69-ae19e7c187f2","156":"b5f22f89-b604-45b9-8cd1-f202d0f1d6d4","157":"f44a59d6-3356-4568-bd04-e1d6ca6fecea","158":"1bed3aae-8fff-49a3-aa0d-944eba6dac2e","159":"ee42cad3-0144-4a27-a063-fd080b7ff9aa","160":"d831906b-e432-4725-adb8-d2cbb5195780","161":"28f734ae-5adb-44c7-a3e3-799aae54c972","162":"11b94360-8492-4c07-93cf-b5198173dba7","163":"00f21d8f-362f-4965-9245-3e33ad9f0349","164":"b6c96308-acce-4650-bb0c-3fd6566f71e4","165":"a92f3668-4123-4f84-869c-fb0d8487099c","166":"ffe72fd8-2a71-4fea-a99f-2dbbd018fcc1","167":"cb72fddb-99cb-463b-aaa8-64ef76413aec","168":"d4e8eef4-8aec-40eb-bb19-c52ddeef4eb9","169":"7e4bf9d9-b59f-4699-9701-3fb5efd9361b","170":"841eb631-264b-404c-943f-bc8545b59c34","171":"c7d7c37d-0431-4209-bff4-e318e716bc09","172":"d62c5492-fe98-4ac6-b679-dba8cf62a6a6","173":"bd9be4c4-9339-4de9-b2ac-123580cc3ccf","174":"f404e24e-5728-439c-ac9b-6f935274bcd6","175":"b387a6b2-0423-4b8f-85e4-4489f564b809","176":"c49fb5c2-0447-4b87-a6e7-4ad89b8c4a0c","177":"271546d9-2bf8-43cd-b5c9-16fd380a799f","178":"346b0c68-39cb-4586-a215-bd788376b4bc","179":"f9f2e9e4-ea23-487c-b531-3c53cbc4d70b","180":"cddf2ee3-7d5f-489f-a940-7e9b91691efd","181":"c6c471cd-3019-4ae1-882f-ca31a5bcab13","182":"dcbfe1c4-13c4-40fc-a072-e8fe2b0b597c","183":"e7f67d37-d679-4329-bc4d-8e040bd5340c","184":"4d3400a7-f170-4999-9ff2-201ad0448613","185":"1018f4e9-bc77-4f1a-b600-1067ebe4eda2","186":"0799e5af-587e-4ab0-9f94-aa19da3767f9","187":"c5002676-3560-4a46-b65f-5bfaed19be34","188":"bc5b7ac2-145d-42ca-8e23-13e26eff672b","189":"f3fa854d-12b8-4f3d-bc82-043e1becd696","190":"653f2fb2-3acd-4505-a794-7922f1ab2682","191":"b89eae30-2bf3-4d0f-a901-72b8a2177898","192":"d631e6f6-3cc1-4ca8-9a37-91cb721c7d1e","193":"1b3c0969-c1cc-4350-a358-a1cc6eabab50","194":"1391ce11-081a-4b54-864e-4eb100c9c4fa","195":"09bf870b-c5dc-4e24-8018-02d5662e0a0e","196":"be815c90-43e1-4144-a1ad-61d3ab96ec66","197":"5f5dd6bf-9b8b-459c-9e9f-3e0c8eeaf4f3","198":"36942869-27cc-4a5e-9ae6-eb0082cc036e","199":"604b7d08-64bb-4bb4-9efe-436ab3e50134","200":"e52f981e-63ab-4df6-a42a-b37795aa1ff4","201":"5c7c183c-222b-43d1-879f-3bd91dac5c70","202":"481a314d-81cf-4fe3-8177-64b8d8201d5e","203":"66ef53ea-ea78-499f-8b76-ed495a9c879e","204":"12a89b0a-0ee4-45fc-aab5-d3d8c1cdec03","205":"f8def497-84c3-412a-8300-cf9f04d4a4d9","206":"e86ddf1f-73a2-4835-9b50-bd9a7ba70e0b","207":"ee15deb9-f0dc-491c-9996-c81ca7c31139","208":"e9e6a75f-9607-4282-a152-18257547c2e2","209":"2033d5d6-e8c1-4337-b389-6e2a4a2680dc","210":"47c92000-3cde-444c-a29e-b395de4af6a4","211":"00f46af9-1418-4227-8332-88438f68f280","212":"1f24ae55-741e-42b2-a5b1-4279309563e3","213":"537ffa1a-3b39-47ca-a4e9-d0b4cf40a04c","214":"f86596fd-fbd9-42a2-b7a0-883f64c6ef57","215":"0228ab15-b393-495e-a08a-342a0fb8db02","216":"59ae28d3-7794-473d-81a1-397df354e0fe","217":"55db301d-bf7a-47b0-bffd-a5d844c03a3a","218":"b9e71c66-f5fa-4227-b2cd-84b1b31de064","219":"9471b72f-9945-4363-9b2e-119fc8758cae","220":"08056deb-b8b0-4866-9aaa-3b71d28cde47","221":"7af5dfe1-32b1-4a1c-8d81-1cc82d32453e","222":"4c58cdf6-52fd-4e9a-a8cf-c60b2781b3de","223":"b79cd3e3-8404-4690-bcd7-a87a2292446c","224":"89feabee-f7c0-4ecd-87a4-500cc84ab32b","225":"3cc3c176-d67b-4b8c-9141-fee90c8be6d6","226":"6b7f737f-e1a2-461f-9c8a-5165c27ed1bc","227":"a35f0444-f3dd-4895-9796-5892c344ea25","228":"a203f961-d8e6-4352-bda6-8bcb457aaa04","229":"0ef85e4e-f66e-481e-bd86-2c204f7ac060","230":"bd8781be-3cb4-4ce1-9cfb-12731f75d76e","231":"59c6ef73-1cef-4925-a86a-f781fa41ba1c","232":"b8bdfb0c-d667-4b12-afa2-0bffe062cf2e","233":"3e139bbd-6e19-472d-a714-e6c9b8d2db63","234":"1529519c-916a-442a-94ff-6c2492df0b9c","235":"3d6b2faf-35f1-4918-8ccf-36069225b392","236":"cd675625-8f2f-4a46-8920-08e999b3771a","237":"201d6746-e327-465e-a3d2-51b8863ac750","238":"ed9ae9bc-bdb1-4874-8cb0-8516adc8def5","239":"9f731652-4272-4470-a598-501a1f0b4a47","240":"90888c87-cdde-4fff-a165-60ddf0ac6cf3","241":"ea304ef8-832d-4147-9e06-ef124437a82e","242":"3d05607b-f1ac-4527-b3ea-7359418cf6fa","243":"d54a4299-0488-4621-b58b-ab8ef49411a0","244":"0ce1e508-538c-456a-9d7b-bd6faa8a464b","245":"1d113aac-e456-41a1-ab58-54950f648002","246":"37ef6577-529d-4b63-b9e6-2f2fd38c8588","247":"16e5a054-cec2-4156-b7fe-f4aadc490ec3","248":"2d9fe3f9-e89b-4da6-b8c3-67ea7a4783f2","249":"d393b8ef-1885-4423-bb37-d9af3defae04","250":"ebbce199-8ea2-46e9-a671-5367d4be95ad","251":"313a89e5-82ee-43f1-aa33-841729a57cc4","252":"d6cee719-2a86-42ac-91af-bfbee23100e1","253":"d6a7105d-3dac-4800-b99d-905f6db23946","254":"635b0e98-00b0-4d84-854f-f2893f3baaa3","255":"aa6df0fe-dacd-4122-83c8-cc97e27668b5","256":"e8fbc90b-6338-4dcb-89cf-53a85318a2c1","257":"fb645eae-cdce-4564-86e6-1b529ffca3de","258":"b61fcb2a-adb7-4f10-9d41-31e8b516f01d","259":"13a3080a-9429-490a-b4a7-3dc44e76f4f4","260":"878a074e-f166-4602-9ca5-3e06702de519","261":"9519d812-bd87-4222-b62c-9c3ae25250ca","262":"b69cc6a9-2056-4ea0-813c-e6e9e3b49609","263":"ab4080f6-b427-4540-9cd9-c760509f9e09","264":"728815be-0d56-437a-b617-0e2c75e0e104","265":"7c5a141a-2522-4ff8-b769-ed66ad2161aa","266":"46705218-0dc9-4728-a654-360ab3bf40b2","267":"41885cb8-fcf5-4293-9323-9149edf69e22","268":"3940b15c-1c39-4192-8260-d4928c7314a3","269":"38f97b24-3c61-4908-a316-5eb8ea8da4a5","270":"76d06ba3-10eb-4afa-8e14-dcfdba1bbc80","271":"f3d88898-e8f6-4ee9-b9d1-123a2b71dccb","272":"925a2c48-45c2-4f51-aadc-686024d19cf2","273":"15539018-5381-4b46-b46b-9d95b5dd8e3e","274":"09d74acc-55ca-4259-a924-a58b3c7c9e08","275":"cf84a54d-476e-4c3a-92c7-51807e2a8b6a","276":"48c20087-dd8c-4e9f-849f-f9a8a40c1fcf","277":"e6bb445b-ba41-4f66-8780-eb61d20f488d","278":"443caad7-3095-4863-8f1d-e111daed4831","279":"bef6eeee-2440-434b-b76a-8e2dbb6de18c","280":"f557ca85-1ad8-47aa-a19e-1a325b659ea6","281":"6072bfda-92f2-4829-baad-db7cf066c23a","282":"36a83146-4e0c-4a71-9691-a522d3f9c56a","283":"11f79481-57c1-406b-9ad5-64b46b17bb53","284":"fb0d67a1-93d7-4b8c-9df3-942350793e9a","285":"4dae509b-e207-4b07-a8b1-624053d154c0","286":"c3f05619-6f18-4a76-9353-db67425a8aa9","287":"075152d1-4757-4f20-a72a-674cc7886886","288":"d0a3631f-f000-4dc7-998e-7a33f945740b","289":"522b47b3-640b-44b5-b5eb-757f0d26a181","290":"37efa081-ec3f-4832-ae23-22c3092f789e","291":"9364a9bd-6d59-46c2-a958-9730ab6860d1","292":"0850e6be-ecab-4683-bf46-082930d1814a","293":"cd450669-ab27-4677-ad58-5923adf97d4f","294":"3889cd46-ffba-4b0b-a684-38e7177920a4","295":"7ff7adcb-2dda-46f7-9834-8a702622a205","296":"11c692d2-ee2f-4cee-b750-3271374dd66e","297":"79754afd-af4f-4ec1-9296-5e6688d69bb1","298":"e792cb4d-26ad-4665-80b7-6c98df35eb22","299":"79185277-0335-4eff-ad7a-ad8ec62cf46d","300":"3c14f053-27df-49e8-8a92-bdffa254e163","301":"b99b9ead-877c-4508-a76f-03143d99dba1","302":"5f2f134a-1183-4f6e-a394-cf7f5405f615","303":"d15e9fe4-8960-4650-b299-94f269cfd7c4","304":"2f21d0c4-a101-4826-acbf-3fc19e326c95","305":"a69d4797-dc0a-4cc8-994d-55b03d25f27e","306":"e77d6462-57d9-40c7-9d7f-194086aef383","307":"31dd48aa-3412-4228-a65e-bd2deda621e6","308":"25a6f1b3-f288-46b9-891a-5f0468912fe4","309":"36bb5cdc-19b3-4206-8a04-401aee8b05e2","310":"39cc35da-35f8-4217-8a8a-092625e31cc0","311":"19f182a1-deef-441e-a23f-0f4398913586","312":"ae80cfc9-c039-4e41-9294-3da8e75cf8d8","313":"d6af3470-48c2-44ac-a8b3-c6866389036b","314":"8d9f6bba-2b5d-4fa0-9c22-4033d540445d","315":"71f894fb-fde5-4673-8f0a-0d68493dbce6","316":"1c4b63d9-5486-4bf8-b750-d9d99289b960","317":"61b67918-a4aa-4ad9-9567-96a26f0f9f0a","318":"edb64482-c11b-4796-9eeb-d9c8616db1df","319":"3fff40b0-653c-4419-bc54-baea3747799f","320":"55eec8da-1f5f-4706-a057-fbc2e923729c","321":"188a0ced-aef7-4f23-bc11-748125d55985","322":"08eb7db7-c1e3-4500-bf77-8481907ea0f9","323":"e42b6d2c-4153-40a2-841e-e813d8481568","324":"9f115e71-364d-4415-a688-a333fc34e0dc","325":"0e4a380c-5820-40b7-a14f-b8c4925b604a","326":"9d49cfa6-85b7-4b3f-ad1b-48c17806b5cf","327":"42733418-0f95-4a37-a6d9-9fbf2e765cf4","328":"3965cdb1-cc74-41a0-bf0a-9237543bf048","329":"8412c355-330b-4cc6-938a-e50fe56d53fa","330":"0df4e780-0b3c-4638-894b-ea7990e2e01d","331":"f423d4f1-5374-4ce8-9a4d-82b7aaa8eaea","332":"3e855d16-f959-4c32-8357-533525b05b4c","333":"dcc55240-e8e2-4c00-afe7-06d2e0fb5748","334":"f358ed3d-92f4-4ed2-a04b-dfcef5bbee1c","335":"87c8ccf7-85c5-456b-bcc4-20056c2eb994","336":"6c21efbb-833e-436b-ac0c-e5879b12db38","337":"2ac3c98e-3ac3-4597-857d-ea8c8c16e0bf","338":"8a7620d4-e145-46c8-9707-01b4f3aa60d6","339":"9238941f-7c58-4500-9079-d0967813cd84","340":"92422606-7ce4-48fb-8e22-102c4c380d90","341":"72c5afde-22da-46ef-bec5-4fc968392411","342":"de3667d8-9c1a-4cfe-968d-f4491d2e12e8","343":"ad09ec49-a3c1-4c92-ba34-131b942284b5","344":"8169f345-3c81-4dfb-9b05-bab95756f020","345":"a5ec8bb2-6c78-4781-954d-adcd3487da2a","346":"eeb0874b-a8dd-462d-ab84-2a3d6341ab3d","347":"142f1505-dc7e-44b5-a519-79df0bf68e40","348":"b51dbad2-9773-4f38-9f57-56d27db1c697","349":"02ab0336-0db3-45ae-b928-16dbf0f64cb4","350":"51e886ad-19e2-4c62-92ff-8ffa740a6604","351":"b61e7bba-2f24-44c4-a47f-d42dbc7e095a","352":"ba6bbd5b-0053-406d-867f-372f67505e3c","353":"e753355e-d8aa-426a-bced-1809ebb53191","354":"364bfb96-2826-491d-accb-299818e4e01e","355":"8658c5ed-b972-4908-aa78-a4184c8dc3ae","356":"e1e3c961-6ae1-4f02-8f85-8a270b5d2331","357":"6cb6cf61-2a69-433d-a3c7-547d22ece507","358":"a1628cf3-5d74-4bc0-8d76-ae36360acaba","359":"cc4fa121-667f-4328-8cfd-e3bc5454e007","360":"869e6b6d-8eb2-439f-af9f-0017df2002ac","361":"15d92394-ae02-44a0-9ecf-ecdbd70d5088","362":"04638432-bb0e-4a1d-b488-047fcbdafd83","363":"49bfd084-1ede-405d-88cd-4a2a5c295ae8","364":"9e97ad31-5b74-42b5-95ed-20c75e921ed0","365":"750ad979-2984-4320-a17a-dd3e877d4410","366":"3d8fea92-2cec-4ccc-879c-4fd774c3301d","367":"d26c5d7b-58c1-4872-8271-4c03a2613db9","368":"ba7e0a6e-1461-47a0-a365-ca49a02dbb46","369":"aa05ebbb-2f15-4c95-9bfa-21997dd061f1","370":"72b121c6-8cf6-44a6-8658-15d13816c0bd","371":"a9cca161-c4fe-4250-b6a1-69067e636e04","372":"01669102-66a5-4e59-94c4-3bbccc0a9814","373":"e56ac047-194d-4d9b-bb95-2bfca41c40cd","374":"5f0e95a2-c550-4c36-8eb0-baa65b8623d3","375":"75a79f3c-4bf4-4929-85af-945eeb06617e","376":"85fb38b8-c67d-4d01-bd27-b1fcfa291a1a","377":"33183f5a-36ec-4c05-a664-40ca41467d2d","378":"79215c81-01cc-4e5f-b4b2-4082c9c1fe83","379":"a472ea37-6d3c-4212-9d7e-c160e5be670a","380":"bc00d348-4234-42e8-8ae4-f894e892215b","381":"eeeb1f31-f21c-4df9-ac2e-734eb394df43","382":"ea808b91-3d94-43a5-800d-4b5e8900acb6","383":"0baf7a3e-0037-496e-9f87-031b2258aa4d","384":"3d90b37d-045c-4c7d-8a4a-9d4f1c93fb01","385":"1dd4103a-9701-4da3-b66d-e57765aa5c15","386":"af72ef21-c8bf-4bfb-b1b1-1535c0b385f3","387":"991e2fa8-e9c2-478b-92d6-4b04fbef4010","388":"2fb5ae2c-0cc8-4cc4-a488-c272f9c7231f","389":"262bac4d-c49b-4803-b9d9-ce745e6c37f9","390":"f4c76cb9-38c0-4131-ae27-c62a050b104e","391":"fce26de8-1097-4e21-bd4c-e49ad59fa320","392":"67fbc966-de02-4cb8-9b1f-20521cce3022","393":"3fda0441-748a-4081-975f-a0ad1aa89db6"}]